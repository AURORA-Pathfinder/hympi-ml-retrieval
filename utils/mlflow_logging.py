from typing import Dict

import mlflow
import mlflow.entities
from mlflow.tracking._tracking_service.client import TrackingServiceClient

import keras.models


def start_run(tracking_uri: str, experiment_name, **autolog_args) -> mlflow.ActiveRun:
    """
    Starts a new mlflow run with a given experiment name and returns the ActiveRun.
    """
    mlflow.set_tracking_uri(f"file://{tracking_uri}")

    mlflow.set_experiment(experiment_name)

    mlflow.autolog(**autolog_args)
    return mlflow.start_run()


def get_artifacts_uri(run_id: str):
    client = TrackingServiceClient(mlflow.get_tracking_uri())
    return client._get_artifact_repo(run_id).artifact_uri


def get_absolute_artifact_path(run_id: str, local_path: str):
    """
    Creates a new encoder layer from an MLFlow artifact path given an experiment and run name.
    """
    artifacts_uri = get_artifacts_uri(run_id)
    return f"{artifacts_uri}/{local_path}"


def get_default_model(run_id: str) -> keras.models.Model:
    """
    Returns the default model that is generated by MLFlow when running Keras models
    """
    return get_model(run_id, "model/data/model")


def get_model(run_id: str, local_artifact_path: str) -> keras.models.Model:
    """
    Returns a keras model located in the artifacts of the run at the local artifact path.
    """
    model_path = get_absolute_artifact_path(run_id, local_artifact_path)
    return keras.models.load_model(model_path)


def get_datasets_by_context(run_id: str) -> Dict[str, mlflow.data.Dataset]:
    run = mlflow.get_run(run_id)

    dataset_dict = {}

    for dataset_input in run.inputs.dataset_inputs:
        context = "unknown"

        for tag in dataset_input.tags:
            if tag.key == "mlflow.data.context":
                context = tag.value
        dataset_dict.update({context: dataset_input.dataset})

    return dataset_dict
