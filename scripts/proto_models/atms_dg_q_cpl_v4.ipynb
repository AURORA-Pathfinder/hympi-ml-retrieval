{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "008ce633-8ecc-4d52-a254-a0784d743198",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-29 19:30:05.410466: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-29 19:30:05.523471: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import isfile\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "#os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"]=\"true\"\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"]=\"cuda_malloc_async\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import L1, L2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import mlflow\n",
    "import mlflow.tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea3ea1be-bfd5-4112-989a-8d9bd16bcb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/29 19:30:09 INFO mlflow.tracking.fluent: Experiment with name 'ATMS+CPL q' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///data/nature_run/work/src/mlruns/892757010930948959', creation_time=1727652609678, experiment_id='892757010930948959', last_update_time=1727652609678, lifecycle_stage='active', name='ATMS+CPL q', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.tensorflow.autolog()\n",
    "mlflow.set_experiment(\"ATMS+CPL q\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92b48a92-7531-44b6-8461-5c367878d930",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(filelist):\n",
    "    hsel_val = []\n",
    "    scalar_val = []\n",
    "    table_val = []\n",
    "    cpl_val = []\n",
    "\n",
    "    for i in filelist:\n",
    "        # Keys: 'mh', 'hsel', 'scalar', 'table']\n",
    "        tmp = np.load(i)\n",
    "        hsel_val.append(tmp[\"mh\"])\n",
    "        scalar_val.append(tmp[\"scalar\"])\n",
    "        table_val.append(tmp[\"table\"])\n",
    "        cpl_val.append(tmp[\"cpl\"])\n",
    "\n",
    "    return np.vstack(hsel_val), np.vstack(cpl_val), np.vstack(scalar_val), np.vstack(table_val)\n",
    "\n",
    "\n",
    "train = ['/data/nature_run/fulldays_reduced/all_cpl_20060815.npz',\n",
    "         '/data/nature_run/fulldays_reduced/all_cpl_20060915.npz',\n",
    "         '/data/nature_run/fulldays_reduced/all_cpl_20061015.npz',\n",
    "         '/data/nature_run/fulldays_reduced/all_cpl_20060515.npz',\n",
    "         '/data/nature_run/fulldays_reduced/all_cpl_20060715.npz',\n",
    "         '/data/nature_run/fulldays_reduced/all_cpl_20061115.npz',\n",
    "         '/data/nature_run/fulldays_reduced/all_cpl_20060315.npz', \n",
    "         '/data/nature_run/fulldays_reduced/all_cpl_20061215.npz',\n",
    "         '/data/nature_run/fulldays_reduced/all_cpl_20060615.npz']\n",
    "\n",
    "test = ['/data/nature_run/fulldays_reduced/all_cpl_20060803.npz']\n",
    "\n",
    "validation = ['/data/nature_run/fulldays_reduced/all_cpl_20060803.npz']\n",
    "\n",
    "hsel_train, cpl_train, scalar_train, table_train = get_data(train)\n",
    "hsel_test, cpl_test, scalar_test, table_test = get_data(test)\n",
    "hsel_val, cpl_val, scalar_val, table_val = get_data(validation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c5ebff-6c25-4ae4-a936-6e372a7a3147",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hsel_train, table_train, scalar_train, hsel_test, table_test, scalar_test = dataload(\"mh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e5dbb2-4a9a-419a-baf7-be1ced137464",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hsel_train, table_train, scalar_train, hsel_test, table_test, scalar_test = dataload(\"mh\")\n",
    "#hsel_val = hsel_test.copy()\n",
    "#table_val = table_test.copy()\n",
    "#scalar_val = scalar_test.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e622c75-32d0-47dd-8af7-7d25a1d78f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8414706, 22)\n",
      "(8414706, 733)\n",
      "(8414706, 72, 3)\n",
      "(8414706, 44)\n"
     ]
    }
   ],
   "source": [
    "print(hsel_train.shape)\n",
    "print(cpl_train.shape)\n",
    "print(table_train.shape)\n",
    "print(scalar_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2751b636-5210-4f12-8989-d3f9b0a29eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-29 19:35:04.513417: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-29 19:35:05.058197: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-09-29 19:35:05.059203: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31017 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:1b:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "# What should we do\n",
    "# 1) Only use train scalars\n",
    "# 2) Scale seperateley\n",
    "\n",
    "\n",
    "# Presssure ####\n",
    "spress_test = scalar_test[:, 3].reshape(-1, 1)\n",
    "spress_train = scalar_train[:, 3].reshape(-1, 1)\n",
    "spress_val = scalar_val[:, 3].reshape(-1, 1)\n",
    "\n",
    "mins = np.min(spress_train, axis=0)\n",
    "maxs = np.max(spress_train, axis=0)\n",
    "np.savez(\"spress_scalar_cpl.npz\", mins=mins, maxs=maxs)\n",
    "\n",
    "spress_test = (spress_test - mins)/(maxs - mins)\n",
    "spress_train = (spress_train - mins)/(maxs - mins)\n",
    "spress_val = (spress_val - mins)/(maxs - mins)\n",
    "\n",
    "\n",
    "# Labels ####\n",
    "q_train = table_train[:, :, 2]\n",
    "q_test = table_test[:, :, 2]\n",
    "q_val = table_val[:, :, 2]\n",
    "\n",
    "# Spectra ####\n",
    "mins = np.min(hsel_train, axis=0)\n",
    "maxs = np.max(hsel_train, axis=0)\n",
    "\n",
    "np.savez(\"minimac_scaling_factors_cpl_mh.npz\", maxs=maxs, mins=mins)\n",
    "\n",
    "hsel_train = np.nan_to_num(hsel_train)\n",
    "hsel_test = np.nan_to_num(hsel_test)\n",
    "hsel_val = np.nan_to_num(hsel_val)\n",
    "\n",
    "hsel_train = (hsel_train - mins)/(maxs - mins)\n",
    "hsel_test = (hsel_test - mins)/(maxs - mins)\n",
    "hsel_val = (hsel_val - mins)/(maxs - mins)\n",
    "\n",
    "# CPL #####\n",
    "mins = np.min(cpl_train, axis=0)\n",
    "maxs = np.max(cpl_train, axis=0)\n",
    "np.savez(\"minimac_scaling_factors_cpl_cpl.npz\", maxs=maxs, mins=mins)\n",
    "\n",
    "cpl_train = (cpl_train - mins)/(maxs - mins)\n",
    "cpl_test = (cpl_test - mins)/(maxs - mins)\n",
    "cpl_val = (cpl_val - mins)/(maxs - mins)\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    # train\n",
    "    x_train = {'rad': tf.convert_to_tensor(hsel_train, np.float32),\n",
    "               'spress': tf.convert_to_tensor(spress_train, np.float32),\n",
    "               'cpl': tf.convert_to_tensor(cpl_train, np.float32)}\n",
    "    del hsel_train\n",
    "    del spress_train\n",
    "    \n",
    "    y_train =  tf.convert_to_tensor(q_train, np.float32)\n",
    "    del q_train\n",
    "\n",
    "    \n",
    "    # Val\n",
    "    x_val = {'rad': tf.convert_to_tensor(hsel_val, np.float32),\n",
    "             'spress': tf.convert_to_tensor(spress_val, np.float32),\n",
    "             'cpl': tf.convert_to_tensor(cpl_val, np.float32)}\n",
    "    del hsel_val\n",
    "    del spress_val\n",
    "    \n",
    "    y_val =  tf.convert_to_tensor(q_val, np.float32)\n",
    "    del q_val\n",
    "\n",
    "    \n",
    "    # Test\n",
    "    x_test = {'rad': tf.convert_to_tensor(hsel_test, np.float32),\n",
    "              'spress': tf.convert_to_tensor(spress_test, np.float32),\n",
    "              'cpl': tf.convert_to_tensor(cpl_test, np.float32)}\n",
    "    del hsel_test\n",
    "    del spress_test\n",
    "    \n",
    "    y_test =  tf.convert_to_tensor(q_test, np.float32)\n",
    "    del q_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66848f44-450d-4748-b044-1d8a1da680a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(x_test)\n",
    "# print(x_val)\n",
    "# print(y_train.shape)\n",
    "#a = np.argwhere(np.isnan(x_train['rad']))\n",
    "#print(np.sum(np.isnan(x_train['rad'])))\n",
    "#np.nan_to_num(x_train['rad'], copy=False)\n",
    "#print(np.sum(np.isnan(x_train['rad'])))\n",
    "#print(a)\n",
    "#print(len(a))\n",
    "\n",
    "np.sum(np.isnan(x_train['rad']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "137680e3-1dc6-4550-8561-a37c87676066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"q\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " rad (InputLayer)               [(None, 22)]         0           []                               \n",
      "                                                                                                  \n",
      " spress (InputLayer)            [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 23)           0           ['rad[0][0]',                    \n",
      "                                                                  'spress[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 64)           1536        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 64)           0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 64)           4160        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 64)           0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 64)           4160        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 64)           0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 64)           4160        ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 64)           0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " Temp (Dense)                   (None, 72)           4680        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 18,696\n",
      "Trainable params: 18,696\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model(config):\n",
    "    # ATMS 22\n",
    "    mh = Input(shape=(config[\"shape\"],), name=\"rad\")\n",
    "    spress = Input(shape=(1,), name=\"spress\")\n",
    "    # [ha, hb, hc, hd, hw, mh]\n",
    "    \n",
    "    x = Concatenate()([mh, spress])\n",
    "    for i in range(config[\"num_layers\"]):\n",
    "        x =  Dropout(config[\"dropout\"])(Dense(config[\"num_neurons\"], \n",
    "                                             activation=config[\"activation\"])(x))\n",
    "    outputs = Dense(config['output'], name=\"Temp\")(x)\n",
    "\n",
    "    model = Model(inputs=[mh, spress], outputs=outputs, name=\"q\")\n",
    "    model.compile(optimizer=\"adam\", loss='mae')\n",
    "\n",
    "    return model\n",
    "\n",
    "config = {'shape': 22,\n",
    "          'output': 72,\n",
    "          'dropout': np.random.choice([0.01, 0.1, 0.2, 0.5]),\n",
    "          'num_layers': np.random.choice([3, 4, 5, 10]),\n",
    "          'num_neurons': np.random.choice([16, 32, 64, 128]),\n",
    "          'activation': np.random.choice(['gelu', 'gelu', 'relu'])}\n",
    "\n",
    "model = build_model(config)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97de18dc-565e-4b7a-a366-ea1b4cbeb768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"q\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " cpl (InputLayer)               [(None, 733)]        0           []                               \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 128)          93952       ['cpl[0][0]']                    \n",
      "                                                                                                  \n",
      " rad (InputLayer)               [(None, 22)]         0           []                               \n",
      "                                                                                                  \n",
      " spress (InputLayer)            [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 32)           4128        ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 55)           0           ['rad[0][0]',                    \n",
      "                                                                  'spress[0][0]',                 \n",
      "                                                                  'dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 16)           896         ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 16)           0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 16)           272         ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 16)           0           ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 16)           272         ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 16)           0           ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 16)           272         ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 16)           0           ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 16)           272         ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 16)           0           ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 16)           272         ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 16)           0           ['dense_11[0][0]']               \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 16)           272         ['dropout_9[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 16)           0           ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 16)           272         ['dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 16)           0           ['dense_13[0][0]']               \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 16)           272         ['dropout_11[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (None, 16)           0           ['dense_14[0][0]']               \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 16)           272         ['dropout_12[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 16)           0           ['dense_15[0][0]']               \n",
      "                                                                                                  \n",
      " Temp (Dense)                   (None, 72)           1224        ['dropout_13[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 102,648\n",
      "Trainable params: 102,648\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_cpl_model(config):\n",
    "    # ATMS 22\n",
    "    mh = Input(shape=(config[\"shape\"],), name=\"rad\")\n",
    "    spress = Input(shape=(1,), name=\"spress\")\n",
    "    cpl = Input(shape=(733,), name=\"cpl\")\n",
    "    # [ha, hb, hc, hd, hw, mh]\n",
    "\n",
    "    cpl_reduced = Dense(128, activation=config[\"activation\"])(cpl)\n",
    "    cpl_reduced = Dense(32, activation=config[\"activation\"])(cpl_reduced)\n",
    "\n",
    "    \n",
    "    x = Concatenate()([mh, spress, cpl_reduced])\n",
    "    for i in range(config[\"num_layers\"]):\n",
    "        x =  Dropout(config[\"dropout\"])(Dense(config[\"num_neurons\"], \n",
    "                                             activation=config[\"activation\"])(x))\n",
    "    outputs = Dense(config['output'], name=\"Temp\")(x)\n",
    "\n",
    "    model = Model(inputs=[mh, spress, cpl], outputs=outputs, name=\"q\")\n",
    "    model.compile(optimizer=\"adam\", loss='mae')\n",
    "\n",
    "    return model\n",
    "\n",
    "config = {'shape': 22,\n",
    "          'output': 72,\n",
    "          'dropout': np.random.choice([0.01, 0.1, 0.2, 0.5]),\n",
    "          'num_layers': np.random.choice([3, 4, 5, 10]),\n",
    "          'num_neurons': np.random.choice([16, 32, 64, 128]),\n",
    "          'activation': np.random.choice(['gelu', 'gelu', 'relu'])}\n",
    "\n",
    "model = build_cpl_model(config)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3081d9a-e65b-44d5-9c98-9558667c04ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DING\n"
     ]
    }
   ],
   "source": [
    "print(\"DING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b849f517-93eb-4370-bff5-0d7e79fc93cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/29 21:22:37 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/29 21:22:37 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 46s - loss: 4.7007e-04 - val_loss: 3.4588e-04 - 46s/epoch - 11ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 48s - loss: 3.4093e-04 - val_loss: 3.2523e-04 - 48s/epoch - 12ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 39s - loss: 3.2713e-04 - val_loss: 3.2417e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 38s - loss: 3.1834e-04 - val_loss: 3.1432e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 39s - loss: 3.1277e-04 - val_loss: 3.0830e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 38s - loss: 3.0619e-04 - val_loss: 2.9790e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 38s - loss: 3.0130e-04 - val_loss: 2.9066e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 37s - loss: 2.9638e-04 - val_loss: 2.9421e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 37s - loss: 2.9257e-04 - val_loss: 2.8206e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 37s - loss: 2.8907e-04 - val_loss: 2.8289e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 35s - loss: 2.8584e-04 - val_loss: 2.7497e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 35s - loss: 2.8273e-04 - val_loss: 2.7632e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 35s - loss: 2.8041e-04 - val_loss: 2.6891e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 37s - loss: 2.7896e-04 - val_loss: 2.6669e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 36s - loss: 2.7686e-04 - val_loss: 2.6612e-04 - 36s/epoch - 8ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 37s - loss: 2.7535e-04 - val_loss: 2.6169e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 37s - loss: 2.7417e-04 - val_loss: 2.6001e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 18/1000\n",
      "4208/4208 - 36s - loss: 2.7284e-04 - val_loss: 2.6531e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 19/1000\n",
      "4208/4208 - 36s - loss: 2.7225e-04 - val_loss: 2.7229e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 20/1000\n",
      "4208/4208 - 36s - loss: 2.7086e-04 - val_loss: 2.6294e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 21/1000\n",
      "4208/4208 - 37s - loss: 2.6975e-04 - val_loss: 2.6421e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 22/1000\n",
      "4208/4208 - 36s - loss: 2.6935e-04 - val_loss: 2.6175e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 23/1000\n",
      "4208/4208 - 37s - loss: 2.6840e-04 - val_loss: 2.6063e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 24/1000\n",
      "4208/4208 - 37s - loss: 2.6771e-04 - val_loss: 2.5617e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 25/1000\n",
      "4208/4208 - 36s - loss: 2.6702e-04 - val_loss: 2.5849e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 26/1000\n",
      "4208/4208 - 37s - loss: 2.6647e-04 - val_loss: 2.6260e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 27/1000\n",
      "4208/4208 - 37s - loss: 2.6622e-04 - val_loss: 2.6637e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 28/1000\n",
      "4208/4208 - 37s - loss: 2.6483e-04 - val_loss: 2.6191e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 29/1000\n",
      "4208/4208 - 35s - loss: 2.6455e-04 - val_loss: 2.5479e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 30/1000\n",
      "4208/4208 - 36s - loss: 2.6415e-04 - val_loss: 2.5533e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 31/1000\n",
      "4208/4208 - 36s - loss: 2.6360e-04 - val_loss: 2.5604e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 32/1000\n",
      "4208/4208 - 36s - loss: 2.6352e-04 - val_loss: 2.5031e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 33/1000\n",
      "4208/4208 - 36s - loss: 2.6280e-04 - val_loss: 2.6755e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 34/1000\n",
      "4208/4208 - 37s - loss: 2.6225e-04 - val_loss: 2.5697e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 35/1000\n",
      "4208/4208 - 36s - loss: 2.6153e-04 - val_loss: 2.5073e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 36/1000\n",
      "4208/4208 - 36s - loss: 2.6120e-04 - val_loss: 2.5005e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 37/1000\n",
      "4208/4208 - 36s - loss: 2.6050e-04 - val_loss: 2.5676e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 38/1000\n",
      "4208/4208 - 36s - loss: 2.6057e-04 - val_loss: 2.6052e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 39/1000\n",
      "4208/4208 - 36s - loss: 2.6007e-04 - val_loss: 2.5710e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 40/1000\n",
      "4208/4208 - 37s - loss: 2.5986e-04 - val_loss: 2.5579e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 41/1000\n",
      "4208/4208 - 36s - loss: 2.5965e-04 - val_loss: 2.5107e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 42/1000\n",
      "4208/4208 - 36s - loss: 2.5881e-04 - val_loss: 2.5667e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 43/1000\n",
      "4208/4208 - 36s - loss: 2.5859e-04 - val_loss: 2.5794e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 44/1000\n",
      "4208/4208 - 36s - loss: 2.5850e-04 - val_loss: 2.5827e-04 - 36s/epoch - 9ms/step\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpmumx686e/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/29 21:50:11 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/data/jmackin1/miniconda/envs/tf-gpu/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n",
      "2024/09/29 21:54:04 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/29 21:54:04 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 41s - loss: 4.2716e-04 - val_loss: 3.5757e-04 - 41s/epoch - 10ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 39s - loss: 3.3399e-04 - val_loss: 3.3804e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 39s - loss: 3.1276e-04 - val_loss: 3.0785e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 39s - loss: 2.9772e-04 - val_loss: 2.9164e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 39s - loss: 2.8398e-04 - val_loss: 2.7801e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 39s - loss: 2.7635e-04 - val_loss: 2.7054e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 40s - loss: 2.7108e-04 - val_loss: 2.6538e-04 - 40s/epoch - 9ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 39s - loss: 2.6760e-04 - val_loss: 2.7754e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 39s - loss: 2.6529e-04 - val_loss: 2.6694e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 38s - loss: 2.6238e-04 - val_loss: 2.6726e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 40s - loss: 2.6017e-04 - val_loss: 2.5703e-04 - 40s/epoch - 9ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 39s - loss: 2.5779e-04 - val_loss: 2.6429e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 38s - loss: 2.5683e-04 - val_loss: 2.6228e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 38s - loss: 2.5504e-04 - val_loss: 2.7047e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 38s - loss: 2.5477e-04 - val_loss: 2.6401e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 38s - loss: 2.5240e-04 - val_loss: 2.5844e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 39s - loss: 2.5229e-04 - val_loss: 2.5448e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 18/1000\n",
      "4208/4208 - 38s - loss: 2.5054e-04 - val_loss: 2.6065e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 19/1000\n",
      "4208/4208 - 39s - loss: 2.5013e-04 - val_loss: 2.6245e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 20/1000\n",
      "4208/4208 - 38s - loss: 2.5019e-04 - val_loss: 2.5636e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 21/1000\n",
      "4208/4208 - 39s - loss: 2.4882e-04 - val_loss: 2.6078e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 22/1000\n",
      "4208/4208 - 39s - loss: 2.4853e-04 - val_loss: 2.5823e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 23/1000\n",
      "4208/4208 - 38s - loss: 2.4732e-04 - val_loss: 2.5128e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 24/1000\n",
      "4208/4208 - 38s - loss: 2.4691e-04 - val_loss: 2.5730e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 25/1000\n",
      "4208/4208 - 38s - loss: 2.4608e-04 - val_loss: 2.5509e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 26/1000\n",
      "4208/4208 - 39s - loss: 2.4545e-04 - val_loss: 2.4755e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 27/1000\n",
      "4208/4208 - 38s - loss: 2.4509e-04 - val_loss: 2.6043e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 28/1000\n",
      "4208/4208 - 39s - loss: 2.4420e-04 - val_loss: 2.5820e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 29/1000\n",
      "4208/4208 - 39s - loss: 2.4387e-04 - val_loss: 2.4921e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 30/1000\n",
      "4208/4208 - 39s - loss: 2.4250e-04 - val_loss: 2.5552e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 31/1000\n",
      "4208/4208 - 38s - loss: 2.4176e-04 - val_loss: 2.5625e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 32/1000\n",
      "4208/4208 - 38s - loss: 2.4150e-04 - val_loss: 2.5045e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 33/1000\n",
      "4208/4208 - 38s - loss: 2.4140e-04 - val_loss: 2.4867e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 34/1000\n",
      "4208/4208 - 38s - loss: 2.4076e-04 - val_loss: 2.4226e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 35/1000\n",
      "4208/4208 - 38s - loss: 2.4042e-04 - val_loss: 2.5837e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 36/1000\n",
      "4208/4208 - 37s - loss: 2.4013e-04 - val_loss: 2.5522e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 37/1000\n",
      "4208/4208 - 38s - loss: 2.3952e-04 - val_loss: 2.5548e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 38/1000\n",
      "4208/4208 - 37s - loss: 2.3903e-04 - val_loss: 2.5709e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 39/1000\n",
      "4208/4208 - 38s - loss: 2.3863e-04 - val_loss: 2.4915e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 40/1000\n",
      "4208/4208 - 38s - loss: 2.3815e-04 - val_loss: 2.4718e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 41/1000\n",
      "4208/4208 - 38s - loss: 2.3836e-04 - val_loss: 2.5171e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 42/1000\n",
      "4208/4208 - 37s - loss: 2.3724e-04 - val_loss: 2.4480e-04 - 37s/epoch - 9ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp58238s98/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/29 22:25:21 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/29 22:25:21 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 40s - loss: 6.5544e-04 - val_loss: 4.0749e-04 - 40s/epoch - 9ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 38s - loss: 4.2565e-04 - val_loss: 3.7233e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 38s - loss: 4.1722e-04 - val_loss: 3.6017e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 38s - loss: 4.1571e-04 - val_loss: 3.6727e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 38s - loss: 4.1460e-04 - val_loss: 3.6262e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 38s - loss: 4.1378e-04 - val_loss: 3.9671e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 38s - loss: 4.1267e-04 - val_loss: 3.6419e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 38s - loss: 4.1170e-04 - val_loss: 3.5675e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 38s - loss: 4.1167e-04 - val_loss: 3.6110e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 39s - loss: 4.1058e-04 - val_loss: 3.4326e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 39s - loss: 4.1055e-04 - val_loss: 3.7154e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 39s - loss: 4.1029e-04 - val_loss: 3.5747e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 38s - loss: 4.0960e-04 - val_loss: 3.4912e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 38s - loss: 4.0902e-04 - val_loss: 3.6109e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 38s - loss: 4.0843e-04 - val_loss: 3.5630e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 38s - loss: 4.0736e-04 - val_loss: 3.5546e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 38s - loss: 4.0604e-04 - val_loss: 3.5211e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 18/1000\n",
      "4208/4208 - 38s - loss: 4.0461e-04 - val_loss: 3.4753e-04 - 38s/epoch - 9ms/step\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp_fn4d29g/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/29 22:41:11 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/29 22:41:11 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 39s - loss: 5.2384e-04 - val_loss: 4.0540e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 38s - loss: 4.3032e-04 - val_loss: 3.8050e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 38s - loss: 4.1432e-04 - val_loss: 3.7638e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 38s - loss: 4.1299e-04 - val_loss: 3.7028e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 38s - loss: 4.0911e-04 - val_loss: 3.6417e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 38s - loss: 4.0643e-04 - val_loss: 3.6169e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 38s - loss: 4.0099e-04 - val_loss: 3.6130e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 37s - loss: 3.9422e-04 - val_loss: 3.4512e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 38s - loss: 3.8957e-04 - val_loss: 3.4117e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 38s - loss: 3.8914e-04 - val_loss: 3.3980e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 38s - loss: 3.8650e-04 - val_loss: 3.4190e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 38s - loss: 3.8479e-04 - val_loss: 3.5116e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 38s - loss: 3.8506e-04 - val_loss: 3.3282e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 38s - loss: 3.8471e-04 - val_loss: 3.4230e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 38s - loss: 3.8240e-04 - val_loss: 3.3200e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 38s - loss: 3.8219e-04 - val_loss: 3.5157e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 38s - loss: 3.8033e-04 - val_loss: 3.3113e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 18/1000\n",
      "4208/4208 - 38s - loss: 3.7961e-04 - val_loss: 3.4151e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 19/1000\n",
      "4208/4208 - 38s - loss: 3.8008e-04 - val_loss: 3.3659e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 20/1000\n",
      "4208/4208 - 38s - loss: 3.7956e-04 - val_loss: 3.3688e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 21/1000\n",
      "4208/4208 - 37s - loss: 3.7935e-04 - val_loss: 3.4995e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 22/1000\n",
      "4208/4208 - 38s - loss: 3.8004e-04 - val_loss: 3.3777e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 23/1000\n",
      "4208/4208 - 38s - loss: 3.7845e-04 - val_loss: 3.3666e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 24/1000\n",
      "4208/4208 - 38s - loss: 3.7869e-04 - val_loss: 3.4736e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 25/1000\n",
      "4208/4208 - 38s - loss: 3.7736e-04 - val_loss: 3.4212e-04 - 38s/epoch - 9ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp0_lrwntw/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/29 23:01:30 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/29 23:01:30 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 37s - loss: 4.8738e-04 - val_loss: 3.5305e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 34s - loss: 3.2506e-04 - val_loss: 3.3026e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 35s - loss: 3.0708e-04 - val_loss: 3.1699e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 35s - loss: 2.9551e-04 - val_loss: 3.0809e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 35s - loss: 2.8696e-04 - val_loss: 3.0475e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 35s - loss: 2.7975e-04 - val_loss: 2.9490e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 35s - loss: 2.7362e-04 - val_loss: 2.8371e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 35s - loss: 2.6795e-04 - val_loss: 2.7652e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 34s - loss: 2.6415e-04 - val_loss: 2.7279e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 34s - loss: 2.6040e-04 - val_loss: 2.7941e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 34s - loss: 2.5848e-04 - val_loss: 2.7666e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 35s - loss: 2.5609e-04 - val_loss: 2.6680e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 35s - loss: 2.5386e-04 - val_loss: 2.5845e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 35s - loss: 2.5224e-04 - val_loss: 2.6354e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 34s - loss: 2.5017e-04 - val_loss: 2.6325e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 34s - loss: 2.4816e-04 - val_loss: 2.5710e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 34s - loss: 2.4686e-04 - val_loss: 2.5253e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 18/1000\n",
      "4208/4208 - 34s - loss: 2.4576e-04 - val_loss: 2.5912e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 19/1000\n",
      "4208/4208 - 34s - loss: 2.4421e-04 - val_loss: 2.6120e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 20/1000\n",
      "4208/4208 - 34s - loss: 2.4304e-04 - val_loss: 2.5253e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 21/1000\n",
      "4208/4208 - 34s - loss: 2.4226e-04 - val_loss: 2.5279e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 22/1000\n",
      "4208/4208 - 34s - loss: 2.4101e-04 - val_loss: 2.6250e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 23/1000\n",
      "4208/4208 - 34s - loss: 2.4011e-04 - val_loss: 2.5469e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 24/1000\n",
      "4208/4208 - 34s - loss: 2.3912e-04 - val_loss: 2.5530e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 25/1000\n",
      "4208/4208 - 34s - loss: 2.3826e-04 - val_loss: 2.5389e-04 - 34s/epoch - 8ms/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f05b48ac820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpup5m0jkw/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/29 23:19:48 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/29 23:19:48 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 36s - loss: 7.3231e-04 - val_loss: 3.8651e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 34s - loss: 4.0230e-04 - val_loss: 3.7005e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 33s - loss: 3.9024e-04 - val_loss: 3.4585e-04 - 33s/epoch - 8ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 32s - loss: 3.8576e-04 - val_loss: 3.5319e-04 - 32s/epoch - 8ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 34s - loss: 3.8275e-04 - val_loss: 3.5336e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 34s - loss: 3.8155e-04 - val_loss: 3.5339e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 34s - loss: 3.8035e-04 - val_loss: 3.3456e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 34s - loss: 3.7881e-04 - val_loss: 3.3200e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 33s - loss: 3.7871e-04 - val_loss: 3.3555e-04 - 33s/epoch - 8ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 34s - loss: 3.7828e-04 - val_loss: 3.4302e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 33s - loss: 3.7771e-04 - val_loss: 3.3888e-04 - 33s/epoch - 8ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 33s - loss: 3.7726e-04 - val_loss: 3.2708e-04 - 33s/epoch - 8ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 34s - loss: 3.7679e-04 - val_loss: 3.3959e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 33s - loss: 3.7450e-04 - val_loss: 3.3665e-04 - 33s/epoch - 8ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 34s - loss: 3.7311e-04 - val_loss: 3.3845e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 34s - loss: 3.7335e-04 - val_loss: 3.2970e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 34s - loss: 3.7353e-04 - val_loss: 3.3738e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 18/1000\n",
      "4208/4208 - 33s - loss: 3.7556e-04 - val_loss: 3.4676e-04 - 33s/epoch - 8ms/step\n",
      "Epoch 19/1000\n",
      "4208/4208 - 34s - loss: 3.7293e-04 - val_loss: 3.2713e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 20/1000\n",
      "4208/4208 - 34s - loss: 3.7090e-04 - val_loss: 3.2832e-04 - 34s/epoch - 8ms/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f05b483be20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpq6cr9i_6/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/29 23:35:08 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/29 23:35:08 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 39s - loss: 4.1864e-04 - val_loss: 3.5663e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 37s - loss: 3.2517e-04 - val_loss: 3.3870e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 37s - loss: 3.0645e-04 - val_loss: 3.0857e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 36s - loss: 2.9189e-04 - val_loss: 2.8302e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 36s - loss: 2.7895e-04 - val_loss: 2.8107e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 36s - loss: 2.7030e-04 - val_loss: 2.8065e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 36s - loss: 2.6427e-04 - val_loss: 2.6629e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 36s - loss: 2.5978e-04 - val_loss: 2.5885e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 36s - loss: 2.5645e-04 - val_loss: 2.5467e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 36s - loss: 2.5427e-04 - val_loss: 2.6208e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 36s - loss: 2.5174e-04 - val_loss: 2.6181e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 37s - loss: 2.4895e-04 - val_loss: 2.5946e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 36s - loss: 2.4753e-04 - val_loss: 2.5744e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 37s - loss: 2.4609e-04 - val_loss: 2.6143e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 36s - loss: 2.4386e-04 - val_loss: 2.6250e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 36s - loss: 2.4265e-04 - val_loss: 2.5544e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 37s - loss: 2.4129e-04 - val_loss: 2.4848e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 18/1000\n",
      "4208/4208 - 36s - loss: 2.4035e-04 - val_loss: 2.5385e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 19/1000\n",
      "4208/4208 - 36s - loss: 2.3915e-04 - val_loss: 2.5140e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 20/1000\n",
      "4208/4208 - 36s - loss: 2.3853e-04 - val_loss: 2.5218e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 21/1000\n",
      "4208/4208 - 36s - loss: 2.3706e-04 - val_loss: 2.4494e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 22/1000\n",
      "4208/4208 - 36s - loss: 2.3669e-04 - val_loss: 2.5080e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 23/1000\n",
      "4208/4208 - 36s - loss: 2.3617e-04 - val_loss: 2.4599e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 24/1000\n",
      "4208/4208 - 37s - loss: 2.3482e-04 - val_loss: 2.4705e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 25/1000\n",
      "4208/4208 - 37s - loss: 2.3440e-04 - val_loss: 2.5017e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 26/1000\n",
      "4208/4208 - 36s - loss: 2.3403e-04 - val_loss: 2.4715e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 27/1000\n",
      "4208/4208 - 36s - loss: 2.3308e-04 - val_loss: 2.5133e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 28/1000\n",
      "4208/4208 - 37s - loss: 2.3271e-04 - val_loss: 2.4917e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 29/1000\n",
      "4208/4208 - 36s - loss: 2.3150e-04 - val_loss: 2.3982e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 30/1000\n",
      "4208/4208 - 36s - loss: 2.3159e-04 - val_loss: 2.4123e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 31/1000\n",
      "4208/4208 - 37s - loss: 2.3088e-04 - val_loss: 2.5120e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 32/1000\n",
      "4208/4208 - 37s - loss: 2.3025e-04 - val_loss: 2.5181e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 33/1000\n",
      "4208/4208 - 37s - loss: 2.3050e-04 - val_loss: 2.4741e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 34/1000\n",
      "4208/4208 - 37s - loss: 2.2951e-04 - val_loss: 2.4101e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 35/1000\n",
      "4208/4208 - 37s - loss: 2.2889e-04 - val_loss: 2.3835e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 36/1000\n",
      "4208/4208 - 37s - loss: 2.2904e-04 - val_loss: 2.4182e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 37/1000\n",
      "4208/4208 - 36s - loss: 2.2903e-04 - val_loss: 2.4931e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 38/1000\n",
      "4208/4208 - 37s - loss: 2.2838e-04 - val_loss: 2.4575e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 39/1000\n",
      "4208/4208 - 37s - loss: 2.2827e-04 - val_loss: 2.4069e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 40/1000\n",
      "4208/4208 - 37s - loss: 2.2769e-04 - val_loss: 2.3771e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 41/1000\n",
      "4208/4208 - 36s - loss: 2.2750e-04 - val_loss: 2.3905e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 42/1000\n",
      "4208/4208 - 36s - loss: 2.2724e-04 - val_loss: 2.3596e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 43/1000\n",
      "4208/4208 - 36s - loss: 2.2727e-04 - val_loss: 2.4397e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 44/1000\n",
      "4208/4208 - 36s - loss: 2.2682e-04 - val_loss: 2.4295e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 45/1000\n",
      "4208/4208 - 36s - loss: 2.2688e-04 - val_loss: 2.4670e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 46/1000\n",
      "4208/4208 - 36s - loss: 2.2648e-04 - val_loss: 2.3865e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 47/1000\n",
      "4208/4208 - 36s - loss: 2.2605e-04 - val_loss: 2.3937e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 48/1000\n",
      "4208/4208 - 36s - loss: 2.2600e-04 - val_loss: 2.4632e-04 - 36s/epoch - 8ms/step\n",
      "Epoch 49/1000\n",
      "4208/4208 - 36s - loss: 2.2573e-04 - val_loss: 2.4800e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 50/1000\n",
      "4208/4208 - 36s - loss: 2.2513e-04 - val_loss: 2.3252e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 51/1000\n",
      "4208/4208 - 36s - loss: 2.2514e-04 - val_loss: 2.5629e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 52/1000\n",
      "4208/4208 - 35s - loss: 2.2522e-04 - val_loss: 2.3714e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 53/1000\n",
      "4208/4208 - 37s - loss: 2.2455e-04 - val_loss: 2.3419e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 54/1000\n",
      "4208/4208 - 36s - loss: 2.2449e-04 - val_loss: 2.3739e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 55/1000\n",
      "4208/4208 - 36s - loss: 2.2359e-04 - val_loss: 2.4008e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 56/1000\n",
      "4208/4208 - 36s - loss: 2.2425e-04 - val_loss: 2.4225e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 57/1000\n",
      "4208/4208 - 37s - loss: 2.2416e-04 - val_loss: 2.3382e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 58/1000\n",
      "4208/4208 - 37s - loss: 2.2372e-04 - val_loss: 2.4357e-04 - 37s/epoch - 9ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpygrbquzj/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/30 00:14:29 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/30 00:14:29 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 38s - loss: 4.7156e-04 - val_loss: 3.4762e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 36s - loss: 3.5288e-04 - val_loss: 3.2849e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 36s - loss: 3.4401e-04 - val_loss: 3.3255e-04 - 36s/epoch - 8ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 36s - loss: 3.3854e-04 - val_loss: 3.3781e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 37s - loss: 3.3392e-04 - val_loss: 3.0799e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 37s - loss: 3.2804e-04 - val_loss: 3.0144e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 37s - loss: 3.2378e-04 - val_loss: 3.0203e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 36s - loss: 3.2113e-04 - val_loss: 3.0230e-04 - 36s/epoch - 8ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 37s - loss: 3.1778e-04 - val_loss: 3.0390e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 36s - loss: 3.1560e-04 - val_loss: 3.0131e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 37s - loss: 3.1291e-04 - val_loss: 2.9408e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 36s - loss: 3.1057e-04 - val_loss: 2.8444e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 36s - loss: 3.0827e-04 - val_loss: 2.8568e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 36s - loss: 3.0660e-04 - val_loss: 2.8399e-04 - 36s/epoch - 8ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 36s - loss: 3.0486e-04 - val_loss: 2.8115e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 36s - loss: 3.0397e-04 - val_loss: 2.8694e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 37s - loss: 3.0296e-04 - val_loss: 2.8149e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 18/1000\n",
      "4208/4208 - 36s - loss: 3.0212e-04 - val_loss: 2.6869e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 19/1000\n",
      "4208/4208 - 37s - loss: 3.0134e-04 - val_loss: 2.7413e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 20/1000\n",
      "4208/4208 - 37s - loss: 3.0018e-04 - val_loss: 2.9002e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 21/1000\n",
      "4208/4208 - 37s - loss: 2.9954e-04 - val_loss: 2.8270e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 22/1000\n",
      "4208/4208 - 36s - loss: 2.9843e-04 - val_loss: 2.7434e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 23/1000\n",
      "4208/4208 - 35s - loss: 2.9807e-04 - val_loss: 2.7801e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 24/1000\n",
      "4208/4208 - 37s - loss: 2.9765e-04 - val_loss: 2.7951e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 25/1000\n",
      "4208/4208 - 35s - loss: 2.9712e-04 - val_loss: 2.7486e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 26/1000\n",
      "4208/4208 - 37s - loss: 2.9593e-04 - val_loss: 2.8024e-04 - 37s/epoch - 9ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpn0gtba_p/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/30 00:34:31 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/30 00:34:31 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 50s - loss: 3.6506e-04 - val_loss: 3.2382e-04 - 50s/epoch - 12ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 48s - loss: 2.8111e-04 - val_loss: 2.6717e-04 - 48s/epoch - 11ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 47s - loss: 2.6082e-04 - val_loss: 2.6046e-04 - 47s/epoch - 11ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 47s - loss: 2.5013e-04 - val_loss: 2.5050e-04 - 47s/epoch - 11ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 47s - loss: 2.4307e-04 - val_loss: 2.6304e-04 - 47s/epoch - 11ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 48s - loss: 2.3699e-04 - val_loss: 2.5025e-04 - 48s/epoch - 11ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 47s - loss: 2.3259e-04 - val_loss: 2.5310e-04 - 47s/epoch - 11ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 47s - loss: 2.2817e-04 - val_loss: 2.4953e-04 - 47s/epoch - 11ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 47s - loss: 2.2513e-04 - val_loss: 2.5988e-04 - 47s/epoch - 11ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 47s - loss: 2.2213e-04 - val_loss: 2.5094e-04 - 47s/epoch - 11ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 47s - loss: 2.1844e-04 - val_loss: 2.5179e-04 - 47s/epoch - 11ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 47s - loss: 2.1708e-04 - val_loss: 2.4848e-04 - 47s/epoch - 11ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 47s - loss: 2.1526e-04 - val_loss: 2.4172e-04 - 47s/epoch - 11ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 47s - loss: 2.1190e-04 - val_loss: 2.5442e-04 - 47s/epoch - 11ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 47s - loss: 2.1152e-04 - val_loss: 2.4584e-04 - 47s/epoch - 11ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 47s - loss: 2.1015e-04 - val_loss: 2.5118e-04 - 47s/epoch - 11ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 48s - loss: 2.0751e-04 - val_loss: 2.4158e-04 - 48s/epoch - 11ms/step\n",
      "Epoch 18/1000\n",
      "4208/4208 - 47s - loss: 2.0620e-04 - val_loss: 2.5061e-04 - 47s/epoch - 11ms/step\n",
      "Epoch 19/1000\n",
      "4208/4208 - 47s - loss: 2.0592e-04 - val_loss: 2.4531e-04 - 47s/epoch - 11ms/step\n",
      "Epoch 20/1000\n",
      "4208/4208 - 48s - loss: 2.0528e-04 - val_loss: 2.4888e-04 - 48s/epoch - 11ms/step\n",
      "Epoch 21/1000\n",
      "4208/4208 - 47s - loss: 2.0344e-04 - val_loss: 2.5117e-04 - 47s/epoch - 11ms/step\n",
      "Epoch 22/1000\n",
      "4208/4208 - 47s - loss: 2.0323e-04 - val_loss: 2.4951e-04 - 47s/epoch - 11ms/step\n",
      "Epoch 23/1000\n",
      "4208/4208 - 47s - loss: 2.0238e-04 - val_loss: 2.5185e-04 - 47s/epoch - 11ms/step\n",
      "Epoch 24/1000\n",
      "4208/4208 - 47s - loss: 2.0176e-04 - val_loss: 2.6206e-04 - 47s/epoch - 11ms/step\n",
      "Epoch 25/1000\n",
      "4208/4208 - 47s - loss: 2.0097e-04 - val_loss: 2.5524e-04 - 47s/epoch - 11ms/step\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpsthiwex9/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/30 00:59:37 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/30 00:59:37 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 33s - loss: 9.9632e-04 - val_loss: 9.1425e-04 - 33s/epoch - 8ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 32s - loss: 8.7653e-04 - val_loss: 9.2208e-04 - 32s/epoch - 8ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 32s - loss: 8.7568e-04 - val_loss: 9.1130e-04 - 32s/epoch - 8ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 32s - loss: 8.7469e-04 - val_loss: 9.2235e-04 - 32s/epoch - 8ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 32s - loss: 8.7472e-04 - val_loss: 9.2383e-04 - 32s/epoch - 8ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 32s - loss: 8.7471e-04 - val_loss: 8.9870e-04 - 32s/epoch - 8ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 31s - loss: 8.7475e-04 - val_loss: 9.1842e-04 - 31s/epoch - 7ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 32s - loss: 8.7465e-04 - val_loss: 9.1705e-04 - 32s/epoch - 8ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 31s - loss: 8.7531e-04 - val_loss: 9.2910e-04 - 31s/epoch - 7ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 32s - loss: 8.7547e-04 - val_loss: 9.0463e-04 - 32s/epoch - 8ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 31s - loss: 8.7525e-04 - val_loss: 9.1835e-04 - 31s/epoch - 7ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 32s - loss: 8.7535e-04 - val_loss: 9.0494e-04 - 32s/epoch - 8ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 31s - loss: 8.7527e-04 - val_loss: 9.2230e-04 - 31s/epoch - 7ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 32s - loss: 8.7516e-04 - val_loss: 9.1716e-04 - 32s/epoch - 8ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp8an2hspd/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/30 01:10:39 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/30 01:10:39 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 34s - loss: 0.0013 - val_loss: 9.2432e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 31s - loss: 8.8696e-04 - val_loss: 9.2498e-04 - 31s/epoch - 7ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 32s - loss: 8.8648e-04 - val_loss: 9.1511e-04 - 32s/epoch - 8ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 32s - loss: 8.8581e-04 - val_loss: 9.1420e-04 - 32s/epoch - 8ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 31s - loss: 8.8552e-04 - val_loss: 9.1605e-04 - 31s/epoch - 7ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 32s - loss: 8.8589e-04 - val_loss: 9.0963e-04 - 32s/epoch - 8ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 32s - loss: 8.8542e-04 - val_loss: 9.3571e-04 - 32s/epoch - 8ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 32s - loss: 8.8552e-04 - val_loss: 9.3224e-04 - 32s/epoch - 7ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 31s - loss: 8.8547e-04 - val_loss: 9.1499e-04 - 31s/epoch - 7ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 31s - loss: 8.8569e-04 - val_loss: 9.0227e-04 - 31s/epoch - 7ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 31s - loss: 8.8550e-04 - val_loss: 9.1796e-04 - 31s/epoch - 7ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 31s - loss: 8.8547e-04 - val_loss: 9.2220e-04 - 31s/epoch - 7ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 31s - loss: 8.8547e-04 - val_loss: 9.0529e-04 - 31s/epoch - 7ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 32s - loss: 8.8546e-04 - val_loss: 9.2952e-04 - 32s/epoch - 8ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 32s - loss: 8.8553e-04 - val_loss: 9.1895e-04 - 32s/epoch - 8ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 32s - loss: 8.8543e-04 - val_loss: 9.0863e-04 - 32s/epoch - 8ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 32s - loss: 8.8568e-04 - val_loss: 9.2139e-04 - 32s/epoch - 7ms/step\n",
      "Epoch 18/1000\n",
      "4208/4208 - 32s - loss: 8.8549e-04 - val_loss: 9.2670e-04 - 32s/epoch - 8ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpqtgt2mvt/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/30 01:23:56 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/30 01:23:56 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 41s - loss: 8.9362e-04 - val_loss: 9.1877e-04 - 41s/epoch - 10ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 39s - loss: 8.8266e-04 - val_loss: 9.3177e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 39s - loss: 8.8256e-04 - val_loss: 9.1850e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 39s - loss: 8.8237e-04 - val_loss: 9.1622e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 38s - loss: 8.8281e-04 - val_loss: 9.1689e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 40s - loss: 8.8239e-04 - val_loss: 9.2150e-04 - 40s/epoch - 9ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 39s - loss: 8.8087e-04 - val_loss: 9.1228e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 40s - loss: 8.8039e-04 - val_loss: 9.1031e-04 - 40s/epoch - 9ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 39s - loss: 8.8040e-04 - val_loss: 9.1783e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 39s - loss: 8.8040e-04 - val_loss: 9.2044e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 39s - loss: 8.8064e-04 - val_loss: 9.0260e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 39s - loss: 8.8033e-04 - val_loss: 9.0934e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 39s - loss: 8.8057e-04 - val_loss: 9.2364e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 39s - loss: 8.8038e-04 - val_loss: 9.1044e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 38s - loss: 8.8042e-04 - val_loss: 9.2579e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 39s - loss: 8.8044e-04 - val_loss: 9.0920e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 39s - loss: 8.8047e-04 - val_loss: 9.2681e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 18/1000\n",
      "4208/4208 - 39s - loss: 8.8030e-04 - val_loss: 9.0751e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 19/1000\n",
      "4208/4208 - 40s - loss: 8.8065e-04 - val_loss: 9.1737e-04 - 40s/epoch - 9ms/step\n",
      "1/1 [==============================] - 0s 221ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp80tq9mig/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/30 01:40:38 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/30 01:40:38 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 33s - loss: 9.7642e-04 - val_loss: 9.1105e-04 - 33s/epoch - 8ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 31s - loss: 8.7404e-04 - val_loss: 9.2558e-04 - 31s/epoch - 7ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 32s - loss: 8.7409e-04 - val_loss: 9.0110e-04 - 32s/epoch - 8ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 31s - loss: 8.7393e-04 - val_loss: 9.1994e-04 - 31s/epoch - 7ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 31s - loss: 8.7372e-04 - val_loss: 9.1346e-04 - 31s/epoch - 7ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 32s - loss: 8.7397e-04 - val_loss: 9.0991e-04 - 32s/epoch - 8ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 31s - loss: 8.7417e-04 - val_loss: 9.0761e-04 - 31s/epoch - 7ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 31s - loss: 8.7492e-04 - val_loss: 9.1399e-04 - 31s/epoch - 7ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 31s - loss: 8.7590e-04 - val_loss: 9.0060e-04 - 31s/epoch - 7ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 31s - loss: 8.7548e-04 - val_loss: 9.1693e-04 - 31s/epoch - 7ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 31s - loss: 8.7542e-04 - val_loss: 9.1050e-04 - 31s/epoch - 7ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 32s - loss: 8.7566e-04 - val_loss: 9.1405e-04 - 32s/epoch - 7ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 32s - loss: 8.7582e-04 - val_loss: 9.2589e-04 - 32s/epoch - 8ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 31s - loss: 8.7574e-04 - val_loss: 9.1018e-04 - 31s/epoch - 7ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 31s - loss: 8.7554e-04 - val_loss: 9.0989e-04 - 31s/epoch - 7ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 31s - loss: 8.7542e-04 - val_loss: 9.2336e-04 - 31s/epoch - 7ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 32s - loss: 8.7542e-04 - val_loss: 9.1572e-04 - 32s/epoch - 8ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpn_11bpj7/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/30 01:53:24 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/30 01:53:24 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 36s - loss: 6.7274e-04 - val_loss: 3.8162e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 34s - loss: 4.0069e-04 - val_loss: 3.5968e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 35s - loss: 3.8922e-04 - val_loss: 3.4378e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 35s - loss: 3.8617e-04 - val_loss: 3.5695e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 35s - loss: 3.8171e-04 - val_loss: 3.5357e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 35s - loss: 3.7965e-04 - val_loss: 3.3907e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 35s - loss: 3.7958e-04 - val_loss: 3.3698e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 35s - loss: 3.7756e-04 - val_loss: 3.3498e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 35s - loss: 3.7724e-04 - val_loss: 3.3750e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 34s - loss: 3.7495e-04 - val_loss: 3.3787e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 35s - loss: 3.7647e-04 - val_loss: 3.2612e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 35s - loss: 3.7486e-04 - val_loss: 3.3643e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 36s - loss: 3.7361e-04 - val_loss: 3.3830e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 35s - loss: 3.7274e-04 - val_loss: 3.3266e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 35s - loss: 3.7317e-04 - val_loss: 3.3540e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 34s - loss: 3.7199e-04 - val_loss: 3.3442e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 34s - loss: 3.7081e-04 - val_loss: 3.3043e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 18/1000\n",
      "4208/4208 - 35s - loss: 3.6883e-04 - val_loss: 3.3764e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 19/1000\n",
      "4208/4208 - 34s - loss: 3.6945e-04 - val_loss: 3.3433e-04 - 34s/epoch - 8ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp7k3x_bxe/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/30 02:08:30 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/30 02:08:30 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 41s - loss: 7.7953e-04 - val_loss: 5.5488e-04 - 41s/epoch - 10ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 38s - loss: 6.0037e-04 - val_loss: 5.3674e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 38s - loss: 5.8140e-04 - val_loss: 5.2285e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 38s - loss: 5.7678e-04 - val_loss: 5.3303e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 39s - loss: 5.7414e-04 - val_loss: 5.1720e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 38s - loss: 5.7316e-04 - val_loss: 5.2543e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 38s - loss: 5.7314e-04 - val_loss: 5.2028e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 38s - loss: 5.7226e-04 - val_loss: 5.1746e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 38s - loss: 5.7131e-04 - val_loss: 5.2992e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 38s - loss: 5.7262e-04 - val_loss: 5.3164e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 38s - loss: 5.7082e-04 - val_loss: 5.1259e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 38s - loss: 5.7000e-04 - val_loss: 5.0687e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 39s - loss: 5.6922e-04 - val_loss: 4.9827e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 38s - loss: 5.7043e-04 - val_loss: 4.9655e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 38s - loss: 5.7026e-04 - val_loss: 4.9268e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 38s - loss: 5.6690e-04 - val_loss: 4.9870e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 38s - loss: 5.6852e-04 - val_loss: 4.8798e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 18/1000\n",
      "4208/4208 - 38s - loss: 5.6877e-04 - val_loss: 5.0049e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 19/1000\n",
      "4208/4208 - 38s - loss: 5.6818e-04 - val_loss: 4.8491e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 20/1000\n",
      "4208/4208 - 38s - loss: 5.6640e-04 - val_loss: 4.9617e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 21/1000\n",
      "4208/4208 - 38s - loss: 5.6655e-04 - val_loss: 4.8363e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 22/1000\n",
      "4208/4208 - 38s - loss: 5.6449e-04 - val_loss: 4.8480e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 23/1000\n",
      "4208/4208 - 38s - loss: 5.6744e-04 - val_loss: 4.8835e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 24/1000\n",
      "4208/4208 - 38s - loss: 5.6608e-04 - val_loss: 4.7323e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 25/1000\n",
      "4208/4208 - 38s - loss: 5.6681e-04 - val_loss: 4.7701e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 26/1000\n",
      "4208/4208 - 38s - loss: 5.6498e-04 - val_loss: 4.7834e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 27/1000\n",
      "4208/4208 - 37s - loss: 5.6540e-04 - val_loss: 4.8353e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 28/1000\n",
      "4208/4208 - 38s - loss: 5.6605e-04 - val_loss: 4.8371e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 29/1000\n",
      "4208/4208 - 38s - loss: 5.6859e-04 - val_loss: 4.7580e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 30/1000\n",
      "4208/4208 - 38s - loss: 5.6734e-04 - val_loss: 4.9341e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 31/1000\n",
      "4208/4208 - 38s - loss: 5.6366e-04 - val_loss: 4.8733e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 32/1000\n",
      "4208/4208 - 38s - loss: 5.6692e-04 - val_loss: 5.0221e-04 - 38s/epoch - 9ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpwms3wne2/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/30 02:33:08 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/30 02:33:08 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 38s - loss: 4.5045e-04 - val_loss: 3.4520e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 36s - loss: 3.3867e-04 - val_loss: 3.3126e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 36s - loss: 3.2661e-04 - val_loss: 3.1440e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 36s - loss: 3.1736e-04 - val_loss: 3.0939e-04 - 36s/epoch - 8ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 37s - loss: 3.0999e-04 - val_loss: 3.1094e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 36s - loss: 3.0472e-04 - val_loss: 3.0940e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 36s - loss: 3.0009e-04 - val_loss: 2.8687e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 36s - loss: 2.9708e-04 - val_loss: 2.9318e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 36s - loss: 2.9354e-04 - val_loss: 2.9019e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 36s - loss: 2.9007e-04 - val_loss: 2.7596e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 36s - loss: 2.8736e-04 - val_loss: 2.7899e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 37s - loss: 2.8444e-04 - val_loss: 2.8036e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 36s - loss: 2.8226e-04 - val_loss: 2.8046e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 37s - loss: 2.7982e-04 - val_loss: 2.7599e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 37s - loss: 2.7798e-04 - val_loss: 2.6776e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 36s - loss: 2.7625e-04 - val_loss: 2.6831e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 37s - loss: 2.7453e-04 - val_loss: 2.5920e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 18/1000\n",
      "4208/4208 - 36s - loss: 2.7264e-04 - val_loss: 2.6074e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 19/1000\n",
      "4208/4208 - 37s - loss: 2.7181e-04 - val_loss: 2.6502e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 20/1000\n",
      "4208/4208 - 37s - loss: 2.7070e-04 - val_loss: 2.6695e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 21/1000\n",
      "4208/4208 - 37s - loss: 2.6959e-04 - val_loss: 2.5452e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 22/1000\n",
      "4208/4208 - 37s - loss: 2.6898e-04 - val_loss: 2.5654e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 23/1000\n",
      "4208/4208 - 37s - loss: 2.6807e-04 - val_loss: 2.5976e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 24/1000\n",
      "4208/4208 - 36s - loss: 2.6764e-04 - val_loss: 2.6266e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 25/1000\n",
      "4208/4208 - 36s - loss: 2.6682e-04 - val_loss: 2.5202e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 26/1000\n",
      "4208/4208 - 36s - loss: 2.6647e-04 - val_loss: 2.5550e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 27/1000\n",
      "4208/4208 - 36s - loss: 2.6552e-04 - val_loss: 2.4865e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 28/1000\n",
      "4208/4208 - 36s - loss: 2.6475e-04 - val_loss: 2.5379e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 29/1000\n",
      "4208/4208 - 37s - loss: 2.6483e-04 - val_loss: 2.6168e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 30/1000\n",
      "4208/4208 - 36s - loss: 2.6382e-04 - val_loss: 2.5729e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 31/1000\n",
      "4208/4208 - 36s - loss: 2.6301e-04 - val_loss: 2.5625e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 32/1000\n",
      "4208/4208 - 36s - loss: 2.6306e-04 - val_loss: 2.5845e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 33/1000\n",
      "4208/4208 - 36s - loss: 2.6280e-04 - val_loss: 2.5580e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 34/1000\n",
      "4208/4208 - 36s - loss: 2.6247e-04 - val_loss: 2.4801e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 35/1000\n",
      "4208/4208 - 35s - loss: 2.6164e-04 - val_loss: 2.5701e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 36/1000\n",
      "4208/4208 - 35s - loss: 2.6133e-04 - val_loss: 2.5196e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 37/1000\n",
      "4208/4208 - 36s - loss: 2.6074e-04 - val_loss: 2.4907e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 38/1000\n",
      "4208/4208 - 36s - loss: 2.6019e-04 - val_loss: 2.5812e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 39/1000\n",
      "4208/4208 - 36s - loss: 2.6002e-04 - val_loss: 2.5498e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 40/1000\n",
      "4208/4208 - 37s - loss: 2.5966e-04 - val_loss: 2.5051e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 41/1000\n",
      "4208/4208 - 36s - loss: 2.5919e-04 - val_loss: 2.5301e-04 - 36s/epoch - 8ms/step\n",
      "Epoch 42/1000\n",
      "4208/4208 - 36s - loss: 2.5887e-04 - val_loss: 2.5156e-04 - 36s/epoch - 9ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmps2pgo7u_/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/30 03:02:38 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/30 03:02:38 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0067s vs `on_train_batch_end` time: 0.0069s). Check your callbacks.\n",
      "4208/4208 - 40s - loss: 3.8548e-04 - val_loss: 3.3687e-04 - 40s/epoch - 9ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 39s - loss: 3.0939e-04 - val_loss: 3.0547e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 38s - loss: 2.8615e-04 - val_loss: 2.8384e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 38s - loss: 2.7076e-04 - val_loss: 2.8695e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 38s - loss: 2.6142e-04 - val_loss: 2.7167e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 38s - loss: 2.5396e-04 - val_loss: 2.5584e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 38s - loss: 2.4867e-04 - val_loss: 2.5453e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 38s - loss: 2.4437e-04 - val_loss: 2.5123e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 39s - loss: 2.4087e-04 - val_loss: 2.4930e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 38s - loss: 2.3766e-04 - val_loss: 2.4683e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 38s - loss: 2.3510e-04 - val_loss: 2.4908e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 38s - loss: 2.3339e-04 - val_loss: 2.4114e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 38s - loss: 2.3148e-04 - val_loss: 2.4657e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 38s - loss: 2.2913e-04 - val_loss: 2.5548e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 38s - loss: 2.2735e-04 - val_loss: 2.4949e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 38s - loss: 2.2575e-04 - val_loss: 2.4126e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 37s - loss: 2.2408e-04 - val_loss: 2.4720e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 18/1000\n",
      "4208/4208 - 38s - loss: 2.2313e-04 - val_loss: 2.4102e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 19/1000\n",
      "4208/4208 - 38s - loss: 2.2116e-04 - val_loss: 2.3830e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 20/1000\n",
      "4208/4208 - 38s - loss: 2.2036e-04 - val_loss: 2.4112e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 21/1000\n",
      "4208/4208 - 38s - loss: 2.1897e-04 - val_loss: 2.3992e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 22/1000\n",
      "4208/4208 - 38s - loss: 2.1826e-04 - val_loss: 2.3771e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 23/1000\n",
      "4208/4208 - 38s - loss: 2.1734e-04 - val_loss: 2.4450e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 24/1000\n",
      "4208/4208 - 38s - loss: 2.1585e-04 - val_loss: 2.3669e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 25/1000\n",
      "4208/4208 - 38s - loss: 2.1508e-04 - val_loss: 2.3314e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 26/1000\n",
      "4208/4208 - 38s - loss: 2.1434e-04 - val_loss: 2.3838e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 27/1000\n",
      "4208/4208 - 37s - loss: 2.1408e-04 - val_loss: 2.4120e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 28/1000\n",
      "4208/4208 - 37s - loss: 2.1279e-04 - val_loss: 2.3985e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 29/1000\n",
      "4208/4208 - 37s - loss: 2.1220e-04 - val_loss: 2.4118e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 30/1000\n",
      "4208/4208 - 38s - loss: 2.1168e-04 - val_loss: 2.3117e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 31/1000\n",
      "4208/4208 - 38s - loss: 2.1132e-04 - val_loss: 2.4141e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 32/1000\n",
      "4208/4208 - 37s - loss: 2.1039e-04 - val_loss: 2.3533e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 33/1000\n",
      "4208/4208 - 38s - loss: 2.1006e-04 - val_loss: 2.4181e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 34/1000\n",
      "4208/4208 - 37s - loss: 2.0949e-04 - val_loss: 2.4062e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 35/1000\n",
      "4208/4208 - 39s - loss: 2.0843e-04 - val_loss: 2.3206e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 36/1000\n",
      "4208/4208 - 37s - loss: 2.0853e-04 - val_loss: 2.4701e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 37/1000\n",
      "4208/4208 - 38s - loss: 2.0784e-04 - val_loss: 2.3398e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 38/1000\n",
      "4208/4208 - 37s - loss: 2.0759e-04 - val_loss: 2.3627e-04 - 37s/epoch - 9ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmphhb84j_l/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/30 03:31:01 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/30 03:31:01 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 37s - loss: 9.9412e-04 - val_loss: 4.5205e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 35s - loss: 5.0387e-04 - val_loss: 4.3405e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 35s - loss: 4.9627e-04 - val_loss: 4.1613e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 34s - loss: 4.9116e-04 - val_loss: 4.2051e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 34s - loss: 4.8992e-04 - val_loss: 4.3026e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 34s - loss: 4.8678e-04 - val_loss: 4.1267e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 35s - loss: 4.8640e-04 - val_loss: 4.2096e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 35s - loss: 4.8539e-04 - val_loss: 4.1584e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 34s - loss: 4.8689e-04 - val_loss: 4.2633e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 35s - loss: 4.8432e-04 - val_loss: 4.1183e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 34s - loss: 4.8634e-04 - val_loss: 4.0388e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 34s - loss: 4.8494e-04 - val_loss: 4.1653e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 34s - loss: 4.8385e-04 - val_loss: 4.0926e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 35s - loss: 4.8383e-04 - val_loss: 4.1304e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 34s - loss: 4.8373e-04 - val_loss: 4.0846e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 34s - loss: 4.8384e-04 - val_loss: 4.1390e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 34s - loss: 4.8367e-04 - val_loss: 4.2635e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 18/1000\n",
      "4208/4208 - 35s - loss: 4.8188e-04 - val_loss: 4.0874e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 19/1000\n",
      "4208/4208 - 34s - loss: 4.8184e-04 - val_loss: 4.0886e-04 - 34s/epoch - 8ms/step\n",
      "1/1 [==============================] - 0s 122ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp_cxk2ir1/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/30 03:45:59 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/30 03:45:59 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 36s - loss: 4.7043e-04 - val_loss: 3.5096e-04 - 36s/epoch - 9ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 35s - loss: 3.2512e-04 - val_loss: 3.2080e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 34s - loss: 3.0551e-04 - val_loss: 3.1624e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 34s - loss: 2.9285e-04 - val_loss: 2.9166e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 35s - loss: 2.8456e-04 - val_loss: 3.0184e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 35s - loss: 2.7844e-04 - val_loss: 2.7911e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 34s - loss: 2.7226e-04 - val_loss: 2.7179e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 34s - loss: 2.6759e-04 - val_loss: 2.8918e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 34s - loss: 2.6408e-04 - val_loss: 2.7053e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 34s - loss: 2.6038e-04 - val_loss: 2.7630e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 35s - loss: 2.5872e-04 - val_loss: 2.6682e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 35s - loss: 2.5593e-04 - val_loss: 2.6473e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 34s - loss: 2.5467e-04 - val_loss: 2.7222e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 33s - loss: 2.5237e-04 - val_loss: 2.6770e-04 - 33s/epoch - 8ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 34s - loss: 2.5043e-04 - val_loss: 2.5751e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 34s - loss: 2.4866e-04 - val_loss: 2.6576e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 34s - loss: 2.4726e-04 - val_loss: 2.5743e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 18/1000\n",
      "4208/4208 - 33s - loss: 2.4583e-04 - val_loss: 2.6558e-04 - 33s/epoch - 8ms/step\n",
      "Epoch 19/1000\n",
      "4208/4208 - 34s - loss: 2.4488e-04 - val_loss: 2.6305e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 20/1000\n",
      "4208/4208 - 34s - loss: 2.4340e-04 - val_loss: 2.4699e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 21/1000\n",
      "4208/4208 - 34s - loss: 2.4238e-04 - val_loss: 2.4927e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 22/1000\n",
      "4208/4208 - 34s - loss: 2.4132e-04 - val_loss: 2.5394e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 23/1000\n",
      "4208/4208 - 34s - loss: 2.4036e-04 - val_loss: 2.5240e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 24/1000\n",
      "4208/4208 - 34s - loss: 2.3949e-04 - val_loss: 2.5566e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 25/1000\n",
      "4208/4208 - 34s - loss: 2.3860e-04 - val_loss: 2.5753e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 26/1000\n",
      "4208/4208 - 34s - loss: 2.3771e-04 - val_loss: 2.4784e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 27/1000\n",
      "4208/4208 - 34s - loss: 2.3716e-04 - val_loss: 2.5768e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 28/1000\n",
      "4208/4208 - 33s - loss: 2.3629e-04 - val_loss: 2.6037e-04 - 33s/epoch - 8ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpw1ekd5ar/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/30 04:05:57 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/30 04:05:57 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 50s - loss: 5.9286e-04 - val_loss: 5.1125e-04 - 50s/epoch - 12ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 48s - loss: 5.0089e-04 - val_loss: 4.3329e-04 - 48s/epoch - 11ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 49s - loss: 4.5432e-04 - val_loss: 4.2346e-04 - 49s/epoch - 12ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 47s - loss: 4.4765e-04 - val_loss: 4.2135e-04 - 47s/epoch - 11ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 48s - loss: 4.4273e-04 - val_loss: 4.0709e-04 - 48s/epoch - 11ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 48s - loss: 4.4073e-04 - val_loss: 4.1205e-04 - 48s/epoch - 11ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 49s - loss: 4.3769e-04 - val_loss: 4.0224e-04 - 49s/epoch - 12ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 48s - loss: 4.3691e-04 - val_loss: 3.9987e-04 - 48s/epoch - 11ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 47s - loss: 4.3617e-04 - val_loss: 4.0011e-04 - 47s/epoch - 11ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 48s - loss: 4.3497e-04 - val_loss: 4.1661e-04 - 48s/epoch - 11ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 48s - loss: 4.3444e-04 - val_loss: 4.1327e-04 - 48s/epoch - 11ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 47s - loss: 4.3477e-04 - val_loss: 4.0393e-04 - 47s/epoch - 11ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 47s - loss: 4.3467e-04 - val_loss: 4.1085e-04 - 47s/epoch - 11ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 48s - loss: 4.3410e-04 - val_loss: 4.1172e-04 - 48s/epoch - 11ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 47s - loss: 4.3329e-04 - val_loss: 4.1071e-04 - 47s/epoch - 11ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 47s - loss: 4.3331e-04 - val_loss: 3.9643e-04 - 47s/epoch - 11ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 47s - loss: 4.3296e-04 - val_loss: 4.1872e-04 - 47s/epoch - 11ms/step\n",
      "Epoch 18/1000\n",
      "4208/4208 - 47s - loss: 4.3226e-04 - val_loss: 4.0256e-04 - 47s/epoch - 11ms/step\n",
      "Epoch 19/1000\n",
      "4208/4208 - 47s - loss: 4.3241e-04 - val_loss: 4.1761e-04 - 47s/epoch - 11ms/step\n",
      "Epoch 20/1000\n",
      "4208/4208 - 48s - loss: 4.2511e-04 - val_loss: 3.6782e-04 - 48s/epoch - 11ms/step\n",
      "Epoch 21/1000\n",
      "4208/4208 - 47s - loss: 4.1978e-04 - val_loss: 3.7807e-04 - 47s/epoch - 11ms/step\n",
      "Epoch 22/1000\n",
      "4208/4208 - 48s - loss: 4.1815e-04 - val_loss: 3.6634e-04 - 48s/epoch - 11ms/step\n",
      "Epoch 23/1000\n",
      "4208/4208 - 47s - loss: 4.1679e-04 - val_loss: 3.7310e-04 - 47s/epoch - 11ms/step\n",
      "Epoch 24/1000\n",
      "4208/4208 - 48s - loss: 4.1649e-04 - val_loss: 3.6479e-04 - 48s/epoch - 11ms/step\n",
      "Epoch 25/1000\n",
      "4208/4208 - 47s - loss: 4.1632e-04 - val_loss: 3.6618e-04 - 47s/epoch - 11ms/step\n",
      "Epoch 26/1000\n",
      "4208/4208 - 48s - loss: 4.1510e-04 - val_loss: 3.7472e-04 - 48s/epoch - 11ms/step\n",
      "Epoch 27/1000\n",
      "4208/4208 - 49s - loss: 4.1572e-04 - val_loss: 3.6813e-04 - 49s/epoch - 12ms/step\n",
      "Epoch 28/1000\n",
      "4208/4208 - 48s - loss: 4.1494e-04 - val_loss: 3.6418e-04 - 48s/epoch - 11ms/step\n",
      "Epoch 29/1000\n",
      "4208/4208 - 47s - loss: 4.1467e-04 - val_loss: 3.7341e-04 - 47s/epoch - 11ms/step\n",
      "Epoch 30/1000\n",
      "4208/4208 - 47s - loss: 4.1450e-04 - val_loss: 3.7207e-04 - 47s/epoch - 11ms/step\n",
      "Epoch 31/1000\n",
      "4208/4208 - 48s - loss: 4.1438e-04 - val_loss: 3.7983e-04 - 48s/epoch - 11ms/step\n",
      "Epoch 32/1000\n",
      "4208/4208 - 47s - loss: 4.1379e-04 - val_loss: 3.6799e-04 - 47s/epoch - 11ms/step\n",
      "Epoch 33/1000\n",
      "4208/4208 - 48s - loss: 4.1401e-04 - val_loss: 3.7321e-04 - 48s/epoch - 11ms/step\n",
      "Epoch 34/1000\n",
      "4208/4208 - 48s - loss: 4.1338e-04 - val_loss: 3.7603e-04 - 48s/epoch - 11ms/step\n",
      "Epoch 35/1000\n",
      "4208/4208 - 48s - loss: 4.1316e-04 - val_loss: 3.8189e-04 - 48s/epoch - 11ms/step\n",
      "Epoch 36/1000\n",
      "4208/4208 - 47s - loss: 4.1361e-04 - val_loss: 3.6622e-04 - 47s/epoch - 11ms/step\n",
      "1/1 [==============================] - 1s 920ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp7z892xoc/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/30 04:39:56 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/30 04:39:56 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 40s - loss: 4.3378e-04 - val_loss: 3.5368e-04 - 40s/epoch - 10ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 39s - loss: 3.5644e-04 - val_loss: 3.3046e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 38s - loss: 3.4629e-04 - val_loss: 3.3354e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 39s - loss: 3.3740e-04 - val_loss: 3.1397e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 38s - loss: 3.2638e-04 - val_loss: 2.9962e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 38s - loss: 3.1679e-04 - val_loss: 2.8183e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 38s - loss: 3.0932e-04 - val_loss: 2.8333e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 38s - loss: 3.0460e-04 - val_loss: 2.7694e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 38s - loss: 3.0167e-04 - val_loss: 2.7372e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 39s - loss: 2.9889e-04 - val_loss: 2.7181e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 39s - loss: 2.9759e-04 - val_loss: 2.7214e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 39s - loss: 2.9615e-04 - val_loss: 2.7442e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 39s - loss: 2.9413e-04 - val_loss: 2.7714e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 39s - loss: 2.9354e-04 - val_loss: 2.7436e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 39s - loss: 2.9201e-04 - val_loss: 2.7375e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 38s - loss: 2.9151e-04 - val_loss: 2.7317e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 38s - loss: 2.9079e-04 - val_loss: 2.6957e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 18/1000\n",
      "4208/4208 - 39s - loss: 2.9008e-04 - val_loss: 2.7473e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 19/1000\n",
      "4208/4208 - 37s - loss: 2.8928e-04 - val_loss: 2.6971e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 20/1000\n",
      "4208/4208 - 38s - loss: 2.8876e-04 - val_loss: 2.5638e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 21/1000\n",
      "4208/4208 - 38s - loss: 2.8817e-04 - val_loss: 2.7175e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 22/1000\n",
      "4208/4208 - 39s - loss: 2.8769e-04 - val_loss: 2.6838e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 23/1000\n",
      "4208/4208 - 39s - loss: 2.8682e-04 - val_loss: 2.6786e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 24/1000\n",
      "4208/4208 - 38s - loss: 2.8646e-04 - val_loss: 2.6867e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 25/1000\n",
      "4208/4208 - 38s - loss: 2.8559e-04 - val_loss: 2.7115e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 26/1000\n",
      "4208/4208 - 39s - loss: 2.8534e-04 - val_loss: 2.7594e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 27/1000\n",
      "4208/4208 - 38s - loss: 2.8444e-04 - val_loss: 2.7074e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 28/1000\n",
      "4208/4208 - 38s - loss: 2.8361e-04 - val_loss: 2.6768e-04 - 38s/epoch - 9ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpxhgo2y4e/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/30 05:02:13 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/30 05:02:13 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 50s - loss: 5.1508e-04 - val_loss: 4.5279e-04 - 50s/epoch - 12ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 49s - loss: 4.6728e-04 - val_loss: 4.1616e-04 - 49s/epoch - 12ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 49s - loss: 4.4684e-04 - val_loss: 4.0831e-04 - 49s/epoch - 12ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 48s - loss: 4.3864e-04 - val_loss: 4.1160e-04 - 48s/epoch - 11ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 47s - loss: 4.3092e-04 - val_loss: 4.0068e-04 - 47s/epoch - 11ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 48s - loss: 4.2822e-04 - val_loss: 4.0245e-04 - 48s/epoch - 11ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 47s - loss: 4.2849e-04 - val_loss: 4.0640e-04 - 47s/epoch - 11ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 47s - loss: 4.2689e-04 - val_loss: 4.1783e-04 - 47s/epoch - 11ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 48s - loss: 4.2556e-04 - val_loss: 4.1454e-04 - 48s/epoch - 11ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 48s - loss: 4.2375e-04 - val_loss: 4.0914e-04 - 48s/epoch - 11ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 48s - loss: 4.2343e-04 - val_loss: 3.9931e-04 - 48s/epoch - 11ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 48s - loss: 4.2168e-04 - val_loss: 4.0815e-04 - 48s/epoch - 11ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 47s - loss: 4.2037e-04 - val_loss: 4.0511e-04 - 47s/epoch - 11ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 47s - loss: 4.2105e-04 - val_loss: 4.0238e-04 - 47s/epoch - 11ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 48s - loss: 4.2136e-04 - val_loss: 4.0326e-04 - 48s/epoch - 11ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 47s - loss: 4.2059e-04 - val_loss: 3.9723e-04 - 47s/epoch - 11ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 48s - loss: 4.1897e-04 - val_loss: 4.0368e-04 - 48s/epoch - 11ms/step\n",
      "Epoch 18/1000\n",
      "4208/4208 - 48s - loss: 4.1923e-04 - val_loss: 4.0873e-04 - 48s/epoch - 11ms/step\n",
      "Epoch 19/1000\n",
      "4208/4208 - 48s - loss: 4.2011e-04 - val_loss: 3.9854e-04 - 48s/epoch - 11ms/step\n",
      "Epoch 20/1000\n",
      "4208/4208 - 49s - loss: 4.1696e-04 - val_loss: 4.0043e-04 - 49s/epoch - 12ms/step\n",
      "Epoch 21/1000\n",
      "4208/4208 - 47s - loss: 4.1698e-04 - val_loss: 4.0853e-04 - 47s/epoch - 11ms/step\n",
      "Epoch 22/1000\n",
      "4208/4208 - 48s - loss: 4.1698e-04 - val_loss: 3.9781e-04 - 48s/epoch - 11ms/step\n",
      "Epoch 23/1000\n",
      "4208/4208 - 47s - loss: 4.1591e-04 - val_loss: 3.9641e-04 - 47s/epoch - 11ms/step\n",
      "Epoch 24/1000\n",
      "4208/4208 - 48s - loss: 4.1697e-04 - val_loss: 4.0442e-04 - 48s/epoch - 11ms/step\n",
      "Epoch 25/1000\n",
      "4208/4208 - 48s - loss: 4.1539e-04 - val_loss: 3.9814e-04 - 48s/epoch - 11ms/step\n",
      "Epoch 26/1000\n",
      "4208/4208 - 48s - loss: 4.1626e-04 - val_loss: 4.0527e-04 - 48s/epoch - 11ms/step\n",
      "Epoch 27/1000\n",
      "4208/4208 - 48s - loss: 4.1420e-04 - val_loss: 3.7739e-04 - 48s/epoch - 11ms/step\n",
      "Epoch 28/1000\n",
      "4208/4208 - 48s - loss: 4.1019e-04 - val_loss: 3.8420e-04 - 48s/epoch - 11ms/step\n",
      "Epoch 29/1000\n",
      "4208/4208 - 47s - loss: 4.0953e-04 - val_loss: 3.7208e-04 - 47s/epoch - 11ms/step\n",
      "Epoch 30/1000\n",
      "4208/4208 - 47s - loss: 4.0682e-04 - val_loss: 3.7619e-04 - 47s/epoch - 11ms/step\n",
      "Epoch 31/1000\n",
      "4208/4208 - 47s - loss: 4.0663e-04 - val_loss: 3.7238e-04 - 47s/epoch - 11ms/step\n",
      "Epoch 32/1000\n",
      "4208/4208 - 48s - loss: 4.0641e-04 - val_loss: 3.7996e-04 - 48s/epoch - 11ms/step\n",
      "Epoch 33/1000\n",
      "4208/4208 - 47s - loss: 4.0558e-04 - val_loss: 3.7367e-04 - 47s/epoch - 11ms/step\n",
      "Epoch 34/1000\n",
      "4208/4208 - 48s - loss: 4.0559e-04 - val_loss: 3.6267e-04 - 48s/epoch - 11ms/step\n",
      "Epoch 35/1000\n",
      "4208/4208 - 48s - loss: 4.0377e-04 - val_loss: 3.8357e-04 - 48s/epoch - 12ms/step\n",
      "Epoch 36/1000\n",
      "4208/4208 - 48s - loss: 4.0398e-04 - val_loss: 3.6105e-04 - 48s/epoch - 11ms/step\n",
      "Epoch 37/1000\n",
      "4208/4208 - 48s - loss: 4.0213e-04 - val_loss: 3.7024e-04 - 48s/epoch - 11ms/step\n",
      "Epoch 38/1000\n",
      "4208/4208 - 49s - loss: 4.0239e-04 - val_loss: 3.6158e-04 - 49s/epoch - 12ms/step\n",
      "Epoch 39/1000\n",
      "4208/4208 - 48s - loss: 4.0389e-04 - val_loss: 3.7267e-04 - 48s/epoch - 11ms/step\n",
      "Epoch 40/1000\n",
      "4208/4208 - 47s - loss: 4.0135e-04 - val_loss: 3.8235e-04 - 47s/epoch - 11ms/step\n",
      "Epoch 41/1000\n",
      "4208/4208 - 47s - loss: 4.0207e-04 - val_loss: 3.6620e-04 - 47s/epoch - 11ms/step\n",
      "Epoch 42/1000\n",
      "4208/4208 - 47s - loss: 4.0158e-04 - val_loss: 3.6729e-04 - 47s/epoch - 11ms/step\n",
      "Epoch 43/1000\n",
      "4208/4208 - 48s - loss: 4.0210e-04 - val_loss: 3.6731e-04 - 48s/epoch - 11ms/step\n",
      "Epoch 44/1000\n",
      "4208/4208 - 48s - loss: 4.0161e-04 - val_loss: 3.6113e-04 - 48s/epoch - 11ms/step\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpmg6r02cl/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/30 05:42:45 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/30 05:42:45 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 31s - loss: 9.1199e-04 - val_loss: 9.0711e-04 - 31s/epoch - 7ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 30s - loss: 8.7798e-04 - val_loss: 9.0690e-04 - 30s/epoch - 7ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 30s - loss: 8.7803e-04 - val_loss: 9.0703e-04 - 30s/epoch - 7ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 30s - loss: 8.7769e-04 - val_loss: 9.1317e-04 - 30s/epoch - 7ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 31s - loss: 8.7786e-04 - val_loss: 9.2588e-04 - 31s/epoch - 7ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 30s - loss: 8.7763e-04 - val_loss: 9.0955e-04 - 30s/epoch - 7ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 31s - loss: 8.7761e-04 - val_loss: 9.1831e-04 - 31s/epoch - 7ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 30s - loss: 8.7801e-04 - val_loss: 9.1848e-04 - 30s/epoch - 7ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 29s - loss: 8.7789e-04 - val_loss: 9.0379e-04 - 29s/epoch - 7ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 30s - loss: 8.7757e-04 - val_loss: 9.0108e-04 - 30s/epoch - 7ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 30s - loss: 8.7764e-04 - val_loss: 9.1949e-04 - 30s/epoch - 7ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 29s - loss: 8.7764e-04 - val_loss: 9.2104e-04 - 29s/epoch - 7ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 31s - loss: 8.7764e-04 - val_loss: 9.0889e-04 - 31s/epoch - 7ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 29s - loss: 8.7788e-04 - val_loss: 9.0160e-04 - 29s/epoch - 7ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 30s - loss: 8.7774e-04 - val_loss: 9.2656e-04 - 30s/epoch - 7ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 30s - loss: 8.7768e-04 - val_loss: 9.0301e-04 - 30s/epoch - 7ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 30s - loss: 8.7771e-04 - val_loss: 9.1328e-04 - 30s/epoch - 7ms/step\n",
      "Epoch 18/1000\n",
      "4208/4208 - 30s - loss: 8.7767e-04 - val_loss: 9.2371e-04 - 30s/epoch - 7ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpfwjy6t1c/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/30 05:55:21 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/30 05:55:21 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 41s - loss: 9.3017e-04 - val_loss: 9.0240e-04 - 41s/epoch - 10ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 39s - loss: 8.7447e-04 - val_loss: 9.1602e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 40s - loss: 8.7434e-04 - val_loss: 9.0726e-04 - 40s/epoch - 10ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 39s - loss: 8.7458e-04 - val_loss: 8.9998e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 39s - loss: 8.7504e-04 - val_loss: 9.1463e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 40s - loss: 8.7497e-04 - val_loss: 9.0144e-04 - 40s/epoch - 9ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 39s - loss: 8.7509e-04 - val_loss: 9.1472e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 39s - loss: 8.7505e-04 - val_loss: 9.1477e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 39s - loss: 8.7504e-04 - val_loss: 8.9401e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 39s - loss: 8.7508e-04 - val_loss: 8.9907e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 38s - loss: 8.7512e-04 - val_loss: 9.0947e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 39s - loss: 8.7506e-04 - val_loss: 9.1064e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 39s - loss: 8.7505e-04 - val_loss: 9.1259e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 39s - loss: 8.7564e-04 - val_loss: 9.1748e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 39s - loss: 8.7572e-04 - val_loss: 9.0427e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 40s - loss: 8.7569e-04 - val_loss: 8.9933e-04 - 40s/epoch - 9ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 39s - loss: 8.7582e-04 - val_loss: 9.2055e-04 - 39s/epoch - 9ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp7o7h3oyz/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/30 06:10:52 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/30 06:10:52 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 35s - loss: 7.6772e-04 - val_loss: 3.8220e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 35s - loss: 4.0415e-04 - val_loss: 3.6867e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 34s - loss: 3.9253e-04 - val_loss: 3.4996e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 34s - loss: 3.8723e-04 - val_loss: 3.5872e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 35s - loss: 3.8433e-04 - val_loss: 3.4191e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 34s - loss: 3.8313e-04 - val_loss: 3.4492e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 35s - loss: 3.8016e-04 - val_loss: 3.4101e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 35s - loss: 3.7840e-04 - val_loss: 3.3715e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 35s - loss: 3.7740e-04 - val_loss: 3.3268e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 34s - loss: 3.7615e-04 - val_loss: 3.3399e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 35s - loss: 3.7630e-04 - val_loss: 3.3882e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 35s - loss: 3.7516e-04 - val_loss: 3.2972e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 34s - loss: 3.7384e-04 - val_loss: 3.3161e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 34s - loss: 3.7238e-04 - val_loss: 3.3551e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 35s - loss: 3.7055e-04 - val_loss: 3.3376e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 34s - loss: 3.7179e-04 - val_loss: 3.4100e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 35s - loss: 3.6952e-04 - val_loss: 3.3868e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 18/1000\n",
      "4208/4208 - 35s - loss: 3.7037e-04 - val_loss: 3.3592e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 19/1000\n",
      "4208/4208 - 34s - loss: 3.6965e-04 - val_loss: 3.2630e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 20/1000\n",
      "4208/4208 - 35s - loss: 3.6689e-04 - val_loss: 3.2358e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 21/1000\n",
      "4208/4208 - 34s - loss: 3.6769e-04 - val_loss: 3.2702e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 22/1000\n",
      "4208/4208 - 34s - loss: 3.6596e-04 - val_loss: 3.2182e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 23/1000\n",
      "4208/4208 - 34s - loss: 3.6564e-04 - val_loss: 3.2021e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 24/1000\n",
      "4208/4208 - 35s - loss: 3.6474e-04 - val_loss: 3.2466e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 25/1000\n",
      "4208/4208 - 35s - loss: 3.6358e-04 - val_loss: 3.2155e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 26/1000\n",
      "4208/4208 - 34s - loss: 3.6402e-04 - val_loss: 3.2080e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 27/1000\n",
      "4208/4208 - 34s - loss: 3.6361e-04 - val_loss: 3.2237e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 28/1000\n",
      "4208/4208 - 34s - loss: 3.6347e-04 - val_loss: 3.1901e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 29/1000\n",
      "4208/4208 - 34s - loss: 3.6132e-04 - val_loss: 3.1980e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 30/1000\n",
      "4208/4208 - 34s - loss: 3.6145e-04 - val_loss: 3.0585e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 31/1000\n",
      "4208/4208 - 34s - loss: 3.6183e-04 - val_loss: 3.2915e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 32/1000\n",
      "4208/4208 - 34s - loss: 3.6167e-04 - val_loss: 3.1431e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 33/1000\n",
      "4208/4208 - 34s - loss: 3.6198e-04 - val_loss: 3.1918e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 34/1000\n",
      "4208/4208 - 35s - loss: 3.6238e-04 - val_loss: 3.2338e-04 - 35s/epoch - 8ms/step\n",
      "Epoch 35/1000\n",
      "4208/4208 - 34s - loss: 3.6237e-04 - val_loss: 3.1855e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 36/1000\n",
      "4208/4208 - 34s - loss: 3.6070e-04 - val_loss: 3.3066e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 37/1000\n",
      "4208/4208 - 34s - loss: 3.6181e-04 - val_loss: 3.1904e-04 - 34s/epoch - 8ms/step\n",
      "Epoch 38/1000\n",
      "4208/4208 - 34s - loss: 3.6136e-04 - val_loss: 3.2816e-04 - 34s/epoch - 8ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp6il6pbmk/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/30 06:36:41 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/30 06:36:41 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 41s - loss: 4.0428e-04 - val_loss: 3.4896e-04 - 41s/epoch - 10ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 39s - loss: 3.2009e-04 - val_loss: 3.1145e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 38s - loss: 2.9667e-04 - val_loss: 2.9559e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 39s - loss: 2.7895e-04 - val_loss: 2.6649e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 38s - loss: 2.6807e-04 - val_loss: 2.6396e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 38s - loss: 2.6090e-04 - val_loss: 2.6034e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 38s - loss: 2.5659e-04 - val_loss: 2.6284e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 37s - loss: 2.5303e-04 - val_loss: 2.6084e-04 - 37s/epoch - 9ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 39s - loss: 2.4988e-04 - val_loss: 2.6536e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 39s - loss: 2.4752e-04 - val_loss: 2.4825e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 39s - loss: 2.4517e-04 - val_loss: 2.5240e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 39s - loss: 2.4369e-04 - val_loss: 2.5070e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 39s - loss: 2.4121e-04 - val_loss: 2.4821e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 39s - loss: 2.4009e-04 - val_loss: 2.5876e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 39s - loss: 2.3859e-04 - val_loss: 2.4610e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 39s - loss: 2.3690e-04 - val_loss: 2.3968e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 39s - loss: 2.3624e-04 - val_loss: 2.5623e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 18/1000\n",
      "4208/4208 - 39s - loss: 2.3518e-04 - val_loss: 2.5490e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 19/1000\n",
      "4208/4208 - 38s - loss: 2.3460e-04 - val_loss: 2.4612e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 20/1000\n",
      "4208/4208 - 38s - loss: 2.3320e-04 - val_loss: 2.4908e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 21/1000\n",
      "4208/4208 - 38s - loss: 2.3202e-04 - val_loss: 2.3971e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 22/1000\n",
      "4208/4208 - 38s - loss: 2.3126e-04 - val_loss: 2.4090e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 23/1000\n",
      "4208/4208 - 39s - loss: 2.3010e-04 - val_loss: 2.3693e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 24/1000\n",
      "4208/4208 - 38s - loss: 2.2946e-04 - val_loss: 2.3664e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 25/1000\n",
      "4208/4208 - 39s - loss: 2.2849e-04 - val_loss: 2.4975e-04 - 39s/epoch - 9ms/step\n",
      "Epoch 26/1000\n",
      "4208/4208 - 38s - loss: 2.2852e-04 - val_loss: 2.4160e-04 - 38s/epoch - 9ms/step\n",
      "Epoch 27/1000\n"
     ]
    }
   ],
   "source": [
    "# CPL\n",
    "\n",
    "for _ in range(100):\n",
    "    config = {'shape': 22,\n",
    "              'output': 72,\n",
    "              'dropout': np.random.choice([0.01, 0.1, 0.2, 0.5]),\n",
    "              'num_layers': np.random.choice([3, 4, 5, 10]),\n",
    "              'num_neurons': np.random.choice([16, 32, 64, 128]),\n",
    "              'activation': np.random.choice(['gelu', 'gelu', 'relu'])}\n",
    "    \n",
    "    model = build_cpl_model(config)\n",
    "    \n",
    "    with mlflow.start_run() as run:\n",
    "        model_checkpoint_callback = ModelCheckpoint(\n",
    "            filepath=f\"models/model_{run.info.run_id}.keras\",\n",
    "            save_weights_only=False,\n",
    "            monitor='val_loss',\n",
    "            mode='min',\n",
    "            save_best_only=True)\n",
    "        callback = EarlyStopping(monitor='val_loss', patience=8, verbose=0)\n",
    "        mlflow.log_param(\"CPL\", True)\n",
    "\n",
    "        history = model.fit(x_train, y_train, epochs=1000, batch_size=2000,\n",
    "                            validation_data=(x_val, y_val),\n",
    "                            verbose=2,\n",
    "                            callbacks=[callback, model_checkpoint_callback])\n",
    "        \n",
    "        evaled_test = model.evaluate(x_train, y_train, batch_size=100, verbose=0)\n",
    "        evaled_train = model.evaluate(x_test, y_test, batch_size=100, verbose=0)\n",
    "\n",
    "        mlflow.log_metric(\"test_loss\", evaled_test)\n",
    "        mlflow.log_metric(\"train_loss\", evaled_train)\n",
    "\n",
    "        plt.plot(history.history[\"loss\"])\n",
    "        plt.plot(history.history[\"val_loss\"])\n",
    "        plt.title('Model Loss')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plotname = f\"plots/loss_plot_{run.info.run_id}.png\"\n",
    "        plt.savefig(plotname)\n",
    "        plt.close()\n",
    "\n",
    "        # Log the plot as an artifact\n",
    "        mlflow.log_artifact(plotname)\n",
    "        #model_path = \"modles\"\n",
    "        #mlflow.tensorflow.log_model(tf_saved_model_dir=model_path, artifact_path=\"model\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4cae9e-128c-4831-968d-a864272e0bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regs\n",
    "\n",
    "for _ in range(100):\n",
    "    config = {'shape': 22,\n",
    "              'output': 72,\n",
    "              'dropout': np.random.choice([0.01, 0.1, 0.2, 0.5]),\n",
    "              'num_layers': np.random.choice([3, 4, 5, 10]),\n",
    "              'num_neurons': np.random.choice([16, 32, 64, 128]),\n",
    "              'activation': np.random.choice(['gelu', 'gelu', 'relu'])}\n",
    "    \n",
    "    model = build_model(config)\n",
    "    \n",
    "    with mlflow.start_run() as run:\n",
    "        model_checkpoint_callback = ModelCheckpoint(\n",
    "            filepath=f\"models/model_{run.info.run_id}.keras\",\n",
    "            save_weights_only=False,\n",
    "            monitor='val_loss',\n",
    "            mode='min',\n",
    "            save_best_only=True)\n",
    "        callback = EarlyStopping(monitor='val_loss', patience=8, verbose=0)\n",
    "        mlflow.log_param(\"CPL\", False)\n",
    "\n",
    "        history = model.fit(x_train, y_train, epochs=1000, batch_size=2000,\n",
    "                            validation_data=(x_val, y_val),\n",
    "                            verbose=2,\n",
    "                            callbacks=[callback, model_checkpoint_callback])\n",
    "        \n",
    "        evaled_test = model.evaluate(x_train, y_train, batch_size=100, verbose=0)\n",
    "        evaled_train = model.evaluate(x_test, y_test, batch_size=100, verbose=0)\n",
    "\n",
    "        mlflow.log_metric(\"test_loss\", evaled_test)\n",
    "        mlflow.log_metric(\"train_loss\", evaled_train)\n",
    "\n",
    "        plt.plot(history.history[\"loss\"])\n",
    "        plt.plot(history.history[\"val_loss\"])\n",
    "        plt.title('Model Loss')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plotname = f\"plots/loss_plot_{run.info.run_id}.png\"\n",
    "        plt.savefig(plotname)\n",
    "        plt.close()\n",
    "\n",
    "        # Log the plot as an artifact\n",
    "        mlflow.log_artifact(plotname)\n",
    "        #model_path = \"modles\"\n",
    "        #mlflow.tensorflow.log_model(tf_saved_model_dir=model_path, artifact_path=\"model\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
