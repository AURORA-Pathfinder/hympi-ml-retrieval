{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "008ce633-8ecc-4d52-a254-a0784d743198",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 09:22:07.762988: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-06 09:22:07.868441: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import isfile\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "#os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"]=\"true\"\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"]=\"cuda_malloc_async\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import L1, L2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import mlflow\n",
    "import mlflow.tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea3ea1be-bfd5-4112-989a-8d9bd16bcb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/06 09:22:13 INFO mlflow.tracking.fluent: Experiment with name 'ATMS fixed t Reduced all levels new' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///data/nature_run/work/src/mlruns/829603690858225119', creation_time=1725628933135, experiment_id='829603690858225119', last_update_time=1725628933135, lifecycle_stage='active', name='ATMS fixed t Reduced all levels new', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.tensorflow.autolog()\n",
    "mlflow.set_experiment(\"ATMS fixed t Reduced all levels new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbcb607-662b-47f4-b6a7-72761b09e04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = ['/data/nature_run/fulldays_reduced/all_20060803.npz', '/data/nature_run/fulldays_reduced/all_20060815.npz', '/data/nature_run/fulldays_reduced/all_20060915.npz']\n",
    "#test = ['/data/nature_run/fulldays_reduced/all_20060315.npz', '/data/nature_run/fulldays_reduced/all_20060515.npz', '/data/nature_run/fulldays_reduced/all_20060615.npz', '/data/nature_run/fulldays_reduced/all_20060715.npz', '/data/nature_run/fulldays_reduced/all_20061015.npz', '/data/nature_run/fulldays_reduced/all_20061115.npz', '/data/nature_run/fulldays_reduced/all_20061215.npz']\n",
    "\n",
    "#print(len(train), len(test), len(train)+ len(test)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c6bafc-be5f-4bcb-9bd9-16ea3147f262",
   "metadata": {},
   "outputs": [],
   "source": [
    "#files = glob.glob(\"/data/nature_run/fulldays_reduced_evenmore/*.npz\")\n",
    "#print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92b48a92-7531-44b6-8461-5c367878d930",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AE\n",
    "\n",
    "def dataload(instr):\n",
    "\n",
    "    train = [\"/data/nature_run/fulldays_reduced_evenmore/20060615/mh.npy\",\n",
    "             \"/data/nature_run/fulldays_reduced_evenmore/20061215/mh.npy\",\n",
    "             \"/data/nature_run/fulldays_reduced_evenmore/20060515/mh.npy\",\n",
    "             \"/data/nature_run/fulldays_reduced_evenmore/20060815/mh.npy\",\n",
    "             \"/data/nature_run/fulldays_reduced_evenmore/20060915/mh.npy\",\n",
    "             \"/data/nature_run/fulldays_reduced_evenmore/20060715/mh.npy\",\n",
    "             \"/data/nature_run/fulldays_reduced_evenmore/20061015/mh.npy\",\n",
    "             \"/data/nature_run/fulldays_reduced_evenmore/20060315/mh.npy\",\n",
    "             \"/data/nature_run/fulldays_reduced_evenmore/20061115/mh.npy\"]\n",
    "\n",
    "    test = [\"/data/nature_run/fulldays_reduced_evenmore/20060803/mh.npy\"]\n",
    "\n",
    "    if instr == \"hsel\":\n",
    "        train = [x.replace(\"mh\", instr) for x in train]\n",
    "        test = [x.replace(\"mh\", instr) for x in test]\n",
    "\n",
    "    dat_train = []\n",
    "    scalar_train = []\n",
    "    table_train = []\n",
    "    \n",
    "    dat_test = []\n",
    "    scalar_test = []\n",
    "    table_test = []\n",
    "    \n",
    "    for i in train:\n",
    "        # Keys: 'mh', 'hsel', 'scalar', 'table']\n",
    "        tmp = np.load(i)\n",
    "        dat_train.append(tmp)\n",
    "        \n",
    "        tmp = np.load(i.replace(instr, \"table\"))\n",
    "        table_train.append(tmp)\n",
    "    \n",
    "        tmp = np.load(i.replace(instr, \"scalar\"))\n",
    "        scalar_train.append(tmp)\n",
    "    \n",
    "    \n",
    "    dat_train = np.vstack(dat_train)\n",
    "    table_train = np.vstack(table_train)\n",
    "    scalar_train = np.vstack(scalar_train)\n",
    "        \n",
    "    for i in test:\n",
    "        # Keys: 'mh', 'hsel', 'scalar', 'table']\n",
    "        tmp = np.load(i)\n",
    "        dat_test.append(tmp)\n",
    "        \n",
    "        tmp = np.load(i.replace(instr, \"table\"))\n",
    "        table_test.append(tmp)\n",
    "    \n",
    "        tmp = np.load(i.replace(instr, \"scalar\"))\n",
    "        scalar_test.append(tmp)\n",
    "    \n",
    "    \n",
    "    dat_test = np.vstack(dat_test)\n",
    "    table_test = np.vstack(table_test)\n",
    "    scalar_test = np.vstack(scalar_test)\n",
    "    \n",
    "    return dat_train, table_train, scalar_train, dat_test, table_test, scalar_test\n",
    "\n",
    "hsel_train, table_train, scalar_train, hsel_test, table_test, scalar_test = dataload(\"mh\")\n",
    "hsel_val = hsel_test.copy()\n",
    "table_val = table_test.copy()\n",
    "scalar_val = scalar_test.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cc1aef-d6f3-4fcd-a3d9-ed736e5d6bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spress_test = scalar_test[:, 3].reshape(-1, 1)\n",
    "# spress_train = scalar_train[:, 3].reshape(-1, 1)\n",
    "# spress_val = scalar_val[:, 3].reshape(-1, 1)\n",
    "\n",
    "\n",
    "# spress_test\n",
    "# spress_train\n",
    "# spress_val\n",
    "\n",
    "# q_train = table_train[:, :, 1]\n",
    "# q_test = table_test[:, :, 1]\n",
    "# q_val = table_val[:, :, 1]\n",
    "\n",
    "# mins = np.min(hsel_val, axis=0)\n",
    "# maxs = np.max(hsel_val, axis=0)\n",
    "# hsel_train = (hsel_val - mins)/(maxs - mins)\n",
    "# np.savez(\"hsel_val_scalar.npz\", mins=mins, maxs=maxs)\n",
    "\n",
    "# mins = np.min(hsel_train, axis=0)\n",
    "# maxs = np.max(hsel_train, axis=0)\n",
    "# hsel_train = (hsel_train - mins)/(maxs - mins)\n",
    "# np.savez(\"hsel_train_scalar.npz\", mins=mins, maxs=maxs)\n",
    "\n",
    "# mins = np.min(hsel_test, axis=0)\n",
    "# maxs = np.max(hsel_test, axis=0)\n",
    "# hsel_test = (hsel_test - mins)/(maxs - mins)\n",
    "# np.savez(\"hsel_test_scalar.npz\", mins=mins, maxs=maxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2751b636-5210-4f12-8989-d3f9b0a29eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 09:23:02.446324: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-06 09:23:03.039588: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-09-06 09:23:03.040625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31017 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:3d:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "# What should we do\n",
    "# 1) Only use train scalars\n",
    "# 2) Scale seperateley\n",
    "\n",
    "\n",
    "# Presssure\n",
    "spress_test = scalar_test[:, 3].reshape(-1, 1)\n",
    "spress_train = scalar_train[:, 3].reshape(-1, 1)\n",
    "spress_val = scalar_val[:, 3].reshape(-1, 1)\n",
    "\n",
    "mins = np.min(spress_train, axis=0)\n",
    "maxs = np.max(spress_train, axis=0)\n",
    "np.savez(\"spress_scalar.npz\", mins=mins, maxs=maxs)\n",
    "spress_test = (spress_test - mins)/(maxs - mins)\n",
    "spress_train = (spress_train - mins)/(maxs - mins)\n",
    "spress_val = (spress_val - mins)/(maxs - mins)\n",
    "\n",
    "\n",
    "# Labels\n",
    "q_train = table_train[:, :, 1]\n",
    "q_test = table_test[:, :, 1]\n",
    "q_val = table_val[:, :, 1]\n",
    "\n",
    "\n",
    "# Spectra\n",
    "\n",
    "mins = np.min(hsel_train, axis=0)\n",
    "maxs = np.max(hsel_train, axis=0)\n",
    "\n",
    "np.savez(\"minimac_scaling_factors_mh.npz\", maxs=maxs, mins=mins)\n",
    "#s_factors = np.load(\"minimac_scaling_factors_hsel.npz\")\n",
    "#mins = s_factors['mins']\n",
    "#maxs = s_factors['maxs']\n",
    "\n",
    "\n",
    "hsel_train = np.nan_to_num(hsel_train)\n",
    "hsel_test = np.nan_to_num(hsel_test)\n",
    "hsel_val = np.nan_to_num(hsel_val)\n",
    "\n",
    "hsel_train = (hsel_train - mins)/(maxs - mins)\n",
    "hsel_test = (hsel_test - mins)/(maxs - mins)\n",
    "hsel_val = (hsel_val - mins)/(maxs - mins)\n",
    "\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    # train\n",
    "    x_train = {'rad': tf.convert_to_tensor(hsel_train, np.float32),\n",
    "               'spress': tf.convert_to_tensor(spress_train, np.float32)}\n",
    "    del hsel_train\n",
    "    del spress_train\n",
    "    \n",
    "    y_train =  tf.convert_to_tensor(q_train, np.float32)\n",
    "    del q_train\n",
    "\n",
    "    \n",
    "    # Val\n",
    "    x_val = {'rad': tf.convert_to_tensor(hsel_val, np.float32),\n",
    "             'spress': tf.convert_to_tensor(spress_val, np.float32)}\n",
    "    del hsel_val\n",
    "    del spress_val\n",
    "    \n",
    "    y_val =  tf.convert_to_tensor(q_val, np.float32)\n",
    "    del q_val\n",
    "\n",
    "    \n",
    "    # Test\n",
    "    x_test = {'rad': tf.convert_to_tensor(hsel_test, np.float32),\n",
    "              'spress': tf.convert_to_tensor(spress_test, np.float32)}\n",
    "    del hsel_test\n",
    "    del spress_test\n",
    "    \n",
    "    y_test =  tf.convert_to_tensor(q_test, np.float32)\n",
    "    del q_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66848f44-450d-4748-b044-1d8a1da680a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(x_test)\n",
    "# print(x_val)\n",
    "# print(y_train.shape)\n",
    "#a = np.argwhere(np.isnan(x_train['rad']))\n",
    "#print(np.sum(np.isnan(x_train['rad'])))\n",
    "#np.nan_to_num(x_train['rad'], copy=False)\n",
    "#print(np.sum(np.isnan(x_train['rad'])))\n",
    "#print(a)\n",
    "#print(len(a))\n",
    "\n",
    "np.sum(np.isnan(x_train['rad']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fdbe91-dd90-46b1-b519-60d0fd1da662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ae_model(config):\n",
    "    # ATMS 22\n",
    "    mh = Input(shape=(config[\"shape\"],), name=\"rad\")\n",
    "    spress = Input(shape=(1,), name=\"spress\")\n",
    "    # [ha, hb, hc, hd, hw, mh]\n",
    "\n",
    "    encoder = load_model(\"encoder_3_mae.keras\")\n",
    "    encoder.trainable = False\n",
    "    #for layer in encoder.layers:\n",
    "    #    layer.trainable = False\n",
    "\n",
    "    \n",
    "    enc = encoder(mh)\n",
    "    x = Concatenate()([enc, spress])\n",
    "    for i in range(config[\"num_layers\"]):\n",
    "        x =  Dropout(config[\"dropout\"])(Dense(config[\"num_neurons\"], \n",
    "                                             activation=config[\"activation\"])(x))\n",
    "    outputs = Dense(config['output'], name=\"Temp\")(x)\n",
    "\n",
    "    model = Model(inputs=[mh, spress], outputs=outputs, name=\"Temp\")\n",
    "    model.compile(optimizer=\"adam\", loss='mae')\n",
    "\n",
    "    return model\n",
    "\n",
    "config = {'shape': 1957,\n",
    "          'output': 72,\n",
    "          'dropout': np.random.choice([0.01, 0.1, 0.2, 0.5]),\n",
    "          'num_layers': np.random.choice([3, 4, 5, 10]),\n",
    "          'num_neurons': np.random.choice([16, 32, 64, 128]),\n",
    "          'activation': np.random.choice(['gelu', 'gelu', 'relu'])}\n",
    "\n",
    "model = build_ae_model(config)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "137680e3-1dc6-4550-8561-a37c87676066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Temp\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " rad (InputLayer)               [(None, 22)]         0           []                               \n",
      "                                                                                                  \n",
      " spress (InputLayer)            [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 23)           0           ['rad[0][0]',                    \n",
      "                                                                  'spress[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 64)           1536        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 64)           0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 64)           4160        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 64)           0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 64)           4160        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 64)           0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 64)           4160        ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 64)           0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " Temp (Dense)                   (None, 72)           4680        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 18,696\n",
      "Trainable params: 18,696\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model(config):\n",
    "    # ATMS 22\n",
    "    mh = Input(shape=(config[\"shape\"],), name=\"rad\")\n",
    "    spress = Input(shape=(1,), name=\"spress\")\n",
    "    # [ha, hb, hc, hd, hw, mh]\n",
    "    \n",
    "    x = Concatenate()([mh, spress])\n",
    "    for i in range(config[\"num_layers\"]):\n",
    "        x =  Dropout(config[\"dropout\"])(Dense(config[\"num_neurons\"], \n",
    "                                             activation=config[\"activation\"])(x))\n",
    "    outputs = Dense(config['output'], name=\"Temp\")(x)\n",
    "\n",
    "    model = Model(inputs=[mh, spress], outputs=outputs, name=\"Temp\")\n",
    "    model.compile(optimizer=\"adam\", loss='mae')\n",
    "\n",
    "    return model\n",
    "\n",
    "config = {'shape': 22,\n",
    "          'output': 72,\n",
    "          'dropout': np.random.choice([0.01, 0.1, 0.2, 0.5]),\n",
    "          'num_layers': np.random.choice([3, 4, 5, 10]),\n",
    "          'num_neurons': np.random.choice([16, 32, 64, 128]),\n",
    "          'activation': np.random.choice(['gelu', 'gelu', 'relu'])}\n",
    "\n",
    "model = build_model(config)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3081d9a-e65b-44d5-9c98-9558667c04ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b849f517-93eb-4370-bff5-0d7e79fc93cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/06 09:24:43 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/06 09:24:43 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 119ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpeko_dwx0/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/06 10:28:28 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/data/jmackin1/miniconda/envs/tf-gpu/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n",
      "2024/09/06 10:31:43 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/06 10:31:43 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 134ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp578ifm0n/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/06 10:54:30 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/06 10:54:30 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 82ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmplhxtczgh/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/06 11:31:01 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/06 11:31:01 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 118ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpzdgxtl6h/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/06 12:03:44 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/06 12:03:44 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0062s vs `on_train_batch_end` time: 0.0064s). Check your callbacks.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbdac58d480> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 186ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpc2fadgti/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/06 12:36:19 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/06 12:36:19 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbd9f84b010> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpkg_p5f3o/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/06 12:46:13 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/06 12:46:13 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 127ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp_z8mcrj9/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/06 13:39:55 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/06 13:39:55 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 98ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp0y9ahs72/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/06 14:17:59 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/06 14:17:59 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0028s vs `on_train_batch_end` time: 0.0030s). Check your callbacks.\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp52i7n60g/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/06 14:23:55 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/06 14:23:55 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 151ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpt1vunvrt/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/06 15:13:18 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/06 15:13:18 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 99ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp5mlgbif5/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/06 15:19:24 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/06 15:19:24 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 117ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmprlou10b5/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/06 15:28:03 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/06 15:28:03 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 104ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpp65ymjza/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/06 15:32:51 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/06 15:32:51 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0072s vs `on_train_batch_end` time: 0.0087s). Check your callbacks.\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpjcdxvv32/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/06 16:02:51 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/06 16:02:51 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0059s vs `on_train_batch_end` time: 0.0063s). Check your callbacks.\n",
      "1/1 [==============================] - 0s 221ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpow577wuh/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/06 16:20:50 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/06 16:20:50 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0044s vs `on_train_batch_end` time: 0.0051s). Check your callbacks.\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpft2yqqsu/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/06 16:44:38 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/06 16:44:38 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 108ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp_lem5v_3/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/06 16:54:36 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/06 16:54:36 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0039s vs `on_train_batch_end` time: 0.0046s). Check your callbacks.\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp37wiei0o/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/06 17:42:45 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/06 17:42:45 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 113ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpkogk5x52/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/06 18:01:34 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/06 18:01:34 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0046s vs `on_train_batch_end` time: 0.0053s). Check your callbacks.\n"
     ]
    }
   ],
   "source": [
    "# AE\n",
    "\n",
    "for _ in range(100):\n",
    "    config = {'shape': 22,\n",
    "              'output': 72,\n",
    "              'dropout': np.random.choice([0.01, 0.1, 0.2, 0.5]),\n",
    "              'num_layers': np.random.choice([3, 4, 5, 10]),\n",
    "              'num_neurons': np.random.choice([16, 32, 64, 128]),\n",
    "              'activation': np.random.choice(['gelu', 'gelu', 'relu']),\n",
    "              'batch_size': np.random.choice([1500, 2000, 5000, 4000])}\n",
    "    \n",
    "    #ae = np.random.choice([True, False, True, True])\n",
    "    #if ae:\n",
    "    #    model = build_ae_model(config)\n",
    "    #else:\n",
    "    ae = False\n",
    "    model = build_model(config)\n",
    "    \n",
    "    with mlflow.start_run() as run:\n",
    "        model_checkpoint_callback = ModelCheckpoint(\n",
    "            filepath=f\"models/model_{run.info.run_id}.keras\",\n",
    "            save_weights_only=False,\n",
    "            monitor='val_loss',\n",
    "            verbose=0,\n",
    "            mode='min',\n",
    "            save_best_only=True)\n",
    "        callback = EarlyStopping(monitor='val_loss', patience=10, verbose=0)\n",
    "        mlflow.log_param(\"Autoencoder\", ae)\n",
    "\n",
    "        history = model.fit(x_train, y_train, epochs=1000, batch_size=config['batch_size'],\n",
    "                            validation_data=(x_val, y_val),\n",
    "                            verbose=0,\n",
    "                            callbacks=[callback, model_checkpoint_callback])\n",
    "        \n",
    "        evaled_test = model.evaluate(x_train, y_train, batch_size=100, verbose=0)\n",
    "        evaled_train = model.evaluate(x_test, y_test, batch_size=100, verbose=0)\n",
    "\n",
    "        mlflow.log_metric(\"test_loss\", evaled_test)\n",
    "        mlflow.log_metric(\"train_loss\", evaled_train)\n",
    "\n",
    "        plt.plot(history.history[\"loss\"])\n",
    "        plt.plot(history.history[\"val_loss\"])\n",
    "        plt.title('Model Loss')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plotname = f\"plots/loss_plot_{run.info.run_id}.png\"\n",
    "        plt.savefig(plotname)\n",
    "        plt.close()\n",
    "\n",
    "        # Log the plot as an artifact\n",
    "        mlflow.log_artifact(plotname)\n",
    "        #model_path = \"modles\"\n",
    "        #mlflow.tensorflow.log_model(tf_saved_model_dir=model_path, artifact_path=\"model\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
