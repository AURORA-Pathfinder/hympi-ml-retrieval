{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "008ce633-8ecc-4d52-a254-a0784d743198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import isfile\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "#os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"]=\"true\"\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"]=\"cuda_malloc_async\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import L1, L2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import mlflow\n",
    "import mlflow.tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea3ea1be-bfd5-4112-989a-8d9bd16bcb1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///data/nature_run/work/src/mlruns/406530874024684188', creation_time=1727649901953, experiment_id='406530874024684188', last_update_time=1727649901953, lifecycle_stage='active', name='ATMS+CPL T', tags={}>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.tensorflow.autolog()\n",
    "mlflow.set_experiment(\"ATMS+CPL T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92b48a92-7531-44b6-8461-5c367878d930",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(filelist):\n",
    "    hsel_val = []\n",
    "    scalar_val = []\n",
    "    table_val = []\n",
    "    cpl_val = []\n",
    "\n",
    "    for i in filelist:\n",
    "        # Keys: 'mh', 'hsel', 'scalar', 'table']\n",
    "        tmp = np.load(i)\n",
    "        hsel_val.append(tmp[\"mh\"])\n",
    "        scalar_val.append(tmp[\"scalar\"])\n",
    "        table_val.append(tmp[\"table\"])\n",
    "        cpl_val.append(tmp[\"cpl\"])\n",
    "\n",
    "    return np.vstack(hsel_val), np.vstack(cpl_val), np.vstack(scalar_val), np.vstack(table_val)\n",
    "\n",
    "\n",
    "train = ['/data/nature_run/fulldays_reduced/all_cpl_20060815.npz',\n",
    "         '/data/nature_run/fulldays_reduced/all_cpl_20060915.npz',\n",
    "         '/data/nature_run/fulldays_reduced/all_cpl_20061015.npz',\n",
    "         '/data/nature_run/fulldays_reduced/all_cpl_20060515.npz',\n",
    "         '/data/nature_run/fulldays_reduced/all_cpl_20060715.npz',\n",
    "         '/data/nature_run/fulldays_reduced/all_cpl_20061115.npz',\n",
    "         '/data/nature_run/fulldays_reduced/all_cpl_20060315.npz', \n",
    "         '/data/nature_run/fulldays_reduced/all_cpl_20061215.npz',\n",
    "         '/data/nature_run/fulldays_reduced/all_cpl_20060615.npz']\n",
    "\n",
    "test = ['/data/nature_run/fulldays_reduced/all_cpl_20060803.npz']\n",
    "\n",
    "validation = ['/data/nature_run/fulldays_reduced/all_cpl_20060803.npz']\n",
    "\n",
    "hsel_train, cpl_train, scalar_train, table_train = get_data(train)\n",
    "hsel_test, cpl_test, scalar_test, table_test = get_data(test)\n",
    "hsel_val, cpl_val, scalar_val, table_val = get_data(validation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c5ebff-6c25-4ae4-a936-6e372a7a3147",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hsel_train, table_train, scalar_train, hsel_test, table_test, scalar_test = dataload(\"mh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e5dbb2-4a9a-419a-baf7-be1ced137464",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hsel_train, table_train, scalar_train, hsel_test, table_test, scalar_test = dataload(\"mh\")\n",
    "#hsel_val = hsel_test.copy()\n",
    "#table_val = table_test.copy()\n",
    "#scalar_val = scalar_test.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e622c75-32d0-47dd-8af7-7d25a1d78f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8414706, 22)\n",
      "(8414706, 733)\n",
      "(8414706, 72, 3)\n",
      "(8414706, 44)\n"
     ]
    }
   ],
   "source": [
    "print(hsel_train.shape)\n",
    "print(cpl_train.shape)\n",
    "print(table_train.shape)\n",
    "print(scalar_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2751b636-5210-4f12-8989-d3f9b0a29eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What should we do\n",
    "# 1) Only use train scalars\n",
    "# 2) Scale seperateley\n",
    "\n",
    "\n",
    "# Presssure ####\n",
    "spress_test = scalar_test[:, 3].reshape(-1, 1)\n",
    "spress_train = scalar_train[:, 3].reshape(-1, 1)\n",
    "spress_val = scalar_val[:, 3].reshape(-1, 1)\n",
    "\n",
    "mins = np.min(spress_train, axis=0)\n",
    "maxs = np.max(spress_train, axis=0)\n",
    "np.savez(\"spress_scalar_cpl.npz\", mins=mins, maxs=maxs)\n",
    "\n",
    "spress_test = (spress_test - mins)/(maxs - mins)\n",
    "spress_train = (spress_train - mins)/(maxs - mins)\n",
    "spress_val = (spress_val - mins)/(maxs - mins)\n",
    "\n",
    "\n",
    "# Labels ####\n",
    "q_train = table_train[:, :, 1]\n",
    "q_test = table_test[:, :, 1]\n",
    "q_val = table_val[:, :, 1]\n",
    "\n",
    "# Spectra ####\n",
    "mins = np.min(hsel_train, axis=0)\n",
    "maxs = np.max(hsel_train, axis=0)\n",
    "\n",
    "np.savez(\"minimac_scaling_factors_cpl_mh.npz\", maxs=maxs, mins=mins)\n",
    "\n",
    "hsel_train = np.nan_to_num(hsel_train)\n",
    "hsel_test = np.nan_to_num(hsel_test)\n",
    "hsel_val = np.nan_to_num(hsel_val)\n",
    "\n",
    "hsel_train = (hsel_train - mins)/(maxs - mins)\n",
    "hsel_test = (hsel_test - mins)/(maxs - mins)\n",
    "hsel_val = (hsel_val - mins)/(maxs - mins)\n",
    "\n",
    "# CPL #####\n",
    "mins = np.min(cpl_train, axis=0)\n",
    "maxs = np.max(cpl_train, axis=0)\n",
    "np.savez(\"minimac_scaling_factors_cpl_cpl.npz\", maxs=maxs, mins=mins)\n",
    "\n",
    "cpl_train = (cpl_train - mins)/(maxs - mins)\n",
    "cpl_test = (cpl_test - mins)/(maxs - mins)\n",
    "cpl_val = (cpl_val - mins)/(maxs - mins)\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    # train\n",
    "    x_train = {'rad': tf.convert_to_tensor(hsel_train, np.float32),\n",
    "               'spress': tf.convert_to_tensor(spress_train, np.float32),\n",
    "               'cpl': tf.convert_to_tensor(cpl_train, np.float32)}\n",
    "    del hsel_train\n",
    "    del spress_train\n",
    "    \n",
    "    y_train =  tf.convert_to_tensor(q_train, np.float32)\n",
    "    del q_train\n",
    "\n",
    "    \n",
    "    # Val\n",
    "    x_val = {'rad': tf.convert_to_tensor(hsel_val, np.float32),\n",
    "             'spress': tf.convert_to_tensor(spress_val, np.float32),\n",
    "             'cpl': tf.convert_to_tensor(cpl_val, np.float32)}\n",
    "    del hsel_val\n",
    "    del spress_val\n",
    "    \n",
    "    y_val =  tf.convert_to_tensor(q_val, np.float32)\n",
    "    del q_val\n",
    "\n",
    "    \n",
    "    # Test\n",
    "    x_test = {'rad': tf.convert_to_tensor(hsel_test, np.float32),\n",
    "              'spress': tf.convert_to_tensor(spress_test, np.float32),\n",
    "              'cpl': tf.convert_to_tensor(cpl_test, np.float32)}\n",
    "    del hsel_test\n",
    "    del spress_test\n",
    "    \n",
    "    y_test =  tf.convert_to_tensor(q_test, np.float32)\n",
    "    del q_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66848f44-450d-4748-b044-1d8a1da680a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(x_test)\n",
    "# print(x_val)\n",
    "# print(y_train.shape)\n",
    "#a = np.argwhere(np.isnan(x_train['rad']))\n",
    "#print(np.sum(np.isnan(x_train['rad'])))\n",
    "#np.nan_to_num(x_train['rad'], copy=False)\n",
    "#print(np.sum(np.isnan(x_train['rad'])))\n",
    "#print(a)\n",
    "#print(len(a))\n",
    "\n",
    "np.sum(np.isnan(x_train['rad']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "137680e3-1dc6-4550-8561-a37c87676066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"T\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " rad (InputLayer)               [(None, 22)]         0           []                               \n",
      "                                                                                                  \n",
      " spress (InputLayer)            [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 23)           0           ['rad[0][0]',                    \n",
      "                                                                  'spress[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 32)           768         ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 32)           0           ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 32)           1056        ['dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 32)           0           ['dense_13[0][0]']               \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 32)           1056        ['dropout_11[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (None, 32)           0           ['dense_14[0][0]']               \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 32)           1056        ['dropout_12[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 32)           0           ['dense_15[0][0]']               \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 32)           1056        ['dropout_13[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)           (None, 32)           0           ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 32)           1056        ['dropout_14[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, 32)           0           ['dense_17[0][0]']               \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 32)           1056        ['dropout_15[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)           (None, 32)           0           ['dense_18[0][0]']               \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 32)           1056        ['dropout_16[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)           (None, 32)           0           ['dense_19[0][0]']               \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 32)           1056        ['dropout_17[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_18 (Dropout)           (None, 32)           0           ['dense_20[0][0]']               \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 32)           1056        ['dropout_18[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_19 (Dropout)           (None, 32)           0           ['dense_21[0][0]']               \n",
      "                                                                                                  \n",
      " Temp (Dense)                   (None, 72)           2376        ['dropout_19[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 12,648\n",
      "Trainable params: 12,648\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model(config):\n",
    "    # ATMS 22\n",
    "    mh = Input(shape=(config[\"shape\"],), name=\"rad\")\n",
    "    spress = Input(shape=(1,), name=\"spress\")\n",
    "    # [ha, hb, hc, hd, hw, mh]\n",
    "    \n",
    "    x = Concatenate()([mh, spress])\n",
    "    for i in range(config[\"num_layers\"]):\n",
    "        x =  Dropout(config[\"dropout\"])(Dense(config[\"num_neurons\"], \n",
    "                                             activation=config[\"activation\"])(x))\n",
    "    outputs = Dense(config['output'], name=\"Temp\")(x)\n",
    "\n",
    "    model = Model(inputs=[mh, spress], outputs=outputs, name=\"T\")\n",
    "    model.compile(optimizer=\"adam\", loss='mae')\n",
    "\n",
    "    return model\n",
    "\n",
    "config = {'shape': 22,\n",
    "          'output': 72,\n",
    "          'dropout': np.random.choice([0.01, 0.1, 0.2, 0.5]),\n",
    "          'num_layers': np.random.choice([3, 4, 5, 10]),\n",
    "          'num_neurons': np.random.choice([16, 32, 64, 128]),\n",
    "          'activation': np.random.choice(['gelu', 'gelu', 'relu'])}\n",
    "\n",
    "model = build_model(config)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97de18dc-565e-4b7a-a366-ea1b4cbeb768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"T\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " cpl (InputLayer)               [(None, 733)]        0           []                               \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 128)          93952       ['cpl[0][0]']                    \n",
      "                                                                                                  \n",
      " rad (InputLayer)               [(None, 22)]         0           []                               \n",
      "                                                                                                  \n",
      " spress (InputLayer)            [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 32)           4128        ['dense_22[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 55)           0           ['rad[0][0]',                    \n",
      "                                                                  'spress[0][0]',                 \n",
      "                                                                  'dense_23[0][0]']               \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 16)           896         ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_20 (Dropout)           (None, 16)           0           ['dense_24[0][0]']               \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 16)           272         ['dropout_20[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_21 (Dropout)           (None, 16)           0           ['dense_25[0][0]']               \n",
      "                                                                                                  \n",
      " dense_26 (Dense)               (None, 16)           272         ['dropout_21[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_22 (Dropout)           (None, 16)           0           ['dense_26[0][0]']               \n",
      "                                                                                                  \n",
      " dense_27 (Dense)               (None, 16)           272         ['dropout_22[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_23 (Dropout)           (None, 16)           0           ['dense_27[0][0]']               \n",
      "                                                                                                  \n",
      " dense_28 (Dense)               (None, 16)           272         ['dropout_23[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_24 (Dropout)           (None, 16)           0           ['dense_28[0][0]']               \n",
      "                                                                                                  \n",
      " dense_29 (Dense)               (None, 16)           272         ['dropout_24[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_25 (Dropout)           (None, 16)           0           ['dense_29[0][0]']               \n",
      "                                                                                                  \n",
      " dense_30 (Dense)               (None, 16)           272         ['dropout_25[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_26 (Dropout)           (None, 16)           0           ['dense_30[0][0]']               \n",
      "                                                                                                  \n",
      " dense_31 (Dense)               (None, 16)           272         ['dropout_26[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_27 (Dropout)           (None, 16)           0           ['dense_31[0][0]']               \n",
      "                                                                                                  \n",
      " dense_32 (Dense)               (None, 16)           272         ['dropout_27[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_28 (Dropout)           (None, 16)           0           ['dense_32[0][0]']               \n",
      "                                                                                                  \n",
      " dense_33 (Dense)               (None, 16)           272         ['dropout_28[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_29 (Dropout)           (None, 16)           0           ['dense_33[0][0]']               \n",
      "                                                                                                  \n",
      " Temp (Dense)                   (None, 72)           1224        ['dropout_29[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 102,648\n",
      "Trainable params: 102,648\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_cpl_model(config):\n",
    "    # ATMS 22\n",
    "    mh = Input(shape=(config[\"shape\"],), name=\"rad\")\n",
    "    spress = Input(shape=(1,), name=\"spress\")\n",
    "    cpl = Input(shape=(733,), name=\"cpl\")\n",
    "    # [ha, hb, hc, hd, hw, mh]\n",
    "\n",
    "    cpl_reduced = Dense(128, activation=config[\"activation\"])(cpl)\n",
    "    cpl_reduced = Dense(32, activation=config[\"activation\"])(cpl_reduced)\n",
    "\n",
    "    \n",
    "    x = Concatenate()([mh, spress, cpl_reduced])\n",
    "    for i in range(config[\"num_layers\"]):\n",
    "        x =  Dropout(config[\"dropout\"])(Dense(config[\"num_neurons\"], \n",
    "                                             activation=config[\"activation\"])(x))\n",
    "    outputs = Dense(config['output'], name=\"Temp\")(x)\n",
    "\n",
    "    model = Model(inputs=[mh, spress, cpl], outputs=outputs, name=\"T\")\n",
    "    model.compile(optimizer=\"adam\", loss='mae')\n",
    "\n",
    "    return model\n",
    "\n",
    "config = {'shape': 22,\n",
    "          'output': 72,\n",
    "          'dropout': np.random.choice([0.01, 0.1, 0.2, 0.5]),\n",
    "          'num_layers': np.random.choice([3, 4, 5, 10]),\n",
    "          'num_neurons': np.random.choice([16, 32, 64, 128]),\n",
    "          'activation': np.random.choice(['gelu', 'gelu', 'relu'])}\n",
    "\n",
    "model = build_cpl_model(config)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3081d9a-e65b-44d5-9c98-9558667c04ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DING\n"
     ]
    }
   ],
   "source": [
    "print(\"DING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b849f517-93eb-4370-bff5-0d7e79fc93cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/29 21:22:30 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/29 21:22:30 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 42s - loss: 10.4116 - val_loss: 11.0691 - 42s/epoch - 10ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 39s - loss: 5.7199 - val_loss: 12.9369 - 39s/epoch - 9ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 40s - loss: 5.5595 - val_loss: 11.1169 - 40s/epoch - 10ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 40s - loss: 5.4983 - val_loss: 11.3651 - 40s/epoch - 10ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 40s - loss: 5.4594 - val_loss: 10.9588 - 40s/epoch - 10ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 39s - loss: 5.4301 - val_loss: 11.8148 - 39s/epoch - 9ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 39s - loss: 5.4149 - val_loss: 12.2834 - 39s/epoch - 9ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 39s - loss: 5.3874 - val_loss: 11.8749 - 39s/epoch - 9ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 39s - loss: 5.3627 - val_loss: 10.7994 - 39s/epoch - 9ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 39s - loss: 5.3470 - val_loss: 11.1659 - 39s/epoch - 9ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 39s - loss: 4.7898 - val_loss: 10.8939 - 39s/epoch - 9ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 38s - loss: 4.5404 - val_loss: 11.7527 - 38s/epoch - 9ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 39s - loss: 4.4802 - val_loss: 11.9627 - 39s/epoch - 9ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 39s - loss: 4.4581 - val_loss: 11.3323 - 39s/epoch - 9ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 39s - loss: 4.4299 - val_loss: 10.7613 - 39s/epoch - 9ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 39s - loss: 4.4168 - val_loss: 11.6218 - 39s/epoch - 9ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 40s - loss: 4.3486 - val_loss: 11.8278 - 40s/epoch - 10ms/step\n",
      "Epoch 18/1000\n",
      "4208/4208 - 39s - loss: 4.2371 - val_loss: 11.3254 - 39s/epoch - 9ms/step\n",
      "Epoch 19/1000\n",
      "4208/4208 - 38s - loss: 4.2062 - val_loss: 11.3164 - 38s/epoch - 9ms/step\n",
      "Epoch 20/1000\n",
      "4208/4208 - 38s - loss: 4.1848 - val_loss: 11.1196 - 38s/epoch - 9ms/step\n",
      "Epoch 21/1000\n",
      "4208/4208 - 39s - loss: 4.1688 - val_loss: 11.2653 - 39s/epoch - 9ms/step\n",
      "Epoch 22/1000\n",
      "4208/4208 - 37s - loss: 4.1522 - val_loss: 11.0529 - 37s/epoch - 9ms/step\n",
      "Epoch 23/1000\n",
      "4208/4208 - 37s - loss: 4.1379 - val_loss: 10.5824 - 37s/epoch - 9ms/step\n",
      "Epoch 24/1000\n",
      "4208/4208 - 37s - loss: 4.1311 - val_loss: 10.4010 - 37s/epoch - 9ms/step\n",
      "Epoch 25/1000\n",
      "4208/4208 - 36s - loss: 4.0814 - val_loss: 10.6287 - 36s/epoch - 9ms/step\n",
      "Epoch 26/1000\n",
      "4208/4208 - 38s - loss: 4.0313 - val_loss: 10.8562 - 38s/epoch - 9ms/step\n",
      "Epoch 27/1000\n",
      "4208/4208 - 37s - loss: 3.9988 - val_loss: 11.2405 - 37s/epoch - 9ms/step\n",
      "Epoch 28/1000\n",
      "4208/4208 - 37s - loss: 3.9876 - val_loss: 11.1103 - 37s/epoch - 9ms/step\n",
      "Epoch 29/1000\n",
      "4208/4208 - 37s - loss: 3.9576 - val_loss: 11.2702 - 37s/epoch - 9ms/step\n",
      "Epoch 30/1000\n",
      "4208/4208 - 38s - loss: 3.9413 - val_loss: 10.7270 - 38s/epoch - 9ms/step\n",
      "Epoch 31/1000\n",
      "4208/4208 - 37s - loss: 3.9297 - val_loss: 11.0672 - 37s/epoch - 9ms/step\n",
      "Epoch 32/1000\n",
      "4208/4208 - 38s - loss: 3.9134 - val_loss: 10.7230 - 38s/epoch - 9ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpk83tqasl/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/29 21:43:28 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/data/jmackin1/miniconda/envs/tf-gpu/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n",
      "2024/09/29 21:47:22 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/29 21:47:22 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 41s - loss: 41.3448 - val_loss: 125.7879 - 41s/epoch - 10ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 39s - loss: 29.4242 - val_loss: 39.6043 - 39s/epoch - 9ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 39s - loss: 25.7225 - val_loss: 20.7280 - 39s/epoch - 9ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 39s - loss: 24.2978 - val_loss: 9.1737 - 39s/epoch - 9ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 38s - loss: 23.2602 - val_loss: 4.9920 - 38s/epoch - 9ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 39s - loss: 22.6110 - val_loss: 5.1496 - 39s/epoch - 9ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 39s - loss: 22.2069 - val_loss: 5.3050 - 39s/epoch - 9ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 39s - loss: 21.8106 - val_loss: 4.7001 - 39s/epoch - 9ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 38s - loss: 21.4243 - val_loss: 4.7359 - 38s/epoch - 9ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 38s - loss: 21.0456 - val_loss: 4.7257 - 38s/epoch - 9ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 39s - loss: 20.6490 - val_loss: 4.7039 - 39s/epoch - 9ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 39s - loss: 20.2656 - val_loss: 4.5922 - 39s/epoch - 9ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 39s - loss: 19.8750 - val_loss: 4.5856 - 39s/epoch - 9ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 39s - loss: 19.4920 - val_loss: 4.5165 - 39s/epoch - 9ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 39s - loss: 19.1084 - val_loss: 4.6368 - 39s/epoch - 9ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 39s - loss: 18.7078 - val_loss: 4.6073 - 39s/epoch - 9ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 40s - loss: 18.3323 - val_loss: 4.4670 - 40s/epoch - 10ms/step\n",
      "Epoch 18/1000\n",
      "4208/4208 - 39s - loss: 17.9407 - val_loss: 4.2585 - 39s/epoch - 9ms/step\n",
      "Epoch 19/1000\n",
      "4208/4208 - 39s - loss: 17.5444 - val_loss: 4.3769 - 39s/epoch - 9ms/step\n",
      "Epoch 20/1000\n",
      "4208/4208 - 39s - loss: 17.1559 - val_loss: 4.4335 - 39s/epoch - 9ms/step\n",
      "Epoch 21/1000\n",
      "4208/4208 - 39s - loss: 16.7703 - val_loss: 4.3310 - 39s/epoch - 9ms/step\n",
      "Epoch 22/1000\n",
      "4208/4208 - 39s - loss: 16.3859 - val_loss: 4.2297 - 39s/epoch - 9ms/step\n",
      "Epoch 23/1000\n",
      "4208/4208 - 39s - loss: 16.0019 - val_loss: 4.1257 - 39s/epoch - 9ms/step\n",
      "Epoch 24/1000\n",
      "4208/4208 - 39s - loss: 15.6204 - val_loss: 4.1247 - 39s/epoch - 9ms/step\n",
      "Epoch 25/1000\n",
      "4208/4208 - 39s - loss: 15.2355 - val_loss: 4.0750 - 39s/epoch - 9ms/step\n",
      "Epoch 26/1000\n",
      "4208/4208 - 39s - loss: 14.8467 - val_loss: 4.0191 - 39s/epoch - 9ms/step\n",
      "Epoch 27/1000\n",
      "4208/4208 - 38s - loss: 14.4577 - val_loss: 4.0223 - 38s/epoch - 9ms/step\n",
      "Epoch 28/1000\n",
      "4208/4208 - 38s - loss: 14.0704 - val_loss: 3.7932 - 38s/epoch - 9ms/step\n",
      "Epoch 29/1000\n",
      "4208/4208 - 38s - loss: 13.6965 - val_loss: 3.9405 - 38s/epoch - 9ms/step\n",
      "Epoch 30/1000\n",
      "4208/4208 - 38s - loss: 13.3130 - val_loss: 3.7787 - 38s/epoch - 9ms/step\n",
      "Epoch 31/1000\n",
      "4208/4208 - 39s - loss: 12.9203 - val_loss: 3.8389 - 39s/epoch - 9ms/step\n",
      "Epoch 32/1000\n",
      "4208/4208 - 39s - loss: 12.5439 - val_loss: 3.6195 - 39s/epoch - 9ms/step\n",
      "Epoch 33/1000\n",
      "4208/4208 - 38s - loss: 12.1634 - val_loss: 3.6499 - 38s/epoch - 9ms/step\n",
      "Epoch 34/1000\n",
      "4208/4208 - 39s - loss: 11.7814 - val_loss: 3.5853 - 39s/epoch - 9ms/step\n",
      "Epoch 35/1000\n",
      "4208/4208 - 39s - loss: 11.4059 - val_loss: 3.5050 - 39s/epoch - 9ms/step\n",
      "Epoch 36/1000\n",
      "4208/4208 - 39s - loss: 11.0255 - val_loss: 3.5277 - 39s/epoch - 9ms/step\n",
      "Epoch 37/1000\n",
      "4208/4208 - 39s - loss: 10.6489 - val_loss: 3.4771 - 39s/epoch - 9ms/step\n",
      "Epoch 38/1000\n",
      "4208/4208 - 39s - loss: 10.2684 - val_loss: 3.3202 - 39s/epoch - 9ms/step\n",
      "Epoch 39/1000\n",
      "4208/4208 - 38s - loss: 9.9019 - val_loss: 3.3456 - 38s/epoch - 9ms/step\n",
      "Epoch 40/1000\n",
      "4208/4208 - 39s - loss: 9.5258 - val_loss: 3.3565 - 39s/epoch - 9ms/step\n",
      "Epoch 41/1000\n",
      "4208/4208 - 39s - loss: 9.1606 - val_loss: 3.2879 - 39s/epoch - 9ms/step\n",
      "Epoch 42/1000\n",
      "4208/4208 - 39s - loss: 8.7926 - val_loss: 3.2134 - 39s/epoch - 9ms/step\n",
      "Epoch 43/1000\n",
      "4208/4208 - 39s - loss: 8.4307 - val_loss: 3.1737 - 39s/epoch - 9ms/step\n",
      "Epoch 44/1000\n",
      "4208/4208 - 39s - loss: 8.0693 - val_loss: 3.1185 - 39s/epoch - 9ms/step\n",
      "Epoch 45/1000\n",
      "4208/4208 - 39s - loss: 7.7117 - val_loss: 3.0847 - 39s/epoch - 9ms/step\n",
      "Epoch 46/1000\n",
      "4208/4208 - 39s - loss: 7.3390 - val_loss: 3.0906 - 39s/epoch - 9ms/step\n",
      "Epoch 47/1000\n",
      "4208/4208 - 39s - loss: 6.9661 - val_loss: 3.0414 - 39s/epoch - 9ms/step\n",
      "Epoch 48/1000\n",
      "4208/4208 - 39s - loss: 6.6160 - val_loss: 2.9390 - 39s/epoch - 9ms/step\n",
      "Epoch 49/1000\n",
      "4208/4208 - 39s - loss: 6.2808 - val_loss: 3.1090 - 39s/epoch - 9ms/step\n",
      "Epoch 50/1000\n",
      "4208/4208 - 39s - loss: 5.9565 - val_loss: 2.9377 - 39s/epoch - 9ms/step\n",
      "Epoch 51/1000\n",
      "4208/4208 - 39s - loss: 5.6440 - val_loss: 2.8661 - 39s/epoch - 9ms/step\n",
      "Epoch 52/1000\n",
      "4208/4208 - 39s - loss: 5.3519 - val_loss: 2.8903 - 39s/epoch - 9ms/step\n",
      "Epoch 53/1000\n",
      "4208/4208 - 39s - loss: 5.0717 - val_loss: 2.8469 - 39s/epoch - 9ms/step\n",
      "Epoch 54/1000\n",
      "4208/4208 - 38s - loss: 4.8101 - val_loss: 2.8617 - 38s/epoch - 9ms/step\n",
      "Epoch 55/1000\n",
      "4208/4208 - 39s - loss: 4.5622 - val_loss: 2.7927 - 39s/epoch - 9ms/step\n",
      "Epoch 56/1000\n",
      "4208/4208 - 39s - loss: 4.3296 - val_loss: 2.7796 - 39s/epoch - 9ms/step\n",
      "Epoch 57/1000\n",
      "4208/4208 - 38s - loss: 4.1110 - val_loss: 2.8255 - 38s/epoch - 9ms/step\n",
      "Epoch 58/1000\n",
      "4208/4208 - 39s - loss: 3.9072 - val_loss: 2.6659 - 39s/epoch - 9ms/step\n",
      "Epoch 59/1000\n",
      "4208/4208 - 39s - loss: 3.7165 - val_loss: 2.6352 - 39s/epoch - 9ms/step\n",
      "Epoch 60/1000\n",
      "4208/4208 - 38s - loss: 3.5360 - val_loss: 2.6501 - 38s/epoch - 9ms/step\n",
      "Epoch 61/1000\n",
      "4208/4208 - 39s - loss: 3.3692 - val_loss: 2.5228 - 39s/epoch - 9ms/step\n",
      "Epoch 62/1000\n",
      "4208/4208 - 39s - loss: 3.2134 - val_loss: 2.5279 - 39s/epoch - 9ms/step\n",
      "Epoch 63/1000\n",
      "4208/4208 - 39s - loss: 3.0682 - val_loss: 2.4960 - 39s/epoch - 9ms/step\n",
      "Epoch 64/1000\n",
      "4208/4208 - 39s - loss: 2.9261 - val_loss: 2.3667 - 39s/epoch - 9ms/step\n",
      "Epoch 65/1000\n",
      "4208/4208 - 39s - loss: 2.7853 - val_loss: 2.2864 - 39s/epoch - 9ms/step\n",
      "Epoch 66/1000\n",
      "4208/4208 - 39s - loss: 2.6569 - val_loss: 2.2244 - 39s/epoch - 9ms/step\n",
      "Epoch 67/1000\n",
      "4208/4208 - 39s - loss: 2.5423 - val_loss: 2.1737 - 39s/epoch - 9ms/step\n",
      "Epoch 68/1000\n",
      "4208/4208 - 39s - loss: 2.4459 - val_loss: 2.1693 - 39s/epoch - 9ms/step\n",
      "Epoch 69/1000\n",
      "4208/4208 - 39s - loss: 2.3653 - val_loss: 2.1395 - 39s/epoch - 9ms/step\n",
      "Epoch 70/1000\n",
      "4208/4208 - 38s - loss: 2.3021 - val_loss: 2.1370 - 38s/epoch - 9ms/step\n",
      "Epoch 71/1000\n",
      "4208/4208 - 39s - loss: 2.2547 - val_loss: 2.1136 - 39s/epoch - 9ms/step\n",
      "Epoch 72/1000\n",
      "4208/4208 - 39s - loss: 2.2307 - val_loss: 2.0940 - 39s/epoch - 9ms/step\n",
      "Epoch 73/1000\n",
      "4208/4208 - 38s - loss: 2.2169 - val_loss: 2.0806 - 38s/epoch - 9ms/step\n",
      "Epoch 74/1000\n",
      "4208/4208 - 37s - loss: 2.2101 - val_loss: 2.0845 - 37s/epoch - 9ms/step\n",
      "Epoch 75/1000\n",
      "4208/4208 - 38s - loss: 2.2012 - val_loss: 2.0642 - 38s/epoch - 9ms/step\n",
      "Epoch 76/1000\n",
      "4208/4208 - 38s - loss: 2.1887 - val_loss: 2.0656 - 38s/epoch - 9ms/step\n",
      "Epoch 77/1000\n",
      "4208/4208 - 38s - loss: 2.1844 - val_loss: 2.0588 - 38s/epoch - 9ms/step\n",
      "Epoch 78/1000\n",
      "4208/4208 - 39s - loss: 2.1835 - val_loss: 2.0723 - 39s/epoch - 9ms/step\n",
      "Epoch 79/1000\n",
      "4208/4208 - 38s - loss: 2.1770 - val_loss: 2.0711 - 38s/epoch - 9ms/step\n",
      "Epoch 80/1000\n",
      "4208/4208 - 39s - loss: 2.1717 - val_loss: 2.0571 - 39s/epoch - 9ms/step\n",
      "Epoch 81/1000\n",
      "4208/4208 - 39s - loss: 2.1645 - val_loss: 2.0582 - 39s/epoch - 9ms/step\n",
      "Epoch 82/1000\n",
      "4208/4208 - 39s - loss: 2.1631 - val_loss: 2.0446 - 39s/epoch - 9ms/step\n",
      "Epoch 83/1000\n",
      "4208/4208 - 39s - loss: 2.1658 - val_loss: 2.0396 - 39s/epoch - 9ms/step\n",
      "Epoch 84/1000\n",
      "4208/4208 - 39s - loss: 2.1602 - val_loss: 2.0455 - 39s/epoch - 9ms/step\n",
      "Epoch 85/1000\n",
      "4208/4208 - 39s - loss: 2.1500 - val_loss: 2.0428 - 39s/epoch - 9ms/step\n",
      "Epoch 86/1000\n",
      "4208/4208 - 39s - loss: 2.1476 - val_loss: 2.0435 - 39s/epoch - 9ms/step\n",
      "Epoch 87/1000\n",
      "4208/4208 - 39s - loss: 2.1459 - val_loss: 2.0376 - 39s/epoch - 9ms/step\n",
      "Epoch 88/1000\n",
      "4208/4208 - 39s - loss: 2.1577 - val_loss: 2.0527 - 39s/epoch - 9ms/step\n",
      "Epoch 89/1000\n",
      "4208/4208 - 39s - loss: 2.1469 - val_loss: 2.0366 - 39s/epoch - 9ms/step\n",
      "Epoch 90/1000\n",
      "4208/4208 - 38s - loss: 2.1506 - val_loss: 2.0417 - 38s/epoch - 9ms/step\n",
      "Epoch 91/1000\n",
      "4208/4208 - 39s - loss: 2.1738 - val_loss: 2.0421 - 39s/epoch - 9ms/step\n",
      "Epoch 92/1000\n",
      "4208/4208 - 38s - loss: 2.1493 - val_loss: 2.0382 - 38s/epoch - 9ms/step\n",
      "Epoch 93/1000\n",
      "4208/4208 - 39s - loss: 2.1458 - val_loss: 2.0331 - 39s/epoch - 9ms/step\n",
      "Epoch 94/1000\n",
      "4208/4208 - 39s - loss: 3.4178 - val_loss: 2.3571 - 39s/epoch - 9ms/step\n",
      "Epoch 95/1000\n",
      "4208/4208 - 39s - loss: 2.2363 - val_loss: 2.0755 - 39s/epoch - 9ms/step\n",
      "Epoch 96/1000\n",
      "4208/4208 - 39s - loss: 2.1711 - val_loss: 2.0421 - 39s/epoch - 9ms/step\n",
      "Epoch 97/1000\n",
      "4208/4208 - 39s - loss: 2.1511 - val_loss: 2.0289 - 39s/epoch - 9ms/step\n",
      "Epoch 98/1000\n",
      "4208/4208 - 39s - loss: 2.1619 - val_loss: 2.0302 - 39s/epoch - 9ms/step\n",
      "Epoch 99/1000\n",
      "4208/4208 - 39s - loss: 2.1438 - val_loss: 2.0317 - 39s/epoch - 9ms/step\n",
      "Epoch 100/1000\n",
      "4208/4208 - 39s - loss: 2.1347 - val_loss: 2.0268 - 39s/epoch - 9ms/step\n",
      "Epoch 101/1000\n",
      "4208/4208 - 39s - loss: 2.1765 - val_loss: 2.0316 - 39s/epoch - 9ms/step\n",
      "Epoch 102/1000\n",
      "4208/4208 - 39s - loss: 2.1466 - val_loss: 2.0325 - 39s/epoch - 9ms/step\n",
      "Epoch 103/1000\n",
      "4208/4208 - 39s - loss: 2.1353 - val_loss: 2.0228 - 39s/epoch - 9ms/step\n",
      "Epoch 104/1000\n",
      "4208/4208 - 39s - loss: 2.1285 - val_loss: 2.0248 - 39s/epoch - 9ms/step\n",
      "Epoch 105/1000\n",
      "4208/4208 - 38s - loss: 2.1266 - val_loss: 2.0206 - 38s/epoch - 9ms/step\n",
      "Epoch 106/1000\n",
      "4208/4208 - 38s - loss: 2.1220 - val_loss: 2.0261 - 38s/epoch - 9ms/step\n",
      "Epoch 107/1000\n",
      "4208/4208 - 38s - loss: 2.1178 - val_loss: 2.0235 - 38s/epoch - 9ms/step\n",
      "Epoch 108/1000\n",
      "4208/4208 - 38s - loss: 2.1157 - val_loss: 2.0224 - 38s/epoch - 9ms/step\n",
      "Epoch 109/1000\n",
      "4208/4208 - 38s - loss: 2.1142 - val_loss: 2.0219 - 38s/epoch - 9ms/step\n",
      "Epoch 110/1000\n",
      "4208/4208 - 38s - loss: 2.1139 - val_loss: 2.0185 - 38s/epoch - 9ms/step\n",
      "Epoch 111/1000\n",
      "4208/4208 - 38s - loss: 2.1123 - val_loss: 2.0188 - 38s/epoch - 9ms/step\n",
      "Epoch 112/1000\n",
      "4208/4208 - 38s - loss: 2.1116 - val_loss: 2.0159 - 38s/epoch - 9ms/step\n",
      "Epoch 113/1000\n",
      "4208/4208 - 38s - loss: 2.1119 - val_loss: 2.0198 - 38s/epoch - 9ms/step\n",
      "Epoch 114/1000\n",
      "4208/4208 - 38s - loss: 2.1114 - val_loss: 2.0127 - 38s/epoch - 9ms/step\n",
      "Epoch 115/1000\n",
      "4208/4208 - 38s - loss: 2.1087 - val_loss: 2.0244 - 38s/epoch - 9ms/step\n",
      "Epoch 116/1000\n",
      "4208/4208 - 38s - loss: 2.1092 - val_loss: 2.0270 - 38s/epoch - 9ms/step\n",
      "Epoch 117/1000\n",
      "4208/4208 - 38s - loss: 2.1081 - val_loss: 2.0105 - 38s/epoch - 9ms/step\n",
      "Epoch 118/1000\n",
      "4208/4208 - 38s - loss: 2.1073 - val_loss: 2.0086 - 38s/epoch - 9ms/step\n",
      "Epoch 119/1000\n",
      "4208/4208 - 38s - loss: 2.1084 - val_loss: 2.0134 - 38s/epoch - 9ms/step\n",
      "Epoch 120/1000\n",
      "4208/4208 - 38s - loss: 2.1099 - val_loss: 2.0132 - 38s/epoch - 9ms/step\n",
      "Epoch 121/1000\n",
      "4208/4208 - 38s - loss: 2.1069 - val_loss: 2.0168 - 38s/epoch - 9ms/step\n",
      "Epoch 122/1000\n",
      "4208/4208 - 38s - loss: 2.1072 - val_loss: 2.0135 - 38s/epoch - 9ms/step\n",
      "Epoch 123/1000\n",
      "4208/4208 - 39s - loss: 2.1074 - val_loss: 2.0092 - 39s/epoch - 9ms/step\n",
      "Epoch 124/1000\n",
      "4208/4208 - 38s - loss: 2.1062 - val_loss: 2.0056 - 38s/epoch - 9ms/step\n",
      "Epoch 125/1000\n",
      "4208/4208 - 39s - loss: 2.1095 - val_loss: 2.0018 - 39s/epoch - 9ms/step\n",
      "Epoch 126/1000\n",
      "4208/4208 - 38s - loss: 2.1055 - val_loss: 2.0101 - 38s/epoch - 9ms/step\n",
      "Epoch 127/1000\n",
      "4208/4208 - 38s - loss: 2.1052 - val_loss: 2.0112 - 38s/epoch - 9ms/step\n",
      "Epoch 128/1000\n",
      "4208/4208 - 38s - loss: 2.1060 - val_loss: 2.0127 - 38s/epoch - 9ms/step\n",
      "Epoch 129/1000\n",
      "4208/4208 - 39s - loss: 2.1060 - val_loss: 2.0069 - 39s/epoch - 9ms/step\n",
      "Epoch 130/1000\n",
      "4208/4208 - 39s - loss: 2.1081 - val_loss: 2.0026 - 39s/epoch - 9ms/step\n",
      "Epoch 131/1000\n",
      "4208/4208 - 39s - loss: 2.1046 - val_loss: 2.0114 - 39s/epoch - 9ms/step\n",
      "Epoch 132/1000\n",
      "4208/4208 - 38s - loss: 2.1070 - val_loss: 2.0173 - 38s/epoch - 9ms/step\n",
      "Epoch 133/1000\n",
      "4208/4208 - 39s - loss: 2.1078 - val_loss: 2.0210 - 39s/epoch - 9ms/step\n",
      "1/1 [==============================] - 0s 182ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpds5wyatn/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/29 23:17:13 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/29 23:17:13 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 35s - loss: 39.9621 - val_loss: 114.6266 - 35s/epoch - 8ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 33s - loss: 30.7129 - val_loss: 93.4731 - 33s/epoch - 8ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 33s - loss: 27.8448 - val_loss: 26.9584 - 33s/epoch - 8ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 33s - loss: 24.2887 - val_loss: 5.8109 - 33s/epoch - 8ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 33s - loss: 23.0516 - val_loss: 4.8242 - 33s/epoch - 8ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 32s - loss: 22.6123 - val_loss: 4.7741 - 32s/epoch - 8ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 33s - loss: 22.1973 - val_loss: 5.1935 - 33s/epoch - 8ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 32s - loss: 21.8082 - val_loss: 5.1302 - 32s/epoch - 8ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 33s - loss: 21.4226 - val_loss: 5.4058 - 33s/epoch - 8ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 33s - loss: 21.0389 - val_loss: 4.8968 - 33s/epoch - 8ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 33s - loss: 20.6508 - val_loss: 4.9655 - 33s/epoch - 8ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 33s - loss: 20.2684 - val_loss: 5.0149 - 33s/epoch - 8ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 32s - loss: 19.8740 - val_loss: 4.9871 - 32s/epoch - 8ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 32s - loss: 19.4957 - val_loss: 4.8024 - 32s/epoch - 8ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmplajqvo_y/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/29 23:28:55 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/29 23:28:55 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 39s - loss: 26.2563 - val_loss: 3.5926 - 39s/epoch - 9ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 38s - loss: 17.2729 - val_loss: 3.4967 - 38s/epoch - 9ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 37s - loss: 15.0193 - val_loss: 3.4558 - 37s/epoch - 9ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 37s - loss: 13.8045 - val_loss: 3.1626 - 37s/epoch - 9ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 37s - loss: 12.8441 - val_loss: 3.1476 - 37s/epoch - 9ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 37s - loss: 12.1906 - val_loss: 3.0277 - 37s/epoch - 9ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 37s - loss: 11.8025 - val_loss: 2.9550 - 37s/epoch - 9ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 36s - loss: 11.5431 - val_loss: 2.9225 - 36s/epoch - 9ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 37s - loss: 11.3353 - val_loss: 2.8002 - 37s/epoch - 9ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 37s - loss: 11.1488 - val_loss: 2.7206 - 37s/epoch - 9ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 37s - loss: 10.9662 - val_loss: 2.7072 - 37s/epoch - 9ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 37s - loss: 10.7866 - val_loss: 2.6278 - 37s/epoch - 9ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 37s - loss: 10.6111 - val_loss: 2.7728 - 37s/epoch - 9ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 38s - loss: 10.4340 - val_loss: 2.5814 - 38s/epoch - 9ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 38s - loss: 10.2530 - val_loss: 2.8276 - 38s/epoch - 9ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 38s - loss: 10.0769 - val_loss: 2.7060 - 38s/epoch - 9ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 38s - loss: 9.9003 - val_loss: 2.7013 - 38s/epoch - 9ms/step\n",
      "Epoch 18/1000\n",
      "4208/4208 - 37s - loss: 9.7235 - val_loss: 2.6496 - 37s/epoch - 9ms/step\n",
      "Epoch 19/1000\n",
      "4208/4208 - 37s - loss: 9.5490 - val_loss: 2.6898 - 37s/epoch - 9ms/step\n",
      "Epoch 20/1000\n",
      "4208/4208 - 37s - loss: 9.3794 - val_loss: 2.6982 - 37s/epoch - 9ms/step\n",
      "Epoch 21/1000\n",
      "4208/4208 - 37s - loss: 9.2011 - val_loss: 2.4681 - 37s/epoch - 9ms/step\n",
      "Epoch 22/1000\n",
      "4208/4208 - 36s - loss: 9.0299 - val_loss: 2.6531 - 36s/epoch - 9ms/step\n",
      "Epoch 23/1000\n",
      "4208/4208 - 36s - loss: 8.8568 - val_loss: 2.6246 - 36s/epoch - 9ms/step\n",
      "Epoch 24/1000\n",
      "4208/4208 - 37s - loss: 8.6865 - val_loss: 2.5060 - 37s/epoch - 9ms/step\n",
      "Epoch 25/1000\n",
      "4208/4208 - 37s - loss: 8.5079 - val_loss: 2.5381 - 37s/epoch - 9ms/step\n",
      "Epoch 26/1000\n",
      "4208/4208 - 36s - loss: 8.3358 - val_loss: 2.2908 - 36s/epoch - 9ms/step\n",
      "Epoch 27/1000\n",
      "4208/4208 - 36s - loss: 8.1702 - val_loss: 2.4450 - 36s/epoch - 9ms/step\n",
      "Epoch 28/1000\n",
      "4208/4208 - 36s - loss: 7.9923 - val_loss: 2.5141 - 36s/epoch - 9ms/step\n",
      "Epoch 29/1000\n",
      "4208/4208 - 37s - loss: 7.8269 - val_loss: 2.3514 - 37s/epoch - 9ms/step\n",
      "Epoch 30/1000\n",
      "4208/4208 - 37s - loss: 7.6538 - val_loss: 2.4141 - 37s/epoch - 9ms/step\n",
      "Epoch 31/1000\n",
      "4208/4208 - 37s - loss: 7.4864 - val_loss: 2.3602 - 37s/epoch - 9ms/step\n",
      "Epoch 32/1000\n",
      "4208/4208 - 37s - loss: 7.3180 - val_loss: 2.4733 - 37s/epoch - 9ms/step\n",
      "Epoch 33/1000\n",
      "4208/4208 - 37s - loss: 7.1503 - val_loss: 2.3895 - 37s/epoch - 9ms/step\n",
      "Epoch 34/1000\n",
      "4208/4208 - 37s - loss: 6.9811 - val_loss: 2.3958 - 37s/epoch - 9ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp_he_78h6/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/29 23:54:09 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/29 23:54:09 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 37s - loss: 9.2054 - val_loss: 6.4516 - 37s/epoch - 9ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 35s - loss: 5.0963 - val_loss: 6.5234 - 35s/epoch - 8ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 35s - loss: 4.9308 - val_loss: 4.4344 - 35s/epoch - 8ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 35s - loss: 4.4447 - val_loss: 5.7357 - 35s/epoch - 8ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 34s - loss: 4.2841 - val_loss: 6.0052 - 34s/epoch - 8ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 34s - loss: 4.2234 - val_loss: 6.3104 - 34s/epoch - 8ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 35s - loss: 4.1871 - val_loss: 5.5892 - 35s/epoch - 8ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 34s - loss: 4.1605 - val_loss: 5.9087 - 34s/epoch - 8ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 34s - loss: 4.1244 - val_loss: 5.6129 - 34s/epoch - 8ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 34s - loss: 4.0745 - val_loss: 5.0913 - 34s/epoch - 8ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 35s - loss: 4.0170 - val_loss: 4.7629 - 35s/epoch - 8ms/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcb8d9745e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpjym03ihr/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/30 00:04:58 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/30 00:04:58 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 37s - loss: 7.9266 - val_loss: 10.6347 - 37s/epoch - 9ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 35s - loss: 4.9400 - val_loss: 6.8449 - 35s/epoch - 8ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 34s - loss: 4.5805 - val_loss: 9.9555 - 34s/epoch - 8ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 35s - loss: 3.8854 - val_loss: 9.0373 - 35s/epoch - 8ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 34s - loss: 3.7241 - val_loss: 7.5722 - 34s/epoch - 8ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 34s - loss: 3.6088 - val_loss: 7.5741 - 34s/epoch - 8ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 33s - loss: 3.5451 - val_loss: 7.0282 - 33s/epoch - 8ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 33s - loss: 3.5037 - val_loss: 7.1040 - 33s/epoch - 8ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 34s - loss: 3.4567 - val_loss: 6.1306 - 34s/epoch - 8ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 34s - loss: 3.3237 - val_loss: 5.7653 - 34s/epoch - 8ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 34s - loss: 3.2592 - val_loss: 6.9366 - 34s/epoch - 8ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 33s - loss: 3.2240 - val_loss: 6.8312 - 33s/epoch - 8ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 33s - loss: 3.1961 - val_loss: 7.3925 - 33s/epoch - 8ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 34s - loss: 3.1264 - val_loss: 5.9602 - 34s/epoch - 8ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 33s - loss: 3.0448 - val_loss: 6.3266 - 33s/epoch - 8ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 34s - loss: 3.0101 - val_loss: 5.4853 - 34s/epoch - 8ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 33s - loss: 2.9772 - val_loss: 6.0462 - 33s/epoch - 8ms/step\n",
      "Epoch 18/1000\n",
      "4208/4208 - 33s - loss: 2.9218 - val_loss: 5.6561 - 33s/epoch - 8ms/step\n",
      "Epoch 19/1000\n",
      "4208/4208 - 34s - loss: 2.8759 - val_loss: 6.8524 - 34s/epoch - 8ms/step\n",
      "Epoch 20/1000\n",
      "4208/4208 - 35s - loss: 2.8527 - val_loss: 5.0230 - 35s/epoch - 8ms/step\n",
      "Epoch 21/1000\n",
      "4208/4208 - 34s - loss: 2.8160 - val_loss: 5.7116 - 34s/epoch - 8ms/step\n",
      "Epoch 22/1000\n",
      "4208/4208 - 34s - loss: 2.7875 - val_loss: 5.0247 - 34s/epoch - 8ms/step\n",
      "Epoch 23/1000\n",
      "4208/4208 - 34s - loss: 2.7706 - val_loss: 5.4837 - 34s/epoch - 8ms/step\n",
      "Epoch 24/1000\n",
      "4208/4208 - 33s - loss: 2.7557 - val_loss: 5.2896 - 33s/epoch - 8ms/step\n",
      "Epoch 25/1000\n",
      "4208/4208 - 34s - loss: 2.7346 - val_loss: 5.0981 - 34s/epoch - 8ms/step\n",
      "Epoch 26/1000\n",
      "4208/4208 - 33s - loss: 2.7178 - val_loss: 5.8222 - 33s/epoch - 8ms/step\n",
      "Epoch 27/1000\n",
      "4208/4208 - 34s - loss: 2.7043 - val_loss: 4.7963 - 34s/epoch - 8ms/step\n",
      "Epoch 28/1000\n",
      "4208/4208 - 34s - loss: 2.6909 - val_loss: 4.2623 - 34s/epoch - 8ms/step\n",
      "Epoch 29/1000\n",
      "4208/4208 - 33s - loss: 2.6697 - val_loss: 4.5377 - 33s/epoch - 8ms/step\n",
      "Epoch 30/1000\n",
      "4208/4208 - 34s - loss: 2.6451 - val_loss: 5.2566 - 34s/epoch - 8ms/step\n",
      "Epoch 31/1000\n",
      "4208/4208 - 33s - loss: 2.6351 - val_loss: 5.1124 - 33s/epoch - 8ms/step\n",
      "Epoch 32/1000\n",
      "4208/4208 - 33s - loss: 2.6262 - val_loss: 5.4165 - 33s/epoch - 8ms/step\n",
      "Epoch 33/1000\n",
      "4208/4208 - 33s - loss: 2.6171 - val_loss: 4.8477 - 33s/epoch - 8ms/step\n",
      "Epoch 34/1000\n",
      "4208/4208 - 33s - loss: 2.6099 - val_loss: 5.3141 - 33s/epoch - 8ms/step\n",
      "Epoch 35/1000\n",
      "4208/4208 - 33s - loss: 2.6027 - val_loss: 4.5268 - 33s/epoch - 8ms/step\n",
      "Epoch 36/1000\n",
      "4208/4208 - 33s - loss: 2.5970 - val_loss: 5.2645 - 33s/epoch - 8ms/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcb8ce204c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpr9b0x0m5/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/30 00:28:55 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/30 00:28:55 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 41s - loss: 28.9425 - val_loss: 4.5347 - 41s/epoch - 10ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 40s - loss: 19.2116 - val_loss: 3.6235 - 40s/epoch - 9ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 39s - loss: 17.7498 - val_loss: 3.5304 - 39s/epoch - 9ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 39s - loss: 17.1074 - val_loss: 3.6208 - 39s/epoch - 9ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 39s - loss: 16.7468 - val_loss: 3.3650 - 39s/epoch - 9ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 38s - loss: 16.4584 - val_loss: 3.5458 - 38s/epoch - 9ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 39s - loss: 16.1797 - val_loss: 3.4103 - 39s/epoch - 9ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 39s - loss: 15.9156 - val_loss: 3.0796 - 39s/epoch - 9ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 39s - loss: 15.6433 - val_loss: 3.2952 - 39s/epoch - 9ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 39s - loss: 15.3739 - val_loss: 3.4572 - 39s/epoch - 9ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 39s - loss: 15.0991 - val_loss: 3.4774 - 39s/epoch - 9ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 39s - loss: 14.8252 - val_loss: 3.3123 - 39s/epoch - 9ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 39s - loss: 14.5511 - val_loss: 3.2351 - 39s/epoch - 9ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 39s - loss: 14.2852 - val_loss: 3.2055 - 39s/epoch - 9ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 39s - loss: 14.0131 - val_loss: 3.1345 - 39s/epoch - 9ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 39s - loss: 13.7499 - val_loss: 3.1842 - 39s/epoch - 9ms/step\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp9gq0aogc/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/30 00:43:43 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/30 00:43:43 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 36s - loss: 41.1497 - val_loss: 131.0687 - 36s/epoch - 9ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 35s - loss: 30.4099 - val_loss: 58.2024 - 35s/epoch - 8ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 35s - loss: 26.1957 - val_loss: 20.5414 - 35s/epoch - 8ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 34s - loss: 24.2500 - val_loss: 5.4721 - 34s/epoch - 8ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 34s - loss: 23.0105 - val_loss: 5.2120 - 34s/epoch - 8ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 34s - loss: 22.5894 - val_loss: 5.0739 - 34s/epoch - 8ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 34s - loss: 22.1951 - val_loss: 5.1659 - 34s/epoch - 8ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 34s - loss: 21.8087 - val_loss: 5.1387 - 34s/epoch - 8ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 34s - loss: 21.4193 - val_loss: 4.8747 - 34s/epoch - 8ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 34s - loss: 21.0300 - val_loss: 4.9113 - 34s/epoch - 8ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 34s - loss: 20.6469 - val_loss: 4.9651 - 34s/epoch - 8ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 34s - loss: 20.2581 - val_loss: 4.9777 - 34s/epoch - 8ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 34s - loss: 19.8646 - val_loss: 4.6936 - 34s/epoch - 8ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 35s - loss: 19.4939 - val_loss: 4.9343 - 35s/epoch - 8ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 35s - loss: 19.0886 - val_loss: 4.7921 - 35s/epoch - 8ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 35s - loss: 18.7197 - val_loss: 4.5314 - 35s/epoch - 8ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 35s - loss: 18.3196 - val_loss: 4.5950 - 35s/epoch - 8ms/step\n",
      "Epoch 18/1000\n",
      "4208/4208 - 35s - loss: 17.9457 - val_loss: 4.5254 - 35s/epoch - 8ms/step\n",
      "Epoch 19/1000\n",
      "4208/4208 - 34s - loss: 17.5463 - val_loss: 4.6497 - 34s/epoch - 8ms/step\n",
      "Epoch 20/1000\n",
      "4208/4208 - 34s - loss: 17.1555 - val_loss: 4.6144 - 34s/epoch - 8ms/step\n",
      "Epoch 21/1000\n",
      "4208/4208 - 34s - loss: 16.7735 - val_loss: 4.5791 - 34s/epoch - 8ms/step\n",
      "Epoch 22/1000\n",
      "4208/4208 - 35s - loss: 16.3781 - val_loss: 4.4338 - 35s/epoch - 8ms/step\n",
      "Epoch 23/1000\n",
      "4208/4208 - 35s - loss: 15.9958 - val_loss: 4.5458 - 35s/epoch - 8ms/step\n",
      "Epoch 24/1000\n",
      "4208/4208 - 35s - loss: 15.6080 - val_loss: 4.3981 - 35s/epoch - 8ms/step\n",
      "Epoch 25/1000\n",
      "4208/4208 - 35s - loss: 15.2236 - val_loss: 4.3195 - 35s/epoch - 8ms/step\n",
      "Epoch 26/1000\n",
      "4208/4208 - 35s - loss: 14.8376 - val_loss: 4.4007 - 35s/epoch - 8ms/step\n",
      "Epoch 27/1000\n",
      "4208/4208 - 34s - loss: 14.4597 - val_loss: 4.3619 - 34s/epoch - 8ms/step\n",
      "Epoch 28/1000\n",
      "4208/4208 - 34s - loss: 14.0696 - val_loss: 4.1968 - 34s/epoch - 8ms/step\n",
      "Epoch 29/1000\n",
      "4208/4208 - 34s - loss: 13.6798 - val_loss: 4.2064 - 34s/epoch - 8ms/step\n",
      "Epoch 30/1000\n",
      "4208/4208 - 34s - loss: 13.3018 - val_loss: 4.1583 - 34s/epoch - 8ms/step\n",
      "Epoch 31/1000\n",
      "4208/4208 - 34s - loss: 12.9215 - val_loss: 4.0083 - 34s/epoch - 8ms/step\n",
      "Epoch 32/1000\n",
      "4208/4208 - 34s - loss: 12.5403 - val_loss: 4.1659 - 34s/epoch - 8ms/step\n",
      "Epoch 33/1000\n",
      "4208/4208 - 34s - loss: 12.1549 - val_loss: 4.0546 - 34s/epoch - 8ms/step\n",
      "Epoch 34/1000\n",
      "4208/4208 - 34s - loss: 11.7783 - val_loss: 3.9304 - 34s/epoch - 8ms/step\n",
      "Epoch 35/1000\n",
      "4208/4208 - 33s - loss: 11.3916 - val_loss: 3.7898 - 33s/epoch - 8ms/step\n",
      "Epoch 36/1000\n",
      "4208/4208 - 34s - loss: 11.0062 - val_loss: 3.9375 - 34s/epoch - 8ms/step\n",
      "Epoch 37/1000\n",
      "4208/4208 - 34s - loss: 10.6320 - val_loss: 3.7739 - 34s/epoch - 8ms/step\n",
      "Epoch 38/1000\n",
      "4208/4208 - 34s - loss: 10.2593 - val_loss: 3.7508 - 34s/epoch - 8ms/step\n",
      "Epoch 39/1000\n",
      "4208/4208 - 34s - loss: 9.8810 - val_loss: 3.6271 - 34s/epoch - 8ms/step\n",
      "Epoch 40/1000\n",
      "4208/4208 - 34s - loss: 9.5067 - val_loss: 3.6167 - 34s/epoch - 8ms/step\n",
      "Epoch 41/1000\n",
      "4208/4208 - 34s - loss: 9.1314 - val_loss: 3.6756 - 34s/epoch - 8ms/step\n",
      "Epoch 42/1000\n",
      "4208/4208 - 34s - loss: 8.7643 - val_loss: 3.5709 - 34s/epoch - 8ms/step\n",
      "Epoch 43/1000\n",
      "4208/4208 - 34s - loss: 8.3978 - val_loss: 3.5671 - 34s/epoch - 8ms/step\n",
      "Epoch 44/1000\n",
      "4208/4208 - 34s - loss: 8.0397 - val_loss: 3.6439 - 34s/epoch - 8ms/step\n",
      "Epoch 45/1000\n",
      "4208/4208 - 34s - loss: 7.6843 - val_loss: 3.4508 - 34s/epoch - 8ms/step\n",
      "Epoch 46/1000\n",
      "4208/4208 - 34s - loss: 7.3313 - val_loss: 3.4020 - 34s/epoch - 8ms/step\n",
      "Epoch 47/1000\n",
      "4208/4208 - 34s - loss: 6.9825 - val_loss: 3.4386 - 34s/epoch - 8ms/step\n",
      "Epoch 48/1000\n",
      "4208/4208 - 34s - loss: 6.6250 - val_loss: 3.3429 - 34s/epoch - 8ms/step\n",
      "Epoch 49/1000\n",
      "4208/4208 - 34s - loss: 6.2845 - val_loss: 3.3229 - 34s/epoch - 8ms/step\n",
      "Epoch 50/1000\n",
      "4208/4208 - 34s - loss: 5.9601 - val_loss: 3.2742 - 34s/epoch - 8ms/step\n",
      "Epoch 51/1000\n",
      "4208/4208 - 33s - loss: 5.6536 - val_loss: 3.2880 - 33s/epoch - 8ms/step\n",
      "Epoch 52/1000\n",
      "4208/4208 - 33s - loss: 5.3589 - val_loss: 3.1695 - 33s/epoch - 8ms/step\n",
      "Epoch 53/1000\n",
      "4208/4208 - 33s - loss: 5.0830 - val_loss: 3.1702 - 33s/epoch - 8ms/step\n",
      "Epoch 54/1000\n",
      "4208/4208 - 33s - loss: 4.8248 - val_loss: 3.2532 - 33s/epoch - 8ms/step\n",
      "Epoch 55/1000\n",
      "4208/4208 - 34s - loss: 4.5838 - val_loss: 3.1403 - 34s/epoch - 8ms/step\n",
      "Epoch 56/1000\n",
      "4208/4208 - 34s - loss: 4.3598 - val_loss: 3.0949 - 34s/epoch - 8ms/step\n",
      "Epoch 57/1000\n",
      "4208/4208 - 34s - loss: 4.1485 - val_loss: 3.1046 - 34s/epoch - 8ms/step\n",
      "Epoch 58/1000\n",
      "4208/4208 - 33s - loss: 3.9526 - val_loss: 3.0758 - 33s/epoch - 8ms/step\n",
      "Epoch 59/1000\n",
      "4208/4208 - 34s - loss: 3.7685 - val_loss: 3.0111 - 34s/epoch - 8ms/step\n",
      "Epoch 60/1000\n",
      "4208/4208 - 33s - loss: 3.5934 - val_loss: 2.9153 - 33s/epoch - 8ms/step\n",
      "Epoch 61/1000\n",
      "4208/4208 - 33s - loss: 3.4262 - val_loss: 2.9690 - 33s/epoch - 8ms/step\n",
      "Epoch 62/1000\n",
      "4208/4208 - 33s - loss: 3.2685 - val_loss: 2.8868 - 33s/epoch - 8ms/step\n",
      "Epoch 63/1000\n",
      "4208/4208 - 33s - loss: 3.1240 - val_loss: 2.9013 - 33s/epoch - 8ms/step\n",
      "Epoch 64/1000\n",
      "4208/4208 - 34s - loss: 2.9918 - val_loss: 2.8474 - 34s/epoch - 8ms/step\n",
      "Epoch 65/1000\n",
      "4208/4208 - 33s - loss: 2.8689 - val_loss: 2.8387 - 33s/epoch - 8ms/step\n",
      "Epoch 66/1000\n",
      "4208/4208 - 34s - loss: 2.7560 - val_loss: 2.7835 - 34s/epoch - 8ms/step\n",
      "Epoch 67/1000\n",
      "4208/4208 - 33s - loss: 2.6550 - val_loss: 2.7806 - 33s/epoch - 8ms/step\n",
      "Epoch 68/1000\n",
      "4208/4208 - 33s - loss: 2.5687 - val_loss: 2.7312 - 33s/epoch - 8ms/step\n",
      "Epoch 69/1000\n",
      "4208/4208 - 33s - loss: 2.4981 - val_loss: 2.7329 - 33s/epoch - 8ms/step\n",
      "Epoch 70/1000\n",
      "4208/4208 - 33s - loss: 2.4463 - val_loss: 2.7158 - 33s/epoch - 8ms/step\n",
      "Epoch 71/1000\n",
      "4208/4208 - 33s - loss: 2.4143 - val_loss: 2.7183 - 33s/epoch - 8ms/step\n",
      "Epoch 72/1000\n",
      "4208/4208 - 33s - loss: 2.3989 - val_loss: 2.6815 - 33s/epoch - 8ms/step\n",
      "Epoch 73/1000\n",
      "4208/4208 - 34s - loss: 2.3832 - val_loss: 2.6603 - 34s/epoch - 8ms/step\n",
      "Epoch 74/1000\n",
      "4208/4208 - 34s - loss: 2.3713 - val_loss: 2.6514 - 34s/epoch - 8ms/step\n",
      "Epoch 75/1000\n",
      "4208/4208 - 34s - loss: 2.3627 - val_loss: 2.6129 - 34s/epoch - 8ms/step\n",
      "Epoch 76/1000\n",
      "4208/4208 - 34s - loss: 2.3587 - val_loss: 2.5943 - 34s/epoch - 8ms/step\n",
      "Epoch 77/1000\n",
      "4208/4208 - 35s - loss: 2.3534 - val_loss: 2.5737 - 35s/epoch - 8ms/step\n",
      "Epoch 78/1000\n",
      "4208/4208 - 34s - loss: 2.3486 - val_loss: 2.6073 - 34s/epoch - 8ms/step\n",
      "Epoch 79/1000\n",
      "4208/4208 - 34s - loss: 2.3452 - val_loss: 2.5985 - 34s/epoch - 8ms/step\n",
      "Epoch 80/1000\n",
      "4208/4208 - 34s - loss: 2.3391 - val_loss: 2.5770 - 34s/epoch - 8ms/step\n",
      "Epoch 81/1000\n",
      "4208/4208 - 33s - loss: 2.3321 - val_loss: 2.6131 - 33s/epoch - 8ms/step\n",
      "Epoch 82/1000\n",
      "4208/4208 - 34s - loss: 2.3257 - val_loss: 2.6110 - 34s/epoch - 8ms/step\n",
      "Epoch 83/1000\n",
      "4208/4208 - 35s - loss: 2.3223 - val_loss: 2.6019 - 35s/epoch - 8ms/step\n",
      "Epoch 84/1000\n",
      "4208/4208 - 35s - loss: 2.3192 - val_loss: 2.6175 - 35s/epoch - 8ms/step\n",
      "Epoch 85/1000\n",
      "4208/4208 - 35s - loss: 2.3175 - val_loss: 2.6079 - 35s/epoch - 8ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp7aph3hm2/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/30 01:35:58 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/30 01:35:58 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 38s - loss: 18.9995 - val_loss: 4.8774 - 38s/epoch - 9ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 37s - loss: 11.8570 - val_loss: 5.7966 - 37s/epoch - 9ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 37s - loss: 10.4873 - val_loss: 7.7702 - 37s/epoch - 9ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 37s - loss: 9.7429 - val_loss: 3.6890 - 37s/epoch - 9ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 37s - loss: 9.0818 - val_loss: 2.6892 - 37s/epoch - 9ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 37s - loss: 8.6300 - val_loss: 2.6123 - 37s/epoch - 9ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 37s - loss: 8.3551 - val_loss: 2.3683 - 37s/epoch - 9ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 37s - loss: 8.1645 - val_loss: 2.6360 - 37s/epoch - 9ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 37s - loss: 8.0112 - val_loss: 2.4866 - 37s/epoch - 9ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 37s - loss: 7.8804 - val_loss: 2.3180 - 37s/epoch - 9ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 36s - loss: 7.7647 - val_loss: 2.2780 - 36s/epoch - 9ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 36s - loss: 7.6588 - val_loss: 2.2273 - 36s/epoch - 9ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 36s - loss: 7.5548 - val_loss: 2.1682 - 36s/epoch - 9ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 36s - loss: 7.4580 - val_loss: 2.2476 - 36s/epoch - 9ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 36s - loss: 7.3670 - val_loss: 2.2538 - 36s/epoch - 9ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 37s - loss: 7.2706 - val_loss: 2.3246 - 37s/epoch - 9ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 37s - loss: 7.1737 - val_loss: 2.2866 - 37s/epoch - 9ms/step\n",
      "Epoch 18/1000\n",
      "4208/4208 - 36s - loss: 7.0767 - val_loss: 2.2704 - 36s/epoch - 9ms/step\n",
      "Epoch 19/1000\n",
      "4208/4208 - 37s - loss: 6.9836 - val_loss: 2.0965 - 37s/epoch - 9ms/step\n",
      "Epoch 20/1000\n",
      "4208/4208 - 37s - loss: 6.8842 - val_loss: 2.1009 - 37s/epoch - 9ms/step\n",
      "Epoch 21/1000\n",
      "4208/4208 - 37s - loss: 6.7892 - val_loss: 2.0939 - 37s/epoch - 9ms/step\n",
      "Epoch 22/1000\n",
      "4208/4208 - 37s - loss: 6.6973 - val_loss: 2.0859 - 37s/epoch - 9ms/step\n",
      "Epoch 23/1000\n",
      "4208/4208 - 37s - loss: 6.6034 - val_loss: 2.0399 - 37s/epoch - 9ms/step\n",
      "Epoch 24/1000\n",
      "4208/4208 - 37s - loss: 6.5112 - val_loss: 2.0427 - 37s/epoch - 9ms/step\n",
      "Epoch 25/1000\n",
      "4208/4208 - 37s - loss: 6.4182 - val_loss: 2.0711 - 37s/epoch - 9ms/step\n",
      "Epoch 26/1000\n",
      "4208/4208 - 37s - loss: 6.3287 - val_loss: 2.1885 - 37s/epoch - 9ms/step\n",
      "Epoch 27/1000\n",
      "4208/4208 - 37s - loss: 6.2368 - val_loss: 2.1344 - 37s/epoch - 9ms/step\n",
      "Epoch 28/1000\n",
      "4208/4208 - 37s - loss: 6.1403 - val_loss: 2.0657 - 37s/epoch - 9ms/step\n",
      "Epoch 29/1000\n",
      "4208/4208 - 37s - loss: 6.0485 - val_loss: 2.0782 - 37s/epoch - 9ms/step\n",
      "Epoch 30/1000\n",
      "4208/4208 - 37s - loss: 5.9555 - val_loss: 2.0665 - 37s/epoch - 9ms/step\n",
      "Epoch 31/1000\n",
      "4208/4208 - 37s - loss: 5.8665 - val_loss: 1.9949 - 37s/epoch - 9ms/step\n",
      "Epoch 32/1000\n",
      "4208/4208 - 37s - loss: 5.7736 - val_loss: 1.8977 - 37s/epoch - 9ms/step\n",
      "Epoch 33/1000\n",
      "4208/4208 - 37s - loss: 5.6846 - val_loss: 2.0182 - 37s/epoch - 9ms/step\n",
      "Epoch 34/1000\n",
      "4208/4208 - 37s - loss: 5.5970 - val_loss: 1.9351 - 37s/epoch - 9ms/step\n",
      "Epoch 35/1000\n",
      "4208/4208 - 37s - loss: 5.4988 - val_loss: 1.8978 - 37s/epoch - 9ms/step\n",
      "Epoch 36/1000\n",
      "4208/4208 - 37s - loss: 5.4095 - val_loss: 1.9458 - 37s/epoch - 9ms/step\n",
      "Epoch 37/1000\n",
      "4208/4208 - 37s - loss: 5.3210 - val_loss: 1.9640 - 37s/epoch - 9ms/step\n",
      "Epoch 38/1000\n",
      "4208/4208 - 37s - loss: 5.2316 - val_loss: 2.1210 - 37s/epoch - 9ms/step\n",
      "Epoch 39/1000\n",
      "4208/4208 - 37s - loss: 5.1459 - val_loss: 1.9562 - 37s/epoch - 9ms/step\n",
      "Epoch 40/1000\n",
      "4208/4208 - 36s - loss: 5.0543 - val_loss: 1.9892 - 36s/epoch - 9ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpnyso8s2y/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/30 02:05:09 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/30 02:05:09 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 35s - loss: 13.4238 - val_loss: 39.6030 - 35s/epoch - 8ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 33s - loss: 8.1981 - val_loss: 28.9430 - 33s/epoch - 8ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 33s - loss: 7.2942 - val_loss: 16.7930 - 33s/epoch - 8ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 33s - loss: 6.9351 - val_loss: 13.2331 - 33s/epoch - 8ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 33s - loss: 6.7561 - val_loss: 11.3744 - 33s/epoch - 8ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 33s - loss: 6.6124 - val_loss: 10.6979 - 33s/epoch - 8ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 33s - loss: 6.5073 - val_loss: 8.7851 - 33s/epoch - 8ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 33s - loss: 6.4025 - val_loss: 6.4249 - 33s/epoch - 8ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 33s - loss: 6.3253 - val_loss: 5.7588 - 33s/epoch - 8ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 33s - loss: 6.2641 - val_loss: 4.7059 - 33s/epoch - 8ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 33s - loss: 6.2064 - val_loss: 3.5765 - 33s/epoch - 8ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 33s - loss: 6.1531 - val_loss: 3.2177 - 33s/epoch - 8ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 33s - loss: 6.1001 - val_loss: 2.6326 - 33s/epoch - 8ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 33s - loss: 6.0367 - val_loss: 2.8885 - 33s/epoch - 8ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 33s - loss: 5.9521 - val_loss: 2.1778 - 33s/epoch - 8ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 33s - loss: 5.8955 - val_loss: 2.4081 - 33s/epoch - 8ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 32s - loss: 5.8441 - val_loss: 2.2208 - 32s/epoch - 8ms/step\n",
      "Epoch 18/1000\n",
      "4208/4208 - 33s - loss: 5.7956 - val_loss: 2.5986 - 33s/epoch - 8ms/step\n",
      "Epoch 19/1000\n",
      "4208/4208 - 33s - loss: 5.7458 - val_loss: 2.0350 - 33s/epoch - 8ms/step\n",
      "Epoch 20/1000\n",
      "4208/4208 - 33s - loss: 5.6717 - val_loss: 2.2029 - 33s/epoch - 8ms/step\n",
      "Epoch 21/1000\n",
      "4208/4208 - 33s - loss: 5.6204 - val_loss: 2.1814 - 33s/epoch - 8ms/step\n",
      "Epoch 22/1000\n",
      "4208/4208 - 33s - loss: 5.5697 - val_loss: 2.0383 - 33s/epoch - 8ms/step\n",
      "Epoch 23/1000\n",
      "4208/4208 - 33s - loss: 5.5041 - val_loss: 2.0173 - 33s/epoch - 8ms/step\n",
      "Epoch 24/1000\n",
      "4208/4208 - 33s - loss: 5.4483 - val_loss: 2.0605 - 33s/epoch - 8ms/step\n",
      "Epoch 25/1000\n",
      "4208/4208 - 32s - loss: 5.3966 - val_loss: 1.8281 - 32s/epoch - 8ms/step\n",
      "Epoch 26/1000\n",
      "4208/4208 - 32s - loss: 5.3303 - val_loss: 1.8898 - 32s/epoch - 8ms/step\n",
      "Epoch 27/1000\n",
      "4208/4208 - 32s - loss: 5.2778 - val_loss: 2.0359 - 32s/epoch - 8ms/step\n",
      "Epoch 28/1000\n",
      "4208/4208 - 32s - loss: 5.2265 - val_loss: 1.9392 - 32s/epoch - 8ms/step\n",
      "Epoch 29/1000\n",
      "4208/4208 - 33s - loss: 5.1643 - val_loss: 2.0198 - 33s/epoch - 8ms/step\n",
      "Epoch 30/1000\n",
      "4208/4208 - 33s - loss: 5.1153 - val_loss: 1.8687 - 33s/epoch - 8ms/step\n",
      "Epoch 31/1000\n",
      "4208/4208 - 33s - loss: 5.0636 - val_loss: 1.9160 - 33s/epoch - 8ms/step\n",
      "Epoch 32/1000\n",
      "4208/4208 - 32s - loss: 5.0165 - val_loss: 1.9351 - 32s/epoch - 8ms/step\n",
      "Epoch 33/1000\n",
      "4208/4208 - 32s - loss: 4.9653 - val_loss: 1.9581 - 32s/epoch - 8ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp3bdmo0m9/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/30 02:27:08 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/30 02:27:08 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 41s - loss: 22.5757 - val_loss: 44.7170 - 41s/epoch - 10ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 40s - loss: 13.7022 - val_loss: 23.1450 - 40s/epoch - 9ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 40s - loss: 12.7738 - val_loss: 15.5827 - 40s/epoch - 9ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 39s - loss: 12.1794 - val_loss: 9.5210 - 39s/epoch - 9ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 40s - loss: 11.6406 - val_loss: 5.7967 - 40s/epoch - 9ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 40s - loss: 11.3512 - val_loss: 4.7990 - 40s/epoch - 9ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 39s - loss: 11.1480 - val_loss: 3.9299 - 39s/epoch - 9ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 40s - loss: 10.9762 - val_loss: 3.7825 - 40s/epoch - 9ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 40s - loss: 10.8039 - val_loss: 3.4709 - 40s/epoch - 9ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 39s - loss: 10.6370 - val_loss: 3.5110 - 39s/epoch - 9ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 40s - loss: 10.4809 - val_loss: 3.5428 - 40s/epoch - 9ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 40s - loss: 10.3215 - val_loss: 3.4302 - 40s/epoch - 9ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 39s - loss: 10.1599 - val_loss: 3.4459 - 39s/epoch - 9ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 40s - loss: 10.0000 - val_loss: 3.2767 - 40s/epoch - 9ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 39s - loss: 9.8475 - val_loss: 3.4820 - 39s/epoch - 9ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 39s - loss: 9.6885 - val_loss: 3.5053 - 39s/epoch - 9ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 40s - loss: 9.5283 - val_loss: 3.3662 - 40s/epoch - 9ms/step\n",
      "Epoch 18/1000\n",
      "4208/4208 - 39s - loss: 9.3728 - val_loss: 3.5793 - 39s/epoch - 9ms/step\n",
      "Epoch 19/1000\n",
      "4208/4208 - 39s - loss: 9.2136 - val_loss: 3.4778 - 39s/epoch - 9ms/step\n",
      "Epoch 20/1000\n",
      "4208/4208 - 39s - loss: 9.0586 - val_loss: 3.2892 - 39s/epoch - 9ms/step\n",
      "Epoch 21/1000\n",
      "4208/4208 - 38s - loss: 8.9038 - val_loss: 3.3185 - 38s/epoch - 9ms/step\n",
      "Epoch 22/1000\n",
      "4208/4208 - 38s - loss: 8.7459 - val_loss: 3.4062 - 38s/epoch - 9ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpawvh41x9/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/30 02:46:05 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/30 02:46:05 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 42s - loss: 24.1514 - val_loss: 4.1177 - 42s/epoch - 10ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 39s - loss: 15.7407 - val_loss: 3.7238 - 39s/epoch - 9ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 39s - loss: 13.7991 - val_loss: 3.0451 - 39s/epoch - 9ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 39s - loss: 13.0450 - val_loss: 3.2649 - 39s/epoch - 9ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 39s - loss: 12.5016 - val_loss: 3.0163 - 39s/epoch - 9ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 39s - loss: 12.0989 - val_loss: 2.8255 - 39s/epoch - 9ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 39s - loss: 11.8026 - val_loss: 3.0572 - 39s/epoch - 9ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 39s - loss: 11.5666 - val_loss: 2.8853 - 39s/epoch - 9ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 40s - loss: 11.3645 - val_loss: 2.9736 - 40s/epoch - 9ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 40s - loss: 11.1767 - val_loss: 2.7637 - 40s/epoch - 9ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 40s - loss: 10.9994 - val_loss: 2.7189 - 40s/epoch - 9ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 40s - loss: 10.8172 - val_loss: 2.7396 - 40s/epoch - 10ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 40s - loss: 10.6404 - val_loss: 2.5359 - 40s/epoch - 10ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 40s - loss: 10.4648 - val_loss: 2.6694 - 40s/epoch - 10ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 40s - loss: 10.2788 - val_loss: 2.7105 - 40s/epoch - 10ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 40s - loss: 10.1084 - val_loss: 2.6239 - 40s/epoch - 9ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 40s - loss: 9.9287 - val_loss: 2.8209 - 40s/epoch - 10ms/step\n",
      "Epoch 18/1000\n",
      "4208/4208 - 40s - loss: 9.7577 - val_loss: 2.8330 - 40s/epoch - 10ms/step\n",
      "Epoch 19/1000\n",
      "4208/4208 - 40s - loss: 9.5854 - val_loss: 2.6779 - 40s/epoch - 10ms/step\n",
      "Epoch 20/1000\n",
      "4208/4208 - 40s - loss: 9.4076 - val_loss: 2.5088 - 40s/epoch - 10ms/step\n",
      "Epoch 21/1000\n",
      "4208/4208 - 40s - loss: 9.2373 - val_loss: 2.5562 - 40s/epoch - 10ms/step\n",
      "Epoch 22/1000\n",
      "4208/4208 - 40s - loss: 9.0643 - val_loss: 2.4077 - 40s/epoch - 9ms/step\n",
      "Epoch 23/1000\n",
      "4208/4208 - 40s - loss: 8.8893 - val_loss: 2.7098 - 40s/epoch - 9ms/step\n",
      "Epoch 24/1000\n",
      "4208/4208 - 40s - loss: 8.7180 - val_loss: 2.5390 - 40s/epoch - 9ms/step\n",
      "Epoch 25/1000\n",
      "4208/4208 - 40s - loss: 8.5414 - val_loss: 2.4157 - 40s/epoch - 9ms/step\n",
      "Epoch 26/1000\n",
      "4208/4208 - 40s - loss: 8.3746 - val_loss: 2.5189 - 40s/epoch - 9ms/step\n",
      "Epoch 27/1000\n",
      "4208/4208 - 40s - loss: 8.2044 - val_loss: 2.5506 - 40s/epoch - 9ms/step\n",
      "Epoch 28/1000\n",
      "4208/4208 - 40s - loss: 8.0362 - val_loss: 2.4476 - 40s/epoch - 10ms/step\n",
      "Epoch 29/1000\n",
      "4208/4208 - 40s - loss: 7.8599 - val_loss: 2.5869 - 40s/epoch - 9ms/step\n",
      "Epoch 30/1000\n",
      "4208/4208 - 40s - loss: 7.6960 - val_loss: 2.4210 - 40s/epoch - 9ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpa3e5zrei/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/30 03:10:26 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/30 03:10:26 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 34s - loss: 20.2417 - val_loss: 63.4286 - 34s/epoch - 8ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 33s - loss: 13.8573 - val_loss: 59.1173 - 33s/epoch - 8ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 33s - loss: 13.3021 - val_loss: 53.0060 - 33s/epoch - 8ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 33s - loss: 12.8917 - val_loss: 46.1288 - 33s/epoch - 8ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 33s - loss: 12.5277 - val_loss: 36.9639 - 33s/epoch - 8ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 33s - loss: 12.1650 - val_loss: 22.2733 - 33s/epoch - 8ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 33s - loss: 11.8339 - val_loss: 16.1476 - 33s/epoch - 8ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 33s - loss: 11.5302 - val_loss: 10.5967 - 33s/epoch - 8ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 34s - loss: 11.2394 - val_loss: 6.0350 - 34s/epoch - 8ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 33s - loss: 10.9080 - val_loss: 3.6065 - 33s/epoch - 8ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 34s - loss: 10.6823 - val_loss: 2.9746 - 34s/epoch - 8ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 33s - loss: 10.4832 - val_loss: 3.1915 - 33s/epoch - 8ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 34s - loss: 10.3180 - val_loss: 3.3349 - 34s/epoch - 8ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 33s - loss: 10.1570 - val_loss: 2.8559 - 33s/epoch - 8ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 33s - loss: 9.9935 - val_loss: 3.1809 - 33s/epoch - 8ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 33s - loss: 9.8370 - val_loss: 3.0410 - 33s/epoch - 8ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 33s - loss: 9.6767 - val_loss: 3.0159 - 33s/epoch - 8ms/step\n",
      "Epoch 18/1000\n",
      "4208/4208 - 33s - loss: 9.5205 - val_loss: 3.1992 - 33s/epoch - 8ms/step\n",
      "Epoch 19/1000\n",
      "4208/4208 - 33s - loss: 9.3601 - val_loss: 3.2768 - 33s/epoch - 8ms/step\n",
      "Epoch 20/1000\n",
      "4208/4208 - 33s - loss: 9.2017 - val_loss: 3.1014 - 33s/epoch - 8ms/step\n",
      "Epoch 21/1000\n",
      "4208/4208 - 34s - loss: 9.0461 - val_loss: 3.1019 - 34s/epoch - 8ms/step\n",
      "Epoch 22/1000\n",
      "4208/4208 - 34s - loss: 8.8866 - val_loss: 3.0681 - 34s/epoch - 8ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpf5yclluz/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/30 03:26:41 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/30 03:26:41 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 40s - loss: 81.5811 - val_loss: 73.1625 - 40s/epoch - 9ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 36s - loss: 55.0211 - val_loss: 58.9138 - 36s/epoch - 9ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 36s - loss: 50.7213 - val_loss: 56.0638 - 36s/epoch - 9ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 36s - loss: 49.8200 - val_loss: 56.1413 - 36s/epoch - 9ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 37s - loss: 48.9235 - val_loss: 54.2476 - 37s/epoch - 9ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 37s - loss: 48.0343 - val_loss: 52.4393 - 37s/epoch - 9ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 36s - loss: 47.1642 - val_loss: 53.0261 - 36s/epoch - 9ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 37s - loss: 46.2732 - val_loss: 51.5104 - 37s/epoch - 9ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 37s - loss: 45.3897 - val_loss: 50.7350 - 37s/epoch - 9ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 36s - loss: 44.5211 - val_loss: 49.8740 - 36s/epoch - 9ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 37s - loss: 43.6505 - val_loss: 49.1383 - 37s/epoch - 9ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 37s - loss: 42.7760 - val_loss: 48.1237 - 37s/epoch - 9ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 36s - loss: 41.8816 - val_loss: 47.6586 - 36s/epoch - 9ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 37s - loss: 41.0121 - val_loss: 46.6717 - 37s/epoch - 9ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 36s - loss: 40.1250 - val_loss: 45.0027 - 36s/epoch - 9ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 36s - loss: 39.2594 - val_loss: 44.3457 - 36s/epoch - 9ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 36s - loss: 38.3642 - val_loss: 43.5914 - 36s/epoch - 8ms/step\n",
      "Epoch 18/1000\n",
      "4208/4208 - 35s - loss: 37.4805 - val_loss: 42.1563 - 35s/epoch - 8ms/step\n",
      "Epoch 19/1000\n",
      "4208/4208 - 35s - loss: 36.6061 - val_loss: 41.2320 - 35s/epoch - 8ms/step\n",
      "Epoch 20/1000\n",
      "4208/4208 - 36s - loss: 35.7461 - val_loss: 39.9888 - 36s/epoch - 9ms/step\n",
      "Epoch 21/1000\n",
      "4208/4208 - 35s - loss: 34.8614 - val_loss: 39.3448 - 35s/epoch - 8ms/step\n",
      "Epoch 22/1000\n",
      "4208/4208 - 35s - loss: 33.9863 - val_loss: 38.4615 - 35s/epoch - 8ms/step\n",
      "Epoch 23/1000\n",
      "4208/4208 - 36s - loss: 33.0797 - val_loss: 37.2303 - 36s/epoch - 9ms/step\n",
      "Epoch 24/1000\n",
      "4208/4208 - 36s - loss: 32.2290 - val_loss: 36.2420 - 36s/epoch - 9ms/step\n",
      "Epoch 25/1000\n",
      "4208/4208 - 35s - loss: 31.3416 - val_loss: 35.3536 - 35s/epoch - 8ms/step\n",
      "Epoch 26/1000\n",
      "4208/4208 - 35s - loss: 30.4611 - val_loss: 34.0836 - 35s/epoch - 8ms/step\n",
      "Epoch 27/1000\n",
      "4208/4208 - 35s - loss: 29.6004 - val_loss: 33.4357 - 35s/epoch - 8ms/step\n",
      "Epoch 28/1000\n",
      "4208/4208 - 35s - loss: 28.7321 - val_loss: 32.3003 - 35s/epoch - 8ms/step\n",
      "Epoch 29/1000\n",
      "4208/4208 - 35s - loss: 27.8428 - val_loss: 31.2260 - 35s/epoch - 8ms/step\n",
      "Epoch 30/1000\n",
      "4208/4208 - 35s - loss: 26.9738 - val_loss: 29.6977 - 35s/epoch - 8ms/step\n",
      "Epoch 31/1000\n",
      "4208/4208 - 35s - loss: 26.1005 - val_loss: 29.1483 - 35s/epoch - 8ms/step\n",
      "Epoch 32/1000\n",
      "4208/4208 - 35s - loss: 25.2272 - val_loss: 28.2914 - 35s/epoch - 8ms/step\n",
      "Epoch 33/1000\n",
      "4208/4208 - 35s - loss: 24.3497 - val_loss: 27.3200 - 35s/epoch - 8ms/step\n",
      "Epoch 34/1000\n",
      "4208/4208 - 35s - loss: 23.4753 - val_loss: 25.7974 - 35s/epoch - 8ms/step\n",
      "Epoch 35/1000\n",
      "4208/4208 - 36s - loss: 22.6140 - val_loss: 24.8368 - 36s/epoch - 8ms/step\n",
      "Epoch 36/1000\n",
      "4208/4208 - 35s - loss: 21.7461 - val_loss: 24.2037 - 35s/epoch - 8ms/step\n",
      "Epoch 37/1000\n",
      "4208/4208 - 36s - loss: 20.8757 - val_loss: 23.1461 - 36s/epoch - 8ms/step\n",
      "Epoch 38/1000\n",
      "4208/4208 - 35s - loss: 20.0129 - val_loss: 22.2438 - 35s/epoch - 8ms/step\n",
      "Epoch 39/1000\n",
      "4208/4208 - 36s - loss: 19.1422 - val_loss: 20.9731 - 36s/epoch - 8ms/step\n",
      "Epoch 40/1000\n",
      "4208/4208 - 35s - loss: 18.2904 - val_loss: 20.1020 - 35s/epoch - 8ms/step\n",
      "Epoch 41/1000\n",
      "4208/4208 - 35s - loss: 17.4297 - val_loss: 19.2443 - 35s/epoch - 8ms/step\n",
      "Epoch 42/1000\n",
      "4208/4208 - 36s - loss: 16.5857 - val_loss: 18.0623 - 36s/epoch - 9ms/step\n",
      "Epoch 43/1000\n",
      "4208/4208 - 37s - loss: 15.7322 - val_loss: 17.3188 - 37s/epoch - 9ms/step\n",
      "Epoch 44/1000\n",
      "4208/4208 - 36s - loss: 14.8934 - val_loss: 16.1760 - 36s/epoch - 9ms/step\n",
      "Epoch 45/1000\n",
      "4208/4208 - 37s - loss: 14.0580 - val_loss: 15.0833 - 37s/epoch - 9ms/step\n",
      "Epoch 46/1000\n",
      "4208/4208 - 37s - loss: 13.2332 - val_loss: 14.4333 - 37s/epoch - 9ms/step\n",
      "Epoch 47/1000\n",
      "4208/4208 - 36s - loss: 12.4233 - val_loss: 13.7048 - 36s/epoch - 9ms/step\n",
      "Epoch 48/1000\n",
      "4208/4208 - 37s - loss: 11.6321 - val_loss: 12.6051 - 37s/epoch - 9ms/step\n",
      "Epoch 49/1000\n",
      "4208/4208 - 37s - loss: 10.8835 - val_loss: 11.6998 - 37s/epoch - 9ms/step\n",
      "Epoch 50/1000\n",
      "4208/4208 - 36s - loss: 10.0962 - val_loss: 8.0475 - 36s/epoch - 9ms/step\n",
      "Epoch 51/1000\n",
      "4208/4208 - 36s - loss: 9.1148 - val_loss: 6.8827 - 36s/epoch - 9ms/step\n",
      "Epoch 52/1000\n",
      "4208/4208 - 36s - loss: 8.4813 - val_loss: 6.5209 - 36s/epoch - 9ms/step\n",
      "Epoch 53/1000\n",
      "4208/4208 - 36s - loss: 7.8360 - val_loss: 4.5924 - 36s/epoch - 9ms/step\n",
      "Epoch 54/1000\n",
      "4208/4208 - 36s - loss: 7.2061 - val_loss: 4.5988 - 36s/epoch - 9ms/step\n",
      "Epoch 55/1000\n",
      "4208/4208 - 37s - loss: 6.7275 - val_loss: 4.2811 - 37s/epoch - 9ms/step\n",
      "Epoch 56/1000\n",
      "4208/4208 - 36s - loss: 6.2799 - val_loss: 4.2031 - 36s/epoch - 9ms/step\n",
      "Epoch 57/1000\n",
      "4208/4208 - 36s - loss: 5.8525 - val_loss: 3.8316 - 36s/epoch - 8ms/step\n",
      "Epoch 58/1000\n",
      "4208/4208 - 37s - loss: 5.4081 - val_loss: 3.7380 - 37s/epoch - 9ms/step\n",
      "Epoch 59/1000\n",
      "4208/4208 - 36s - loss: 5.0219 - val_loss: 3.7030 - 36s/epoch - 9ms/step\n",
      "Epoch 60/1000\n",
      "4208/4208 - 36s - loss: 4.6649 - val_loss: 3.5166 - 36s/epoch - 9ms/step\n",
      "Epoch 61/1000\n",
      "4208/4208 - 36s - loss: 4.3404 - val_loss: 3.4263 - 36s/epoch - 9ms/step\n",
      "Epoch 62/1000\n",
      "4208/4208 - 36s - loss: 4.0460 - val_loss: 3.3617 - 36s/epoch - 9ms/step\n",
      "Epoch 63/1000\n",
      "4208/4208 - 36s - loss: 3.7799 - val_loss: 3.2650 - 36s/epoch - 9ms/step\n",
      "Epoch 64/1000\n",
      "4208/4208 - 37s - loss: 3.5277 - val_loss: 3.1807 - 37s/epoch - 9ms/step\n",
      "Epoch 65/1000\n",
      "4208/4208 - 35s - loss: 3.3013 - val_loss: 3.2108 - 35s/epoch - 8ms/step\n",
      "Epoch 66/1000\n",
      "4208/4208 - 36s - loss: 3.0997 - val_loss: 3.3938 - 36s/epoch - 9ms/step\n",
      "Epoch 67/1000\n",
      "4208/4208 - 36s - loss: 2.9275 - val_loss: 3.4064 - 36s/epoch - 9ms/step\n",
      "Epoch 68/1000\n",
      "4208/4208 - 36s - loss: 2.7838 - val_loss: 3.3880 - 36s/epoch - 9ms/step\n",
      "Epoch 69/1000\n",
      "4208/4208 - 36s - loss: 2.6859 - val_loss: 3.3310 - 36s/epoch - 9ms/step\n",
      "Epoch 70/1000\n",
      "4208/4208 - 36s - loss: 2.6346 - val_loss: 3.3241 - 36s/epoch - 9ms/step\n",
      "Epoch 71/1000\n",
      "4208/4208 - 36s - loss: 2.6090 - val_loss: 3.3100 - 36s/epoch - 9ms/step\n",
      "Epoch 72/1000\n",
      "4208/4208 - 36s - loss: 2.5912 - val_loss: 3.3467 - 36s/epoch - 9ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp7hm0z843/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/30 04:13:50 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/30 04:13:50 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 43s - loss: 79.0531 - val_loss: 37.9584 - 43s/epoch - 10ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 39s - loss: 51.2585 - val_loss: 22.4227 - 39s/epoch - 9ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 39s - loss: 47.4034 - val_loss: 22.4264 - 39s/epoch - 9ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 40s - loss: 46.4245 - val_loss: 15.5822 - 40s/epoch - 9ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 39s - loss: 45.3775 - val_loss: 15.1935 - 39s/epoch - 9ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 40s - loss: 44.5484 - val_loss: 14.2758 - 40s/epoch - 9ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 40s - loss: 43.7277 - val_loss: 14.4315 - 40s/epoch - 9ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 39s - loss: 42.9338 - val_loss: 14.9591 - 39s/epoch - 9ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 40s - loss: 42.0880 - val_loss: 12.3401 - 40s/epoch - 9ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 40s - loss: 41.2938 - val_loss: 12.4274 - 40s/epoch - 9ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 39s - loss: 40.4581 - val_loss: 12.4057 - 39s/epoch - 9ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 38s - loss: 39.6302 - val_loss: 13.2940 - 38s/epoch - 9ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 39s - loss: 38.8202 - val_loss: 12.2933 - 39s/epoch - 9ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 39s - loss: 37.9997 - val_loss: 12.6272 - 39s/epoch - 9ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 39s - loss: 37.2001 - val_loss: 12.1353 - 39s/epoch - 9ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 39s - loss: 36.3544 - val_loss: 11.9157 - 39s/epoch - 9ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 39s - loss: 35.5594 - val_loss: 12.5497 - 39s/epoch - 9ms/step\n",
      "Epoch 18/1000\n",
      "4208/4208 - 40s - loss: 34.7188 - val_loss: 11.7078 - 40s/epoch - 9ms/step\n",
      "Epoch 19/1000\n",
      "4208/4208 - 39s - loss: 33.9135 - val_loss: 11.1213 - 39s/epoch - 9ms/step\n",
      "Epoch 20/1000\n",
      "4208/4208 - 39s - loss: 33.1030 - val_loss: 10.5785 - 39s/epoch - 9ms/step\n",
      "Epoch 21/1000\n",
      "4208/4208 - 40s - loss: 32.2654 - val_loss: 10.9602 - 40s/epoch - 9ms/step\n",
      "Epoch 22/1000\n",
      "4208/4208 - 40s - loss: 31.4737 - val_loss: 10.6197 - 40s/epoch - 9ms/step\n",
      "Epoch 23/1000\n",
      "4208/4208 - 39s - loss: 30.6569 - val_loss: 10.9291 - 39s/epoch - 9ms/step\n",
      "Epoch 24/1000\n",
      "4208/4208 - 40s - loss: 29.8438 - val_loss: 10.4680 - 40s/epoch - 9ms/step\n",
      "Epoch 25/1000\n",
      "4208/4208 - 40s - loss: 29.0335 - val_loss: 10.0158 - 40s/epoch - 9ms/step\n",
      "Epoch 26/1000\n",
      "4208/4208 - 39s - loss: 28.2047 - val_loss: 10.1231 - 39s/epoch - 9ms/step\n",
      "Epoch 27/1000\n",
      "4208/4208 - 38s - loss: 27.4000 - val_loss: 9.1140 - 38s/epoch - 9ms/step\n",
      "Epoch 28/1000\n",
      "4208/4208 - 39s - loss: 26.5824 - val_loss: 8.9631 - 39s/epoch - 9ms/step\n",
      "Epoch 29/1000\n",
      "4208/4208 - 39s - loss: 25.7649 - val_loss: 8.8856 - 39s/epoch - 9ms/step\n",
      "Epoch 30/1000\n",
      "4208/4208 - 39s - loss: 24.9642 - val_loss: 8.4457 - 39s/epoch - 9ms/step\n",
      "Epoch 31/1000\n",
      "4208/4208 - 40s - loss: 24.1458 - val_loss: 8.4336 - 40s/epoch - 9ms/step\n",
      "Epoch 32/1000\n",
      "4208/4208 - 39s - loss: 23.3519 - val_loss: 7.9291 - 39s/epoch - 9ms/step\n",
      "Epoch 33/1000\n",
      "4208/4208 - 40s - loss: 22.5399 - val_loss: 7.8995 - 40s/epoch - 9ms/step\n",
      "Epoch 34/1000\n",
      "4208/4208 - 40s - loss: 21.7314 - val_loss: 7.7087 - 40s/epoch - 9ms/step\n",
      "Epoch 35/1000\n",
      "4208/4208 - 39s - loss: 20.9270 - val_loss: 7.4445 - 39s/epoch - 9ms/step\n",
      "Epoch 36/1000\n",
      "4208/4208 - 40s - loss: 20.1262 - val_loss: 7.1639 - 40s/epoch - 9ms/step\n",
      "Epoch 37/1000\n",
      "4208/4208 - 39s - loss: 19.3301 - val_loss: 7.0598 - 39s/epoch - 9ms/step\n",
      "Epoch 38/1000\n",
      "4208/4208 - 40s - loss: 18.5295 - val_loss: 6.6788 - 40s/epoch - 9ms/step\n",
      "Epoch 39/1000\n",
      "4208/4208 - 39s - loss: 17.7348 - val_loss: 6.4596 - 39s/epoch - 9ms/step\n",
      "Epoch 40/1000\n",
      "4208/4208 - 39s - loss: 16.9488 - val_loss: 6.2874 - 39s/epoch - 9ms/step\n",
      "Epoch 41/1000\n",
      "4208/4208 - 39s - loss: 16.1516 - val_loss: 5.9220 - 39s/epoch - 9ms/step\n",
      "Epoch 42/1000\n",
      "4208/4208 - 39s - loss: 15.3734 - val_loss: 5.9516 - 39s/epoch - 9ms/step\n",
      "Epoch 43/1000\n",
      "4208/4208 - 39s - loss: 14.5974 - val_loss: 5.7660 - 39s/epoch - 9ms/step\n",
      "Epoch 44/1000\n",
      "4208/4208 - 39s - loss: 13.8296 - val_loss: 5.6170 - 39s/epoch - 9ms/step\n",
      "Epoch 45/1000\n",
      "4208/4208 - 39s - loss: 13.0641 - val_loss: 5.3820 - 39s/epoch - 9ms/step\n",
      "Epoch 46/1000\n",
      "4208/4208 - 39s - loss: 12.3149 - val_loss: 5.3233 - 39s/epoch - 9ms/step\n",
      "Epoch 47/1000\n",
      "4208/4208 - 40s - loss: 11.5816 - val_loss: 5.2647 - 40s/epoch - 9ms/step\n",
      "Epoch 48/1000\n",
      "4208/4208 - 39s - loss: 10.8647 - val_loss: 4.7427 - 39s/epoch - 9ms/step\n",
      "Epoch 49/1000\n",
      "4208/4208 - 39s - loss: 10.1700 - val_loss: 4.6313 - 39s/epoch - 9ms/step\n",
      "Epoch 50/1000\n",
      "4208/4208 - 40s - loss: 9.5052 - val_loss: 4.5350 - 40s/epoch - 9ms/step\n",
      "Epoch 51/1000\n",
      "4208/4208 - 39s - loss: 8.8828 - val_loss: 4.3679 - 39s/epoch - 9ms/step\n",
      "Epoch 52/1000\n",
      "4208/4208 - 39s - loss: 8.2917 - val_loss: 4.2743 - 39s/epoch - 9ms/step\n",
      "Epoch 53/1000\n",
      "4208/4208 - 39s - loss: 7.7428 - val_loss: 4.0714 - 39s/epoch - 9ms/step\n",
      "Epoch 54/1000\n",
      "4208/4208 - 39s - loss: 7.2298 - val_loss: 4.0403 - 39s/epoch - 9ms/step\n",
      "Epoch 55/1000\n",
      "4208/4208 - 39s - loss: 6.7527 - val_loss: 3.8520 - 39s/epoch - 9ms/step\n",
      "Epoch 56/1000\n",
      "4208/4208 - 39s - loss: 6.3077 - val_loss: 3.6495 - 39s/epoch - 9ms/step\n",
      "Epoch 57/1000\n",
      "4208/4208 - 39s - loss: 5.8669 - val_loss: 3.4660 - 39s/epoch - 9ms/step\n",
      "Epoch 58/1000\n",
      "4208/4208 - 40s - loss: 5.4385 - val_loss: 3.3985 - 40s/epoch - 9ms/step\n",
      "Epoch 59/1000\n",
      "4208/4208 - 40s - loss: 5.0543 - val_loss: 3.3374 - 40s/epoch - 10ms/step\n",
      "Epoch 60/1000\n",
      "4208/4208 - 39s - loss: 4.7067 - val_loss: 3.3014 - 39s/epoch - 9ms/step\n",
      "Epoch 61/1000\n",
      "4208/4208 - 39s - loss: 4.3844 - val_loss: 3.1796 - 39s/epoch - 9ms/step\n",
      "Epoch 62/1000\n",
      "4208/4208 - 39s - loss: 4.0921 - val_loss: 3.1241 - 39s/epoch - 9ms/step\n",
      "Epoch 63/1000\n",
      "4208/4208 - 39s - loss: 3.8222 - val_loss: 3.0545 - 39s/epoch - 9ms/step\n",
      "Epoch 64/1000\n",
      "4208/4208 - 39s - loss: 3.5765 - val_loss: 3.0093 - 39s/epoch - 9ms/step\n",
      "Epoch 65/1000\n",
      "4208/4208 - 39s - loss: 3.3576 - val_loss: 2.9526 - 39s/epoch - 9ms/step\n",
      "Epoch 66/1000\n",
      "4208/4208 - 39s - loss: 3.1626 - val_loss: 2.9204 - 39s/epoch - 9ms/step\n",
      "Epoch 67/1000\n",
      "4208/4208 - 39s - loss: 3.0000 - val_loss: 2.9147 - 39s/epoch - 9ms/step\n",
      "Epoch 68/1000\n",
      "4208/4208 - 39s - loss: 2.8819 - val_loss: 2.9055 - 39s/epoch - 9ms/step\n",
      "Epoch 69/1000\n",
      "4208/4208 - 39s - loss: 2.8182 - val_loss: 2.9080 - 39s/epoch - 9ms/step\n",
      "Epoch 70/1000\n",
      "4208/4208 - 39s - loss: 2.7987 - val_loss: 2.9115 - 39s/epoch - 9ms/step\n",
      "Epoch 71/1000\n",
      "4208/4208 - 39s - loss: 2.7925 - val_loss: 2.9103 - 39s/epoch - 9ms/step\n",
      "Epoch 72/1000\n",
      "4208/4208 - 39s - loss: 2.7775 - val_loss: 2.9009 - 39s/epoch - 9ms/step\n",
      "Epoch 73/1000\n",
      "4208/4208 - 39s - loss: 2.7623 - val_loss: 2.8954 - 39s/epoch - 9ms/step\n",
      "Epoch 74/1000\n",
      "4208/4208 - 39s - loss: 2.7518 - val_loss: 2.8874 - 39s/epoch - 9ms/step\n",
      "Epoch 75/1000\n",
      "4208/4208 - 39s - loss: 2.7462 - val_loss: 2.8766 - 39s/epoch - 9ms/step\n",
      "Epoch 76/1000\n",
      "4208/4208 - 39s - loss: 2.7416 - val_loss: 2.8804 - 39s/epoch - 9ms/step\n",
      "Epoch 77/1000\n",
      "4208/4208 - 39s - loss: 2.7362 - val_loss: 2.8806 - 39s/epoch - 9ms/step\n",
      "Epoch 78/1000\n",
      "4208/4208 - 39s - loss: 2.7325 - val_loss: 2.8880 - 39s/epoch - 9ms/step\n",
      "Epoch 79/1000\n",
      "4208/4208 - 39s - loss: 2.7264 - val_loss: 2.8820 - 39s/epoch - 9ms/step\n",
      "Epoch 80/1000\n",
      "4208/4208 - 39s - loss: 2.7125 - val_loss: 2.8748 - 39s/epoch - 9ms/step\n",
      "Epoch 81/1000\n",
      "4208/4208 - 39s - loss: 2.6958 - val_loss: 2.8635 - 39s/epoch - 9ms/step\n",
      "Epoch 82/1000\n",
      "4208/4208 - 39s - loss: 2.6810 - val_loss: 2.8517 - 39s/epoch - 9ms/step\n",
      "Epoch 83/1000\n",
      "4208/4208 - 39s - loss: 2.6667 - val_loss: 2.8558 - 39s/epoch - 9ms/step\n",
      "Epoch 84/1000\n",
      "4208/4208 - 39s - loss: 2.6450 - val_loss: 2.8302 - 39s/epoch - 9ms/step\n",
      "Epoch 85/1000\n",
      "4208/4208 - 39s - loss: 2.6264 - val_loss: 2.8258 - 39s/epoch - 9ms/step\n",
      "Epoch 86/1000\n",
      "4208/4208 - 40s - loss: 2.6187 - val_loss: 2.8160 - 40s/epoch - 9ms/step\n",
      "Epoch 87/1000\n",
      "4208/4208 - 39s - loss: 2.6157 - val_loss: 2.8215 - 39s/epoch - 9ms/step\n",
      "Epoch 88/1000\n",
      "4208/4208 - 40s - loss: 2.6138 - val_loss: 2.8173 - 40s/epoch - 9ms/step\n",
      "Epoch 89/1000\n",
      "4208/4208 - 39s - loss: 2.6103 - val_loss: 2.8113 - 39s/epoch - 9ms/step\n",
      "Epoch 90/1000\n",
      "4208/4208 - 39s - loss: 2.6092 - val_loss: 2.8157 - 39s/epoch - 9ms/step\n",
      "Epoch 91/1000\n",
      "4208/4208 - 39s - loss: 2.6089 - val_loss: 2.8153 - 39s/epoch - 9ms/step\n",
      "Epoch 92/1000\n",
      "4208/4208 - 39s - loss: 2.6085 - val_loss: 2.8132 - 39s/epoch - 9ms/step\n",
      "Epoch 93/1000\n",
      "4208/4208 - 38s - loss: 2.6082 - val_loss: 2.8140 - 38s/epoch - 9ms/step\n",
      "Epoch 94/1000\n",
      "4208/4208 - 38s - loss: 2.6077 - val_loss: 2.8122 - 38s/epoch - 9ms/step\n",
      "Epoch 95/1000\n",
      "4208/4208 - 39s - loss: 2.6065 - val_loss: 2.8176 - 39s/epoch - 9ms/step\n",
      "Epoch 96/1000\n",
      "4208/4208 - 39s - loss: 2.6059 - val_loss: 2.8121 - 39s/epoch - 9ms/step\n",
      "Epoch 97/1000\n",
      "4208/4208 - 39s - loss: 2.6055 - val_loss: 2.8130 - 39s/epoch - 9ms/step\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpfdiaij4l/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/30 05:21:45 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/30 05:21:45 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 41s - loss: 24.6550 - val_loss: 8.0882 - 41s/epoch - 10ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 38s - loss: 15.8935 - val_loss: 3.9703 - 38s/epoch - 9ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 39s - loss: 13.8491 - val_loss: 3.0976 - 39s/epoch - 9ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 38s - loss: 13.0556 - val_loss: 3.0951 - 38s/epoch - 9ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 37s - loss: 12.4896 - val_loss: 2.7971 - 37s/epoch - 9ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 37s - loss: 12.0847 - val_loss: 2.8779 - 37s/epoch - 9ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 38s - loss: 11.7845 - val_loss: 2.8778 - 38s/epoch - 9ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 38s - loss: 11.5586 - val_loss: 2.8710 - 38s/epoch - 9ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 38s - loss: 11.3512 - val_loss: 2.7714 - 38s/epoch - 9ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 38s - loss: 11.1655 - val_loss: 2.8436 - 38s/epoch - 9ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 38s - loss: 10.9835 - val_loss: 2.8349 - 38s/epoch - 9ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 37s - loss: 10.8048 - val_loss: 3.1801 - 37s/epoch - 9ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 38s - loss: 10.6230 - val_loss: 2.7982 - 38s/epoch - 9ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 38s - loss: 10.4522 - val_loss: 2.6855 - 38s/epoch - 9ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 37s - loss: 10.2712 - val_loss: 2.6623 - 37s/epoch - 9ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 37s - loss: 10.0986 - val_loss: 2.7173 - 37s/epoch - 9ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 38s - loss: 9.9243 - val_loss: 2.7308 - 38s/epoch - 9ms/step\n",
      "Epoch 18/1000\n",
      "4208/4208 - 37s - loss: 9.7491 - val_loss: 2.5160 - 37s/epoch - 9ms/step\n",
      "Epoch 19/1000\n",
      "4208/4208 - 38s - loss: 9.5779 - val_loss: 2.7021 - 38s/epoch - 9ms/step\n",
      "Epoch 20/1000\n",
      "4208/4208 - 38s - loss: 9.3986 - val_loss: 2.6351 - 38s/epoch - 9ms/step\n",
      "Epoch 21/1000\n",
      "4208/4208 - 38s - loss: 9.2212 - val_loss: 2.7177 - 38s/epoch - 9ms/step\n",
      "Epoch 22/1000\n",
      "4208/4208 - 38s - loss: 9.0467 - val_loss: 2.5109 - 38s/epoch - 9ms/step\n",
      "Epoch 23/1000\n",
      "4208/4208 - 38s - loss: 8.8742 - val_loss: 2.5774 - 38s/epoch - 9ms/step\n",
      "Epoch 24/1000\n",
      "4208/4208 - 38s - loss: 8.7029 - val_loss: 2.4768 - 38s/epoch - 9ms/step\n",
      "Epoch 25/1000\n",
      "4208/4208 - 37s - loss: 8.5313 - val_loss: 2.4506 - 37s/epoch - 9ms/step\n",
      "Epoch 26/1000\n",
      "4208/4208 - 37s - loss: 8.3600 - val_loss: 2.4623 - 37s/epoch - 9ms/step\n",
      "Epoch 27/1000\n",
      "4208/4208 - 37s - loss: 8.1862 - val_loss: 2.5514 - 37s/epoch - 9ms/step\n",
      "Epoch 28/1000\n",
      "4208/4208 - 37s - loss: 8.0171 - val_loss: 2.5428 - 37s/epoch - 9ms/step\n",
      "Epoch 29/1000\n",
      "4208/4208 - 37s - loss: 7.8430 - val_loss: 2.4061 - 37s/epoch - 9ms/step\n",
      "Epoch 30/1000\n",
      "4208/4208 - 37s - loss: 7.6757 - val_loss: 2.3645 - 37s/epoch - 9ms/step\n",
      "Epoch 31/1000\n",
      "4208/4208 - 37s - loss: 7.5057 - val_loss: 2.4267 - 37s/epoch - 9ms/step\n",
      "Epoch 32/1000\n",
      "4208/4208 - 37s - loss: 7.3360 - val_loss: 2.4406 - 37s/epoch - 9ms/step\n",
      "Epoch 33/1000\n",
      "4208/4208 - 37s - loss: 7.1687 - val_loss: 2.3845 - 37s/epoch - 9ms/step\n",
      "Epoch 34/1000\n",
      "4208/4208 - 37s - loss: 7.0034 - val_loss: 2.3362 - 37s/epoch - 9ms/step\n",
      "Epoch 35/1000\n",
      "4208/4208 - 37s - loss: 6.8363 - val_loss: 2.3078 - 37s/epoch - 9ms/step\n",
      "Epoch 36/1000\n",
      "4208/4208 - 37s - loss: 6.6704 - val_loss: 2.1961 - 37s/epoch - 9ms/step\n",
      "Epoch 37/1000\n",
      "4208/4208 - 37s - loss: 6.5047 - val_loss: 2.3086 - 37s/epoch - 9ms/step\n",
      "Epoch 38/1000\n",
      "4208/4208 - 37s - loss: 6.3428 - val_loss: 2.2544 - 37s/epoch - 9ms/step\n",
      "Epoch 39/1000\n",
      "4208/4208 - 36s - loss: 6.1821 - val_loss: 2.3284 - 36s/epoch - 9ms/step\n",
      "Epoch 40/1000\n",
      "4208/4208 - 37s - loss: 6.0226 - val_loss: 2.2479 - 37s/epoch - 9ms/step\n",
      "Epoch 41/1000\n",
      "4208/4208 - 36s - loss: 5.8598 - val_loss: 2.4370 - 36s/epoch - 9ms/step\n",
      "Epoch 42/1000\n",
      "4208/4208 - 37s - loss: 5.7017 - val_loss: 2.3144 - 37s/epoch - 9ms/step\n",
      "Epoch 43/1000\n",
      "4208/4208 - 38s - loss: 5.5449 - val_loss: 2.1928 - 38s/epoch - 9ms/step\n",
      "Epoch 44/1000\n",
      "4208/4208 - 37s - loss: 5.3900 - val_loss: 2.1447 - 37s/epoch - 9ms/step\n",
      "Epoch 45/1000\n",
      "4208/4208 - 37s - loss: 5.2340 - val_loss: 2.2555 - 37s/epoch - 9ms/step\n",
      "Epoch 46/1000\n",
      "4208/4208 - 37s - loss: 5.0805 - val_loss: 2.0802 - 37s/epoch - 9ms/step\n",
      "Epoch 47/1000\n",
      "4208/4208 - 37s - loss: 4.9286 - val_loss: 2.0717 - 37s/epoch - 9ms/step\n",
      "Epoch 48/1000\n",
      "4208/4208 - 37s - loss: 4.7741 - val_loss: 2.1206 - 37s/epoch - 9ms/step\n",
      "Epoch 49/1000\n",
      "4208/4208 - 37s - loss: 4.6219 - val_loss: 2.0790 - 37s/epoch - 9ms/step\n",
      "Epoch 50/1000\n",
      "4208/4208 - 37s - loss: 4.4745 - val_loss: 2.0371 - 37s/epoch - 9ms/step\n",
      "Epoch 51/1000\n",
      "4208/4208 - 38s - loss: 4.3327 - val_loss: 2.0628 - 38s/epoch - 9ms/step\n",
      "Epoch 52/1000\n",
      "4208/4208 - 38s - loss: 4.1883 - val_loss: 1.9553 - 38s/epoch - 9ms/step\n",
      "Epoch 53/1000\n",
      "4208/4208 - 38s - loss: 4.0476 - val_loss: 2.0098 - 38s/epoch - 9ms/step\n",
      "Epoch 54/1000\n",
      "4208/4208 - 37s - loss: 3.9117 - val_loss: 1.9462 - 37s/epoch - 9ms/step\n",
      "Epoch 55/1000\n",
      "4208/4208 - 38s - loss: 3.7772 - val_loss: 1.9017 - 38s/epoch - 9ms/step\n",
      "Epoch 56/1000\n",
      "4208/4208 - 37s - loss: 3.6464 - val_loss: 1.8774 - 37s/epoch - 9ms/step\n",
      "Epoch 57/1000\n",
      "4208/4208 - 38s - loss: 3.5192 - val_loss: 1.8843 - 38s/epoch - 9ms/step\n",
      "Epoch 58/1000\n",
      "4208/4208 - 38s - loss: 3.4251 - val_loss: 1.8798 - 38s/epoch - 9ms/step\n",
      "Epoch 59/1000\n",
      "4208/4208 - 38s - loss: 3.2869 - val_loss: 1.8919 - 38s/epoch - 9ms/step\n",
      "Epoch 60/1000\n",
      "4208/4208 - 37s - loss: 3.1619 - val_loss: 1.8631 - 37s/epoch - 9ms/step\n",
      "Epoch 61/1000\n",
      "4208/4208 - 38s - loss: 3.1420 - val_loss: 1.8361 - 38s/epoch - 9ms/step\n",
      "Epoch 62/1000\n",
      "4208/4208 - 38s - loss: 2.9595 - val_loss: 1.7651 - 38s/epoch - 9ms/step\n",
      "Epoch 63/1000\n",
      "4208/4208 - 38s - loss: 2.8419 - val_loss: 1.7619 - 38s/epoch - 9ms/step\n",
      "Epoch 64/1000\n",
      "4208/4208 - 37s - loss: 2.7454 - val_loss: 1.7412 - 37s/epoch - 9ms/step\n",
      "Epoch 65/1000\n",
      "4208/4208 - 37s - loss: 2.6456 - val_loss: 1.7393 - 37s/epoch - 9ms/step\n",
      "Epoch 66/1000\n",
      "4208/4208 - 38s - loss: 2.5538 - val_loss: 1.7093 - 38s/epoch - 9ms/step\n",
      "Epoch 67/1000\n",
      "4208/4208 - 38s - loss: 2.5008 - val_loss: 1.7061 - 38s/epoch - 9ms/step\n",
      "Epoch 68/1000\n",
      "4208/4208 - 38s - loss: 2.4205 - val_loss: 1.7155 - 38s/epoch - 9ms/step\n",
      "Epoch 69/1000\n",
      "4208/4208 - 38s - loss: 2.3141 - val_loss: 1.6967 - 38s/epoch - 9ms/step\n",
      "Epoch 70/1000\n",
      "4208/4208 - 38s - loss: 2.2366 - val_loss: 1.6697 - 38s/epoch - 9ms/step\n",
      "Epoch 71/1000\n",
      "4208/4208 - 38s - loss: 2.1666 - val_loss: 1.6625 - 38s/epoch - 9ms/step\n",
      "Epoch 72/1000\n",
      "4208/4208 - 38s - loss: 2.0985 - val_loss: 1.6323 - 38s/epoch - 9ms/step\n",
      "Epoch 73/1000\n",
      "4208/4208 - 38s - loss: 2.1478 - val_loss: 1.6436 - 38s/epoch - 9ms/step\n",
      "Epoch 74/1000\n",
      "4208/4208 - 38s - loss: 1.9830 - val_loss: 1.6134 - 38s/epoch - 9ms/step\n",
      "Epoch 75/1000\n",
      "4208/4208 - 37s - loss: 1.9262 - val_loss: 1.5910 - 37s/epoch - 9ms/step\n",
      "Epoch 76/1000\n",
      "4208/4208 - 37s - loss: 1.8729 - val_loss: 1.5651 - 37s/epoch - 9ms/step\n",
      "Epoch 77/1000\n",
      "4208/4208 - 37s - loss: 1.8685 - val_loss: 1.6006 - 37s/epoch - 9ms/step\n",
      "Epoch 78/1000\n",
      "4208/4208 - 37s - loss: 1.7944 - val_loss: 1.5704 - 37s/epoch - 9ms/step\n",
      "Epoch 79/1000\n",
      "4208/4208 - 37s - loss: 1.7562 - val_loss: 1.5794 - 37s/epoch - 9ms/step\n",
      "Epoch 80/1000\n",
      "4208/4208 - 37s - loss: 1.7228 - val_loss: 1.5557 - 37s/epoch - 9ms/step\n",
      "Epoch 81/1000\n",
      "4208/4208 - 38s - loss: 1.6967 - val_loss: 1.5315 - 38s/epoch - 9ms/step\n",
      "Epoch 82/1000\n",
      "4208/4208 - 38s - loss: 1.9508 - val_loss: 1.5605 - 38s/epoch - 9ms/step\n",
      "Epoch 83/1000\n",
      "4208/4208 - 38s - loss: 1.6861 - val_loss: 1.5349 - 38s/epoch - 9ms/step\n",
      "Epoch 84/1000\n",
      "4208/4208 - 37s - loss: 1.6792 - val_loss: 1.5436 - 37s/epoch - 9ms/step\n",
      "Epoch 85/1000\n",
      "4208/4208 - 37s - loss: 1.6539 - val_loss: 1.5277 - 37s/epoch - 9ms/step\n",
      "Epoch 86/1000\n",
      "4208/4208 - 36s - loss: 1.6513 - val_loss: 1.5336 - 36s/epoch - 9ms/step\n",
      "Epoch 87/1000\n",
      "4208/4208 - 36s - loss: 1.6384 - val_loss: 1.5248 - 36s/epoch - 9ms/step\n",
      "Epoch 88/1000\n",
      "4208/4208 - 37s - loss: 1.6267 - val_loss: 1.5148 - 37s/epoch - 9ms/step\n",
      "Epoch 89/1000\n",
      "4208/4208 - 37s - loss: 1.7943 - val_loss: 1.9576 - 37s/epoch - 9ms/step\n",
      "Epoch 90/1000\n",
      "4208/4208 - 38s - loss: 1.7053 - val_loss: 1.5407 - 38s/epoch - 9ms/step\n",
      "Epoch 91/1000\n",
      "4208/4208 - 36s - loss: 1.6821 - val_loss: 1.5256 - 36s/epoch - 9ms/step\n",
      "Epoch 92/1000\n",
      "4208/4208 - 36s - loss: 1.6248 - val_loss: 1.5045 - 36s/epoch - 9ms/step\n",
      "Epoch 93/1000\n",
      "4208/4208 - 36s - loss: 1.6283 - val_loss: 1.5099 - 36s/epoch - 9ms/step\n",
      "Epoch 94/1000\n",
      "4208/4208 - 37s - loss: 2.3748 - val_loss: 1.5628 - 37s/epoch - 9ms/step\n",
      "Epoch 95/1000\n",
      "4208/4208 - 37s - loss: 1.6832 - val_loss: 1.5370 - 37s/epoch - 9ms/step\n",
      "Epoch 96/1000\n",
      "4208/4208 - 38s - loss: 1.6433 - val_loss: 1.5338 - 38s/epoch - 9ms/step\n",
      "Epoch 97/1000\n",
      "4208/4208 - 38s - loss: 2.4277 - val_loss: 1.5282 - 38s/epoch - 9ms/step\n",
      "Epoch 98/1000\n",
      "4208/4208 - 38s - loss: 1.6398 - val_loss: 1.5357 - 38s/epoch - 9ms/step\n",
      "Epoch 99/1000\n",
      "4208/4208 - 38s - loss: 1.6130 - val_loss: 1.5356 - 38s/epoch - 9ms/step\n",
      "Epoch 100/1000\n",
      "4208/4208 - 38s - loss: 1.7450 - val_loss: 1.5581 - 38s/epoch - 9ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpw1dbxet5/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/30 06:28:23 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/30 06:28:23 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 40s - loss: 7.4986 - val_loss: 3.0148 - 40s/epoch - 9ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 38s - loss: 4.0810 - val_loss: 3.4843 - 38s/epoch - 9ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 38s - loss: 3.7877 - val_loss: 3.3383 - 38s/epoch - 9ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 38s - loss: 3.5061 - val_loss: 4.5109 - 38s/epoch - 9ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 38s - loss: 3.3906 - val_loss: 4.9762 - 38s/epoch - 9ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 38s - loss: 3.3228 - val_loss: 3.3544 - 38s/epoch - 9ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 38s - loss: 3.2572 - val_loss: 4.5194 - 38s/epoch - 9ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 38s - loss: 3.1983 - val_loss: 4.3113 - 38s/epoch - 9ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 38s - loss: 3.1484 - val_loss: 2.4357 - 38s/epoch - 9ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 38s - loss: 3.1132 - val_loss: 3.8424 - 38s/epoch - 9ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 38s - loss: 3.0668 - val_loss: 4.9576 - 38s/epoch - 9ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 38s - loss: 3.0301 - val_loss: 3.0645 - 38s/epoch - 9ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 38s - loss: 2.9977 - val_loss: 3.4603 - 38s/epoch - 9ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 37s - loss: 2.9554 - val_loss: 3.1435 - 37s/epoch - 9ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 37s - loss: 2.9232 - val_loss: 5.0744 - 37s/epoch - 9ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 37s - loss: 2.8954 - val_loss: 3.1507 - 37s/epoch - 9ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 37s - loss: 2.8682 - val_loss: 3.6754 - 37s/epoch - 9ms/step\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpk5zs6myp/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/30 06:43:21 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/30 06:43:21 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 40s - loss: 28.8886 - val_loss: 68.7798 - 40s/epoch - 10ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 38s - loss: 20.8481 - val_loss: 65.8887 - 38s/epoch - 9ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 38s - loss: 20.1994 - val_loss: 63.7533 - 38s/epoch - 9ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 38s - loss: 19.7568 - val_loss: 64.9549 - 38s/epoch - 9ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 38s - loss: 19.1383 - val_loss: 60.6394 - 38s/epoch - 9ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 38s - loss: 18.1576 - val_loss: 58.2761 - 38s/epoch - 9ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 39s - loss: 17.6739 - val_loss: 55.0985 - 39s/epoch - 9ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 38s - loss: 17.3285 - val_loss: 54.8693 - 38s/epoch - 9ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 38s - loss: 17.0108 - val_loss: 51.2649 - 38s/epoch - 9ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 39s - loss: 16.7024 - val_loss: 48.4408 - 39s/epoch - 9ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 38s - loss: 16.3116 - val_loss: 43.3789 - 38s/epoch - 9ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 38s - loss: 15.8898 - val_loss: 38.3180 - 38s/epoch - 9ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 38s - loss: 15.5474 - val_loss: 34.2375 - 38s/epoch - 9ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 38s - loss: 15.1955 - val_loss: 28.8797 - 38s/epoch - 9ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 38s - loss: 14.8346 - val_loss: 24.7270 - 38s/epoch - 9ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 38s - loss: 14.4314 - val_loss: 19.0660 - 38s/epoch - 9ms/step\n",
      "Epoch 17/1000\n"
     ]
    }
   ],
   "source": [
    "# cpl\n",
    "\n",
    "for _ in range(100):\n",
    "    config = {'shape': 22,\n",
    "              'output': 72,\n",
    "              'dropout': np.random.choice([0.01, 0.1, 0.2, 0.5]),\n",
    "              'num_layers': np.random.choice([3, 4, 5, 10]),\n",
    "              'num_neurons': np.random.choice([16, 32, 64, 128]),\n",
    "              'activation': np.random.choice(['gelu', 'gelu', 'relu'])}\n",
    "\n",
    "    model = build_cpl_model(config)\n",
    "    \n",
    "    with mlflow.start_run() as run:\n",
    "        model_checkpoint_callback = ModelCheckpoint(\n",
    "            filepath=f\"models/model_{run.info.run_id}.keras\",\n",
    "            save_weights_only=False,\n",
    "            monitor='val_loss',\n",
    "            mode='min',\n",
    "            save_best_only=True)\n",
    "        callback = EarlyStopping(monitor='val_loss', patience=8, verbose=0)\n",
    "        mlflow.log_param(\"CPL\", True)\n",
    "\n",
    "        history = model.fit(x_train, y_train, epochs=1000, batch_size=2000,\n",
    "                            validation_data=(x_val, y_val),\n",
    "                            verbose=2,\n",
    "                            callbacks=[callback, model_checkpoint_callback])\n",
    "        \n",
    "        evaled_test = model.evaluate(x_train, y_train, batch_size=100, verbose=0)\n",
    "        evaled_train = model.evaluate(x_test, y_test, batch_size=100, verbose=0)\n",
    "\n",
    "        mlflow.log_metric(\"test_loss\", evaled_test)\n",
    "        mlflow.log_metric(\"train_loss\", evaled_train)\n",
    "\n",
    "        plt.plot(history.history[\"loss\"])\n",
    "        plt.plot(history.history[\"val_loss\"])\n",
    "        plt.title('Model Loss')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plotname = f\"plots/loss_plot_{run.info.run_id}.png\"\n",
    "        plt.savefig(plotname)\n",
    "        plt.close()\n",
    "\n",
    "        # Log the plot as an artifact\n",
    "        mlflow.log_artifact(plotname)\n",
    "        #model_path = \"modles\"\n",
    "        #mlflow.tensorflow.log_model(tf_saved_model_dir=model_path, artifact_path=\"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19977a72-b40a-4fe6-8bda-8f98932a5fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regs\n",
    "\n",
    "for _ in range(100):\n",
    "    config = {'shape': 22,\n",
    "              'output': 72,\n",
    "              'dropout': np.random.choice([0.01, 0.1, 0.2, 0.5]),\n",
    "              'num_layers': np.random.choice([3, 4, 5, 10]),\n",
    "              'num_neurons': np.random.choice([16, 32, 64, 128]),\n",
    "              'activation': np.random.choice(['gelu', 'gelu', 'relu'])}\n",
    "    \n",
    "    model = build_model(config)\n",
    "    \n",
    "    with mlflow.start_run() as run:\n",
    "        model_checkpoint_callback = ModelCheckpoint(\n",
    "            filepath=f\"models/model_{run.info.run_id}.keras\",\n",
    "            save_weights_only=False,\n",
    "            monitor='val_loss',\n",
    "            mode='min',\n",
    "            save_best_only=True)\n",
    "        callback = EarlyStopping(monitor='val_loss', patience=8, verbose=0)\n",
    "        mlflow.log_param(\"CPL\", False)\n",
    "\n",
    "        history = model.fit(x_train, y_train, epochs=1000, batch_size=2000,\n",
    "                            validation_data=(x_val, y_val),\n",
    "                            verbose=2,\n",
    "                            callbacks=[callback, model_checkpoint_callback])\n",
    "        \n",
    "        evaled_test = model.evaluate(x_train, y_train, batch_size=100, verbose=0)\n",
    "        evaled_train = model.evaluate(x_test, y_test, batch_size=100, verbose=0)\n",
    "\n",
    "        mlflow.log_metric(\"test_loss\", evaled_test)\n",
    "        mlflow.log_metric(\"train_loss\", evaled_train)\n",
    "\n",
    "        plt.plot(history.history[\"loss\"])\n",
    "        plt.plot(history.history[\"val_loss\"])\n",
    "        plt.title('Model Loss')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plotname = f\"plots/loss_plot_{run.info.run_id}.png\"\n",
    "        plt.savefig(plotname)\n",
    "        plt.close()\n",
    "\n",
    "        # Log the plot as an artifact\n",
    "        mlflow.log_artifact(plotname)\n",
    "        #model_path = \"modles\"\n",
    "        #mlflow.tensorflow.log_model(tf_saved_model_dir=model_path, artifact_path=\"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62d5b96-20c7-4802-939d-2135ffabe8bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
