from typing import Mapping
from abc import ABC, abstractmethod
from collections.abc import Sequence

import torch
import numpy as np
from pydantic import BaseModel

from hympi_ml.data.scale import Scaler
from hympi_ml.data.filter import Filter


class DataSource(BaseModel, ABC):
    """The base class for a source of data"""

    @property
    @abstractmethod
    def sample_count(self) -> int:
        """The total number of sample data points from this DataSource instance."""
        pass


class DataSpec(BaseModel, ABC):
    """A base class for the specification for some kind of data."""

    scaler: Scaler | None = None
    filter: Filter | None = None

    @property
    @abstractmethod
    def shape(self) -> tuple[int, ...]:
        pass

    @property
    @abstractmethod
    def units(self) -> str:
        pass

    @abstractmethod
    def load_raw_slice(self, source: DataSource, start: int, end: int) -> Sequence:
        """
        Load a slice of raw data from a DataSource with the provided 'start' and 'end' indices.
        """
        pass

    def transform_batch(self, batch: torch.Tensor) -> torch.Tensor:
        """
        Applies the data spec transformations to a single batch of raw data.
        """
        if self.scaler is not None:
            return self.scaler.scale_batch(batch)

        return batch

    def unscale_batch(self, batch: torch.Tensor) -> torch.Tensor:
        """
        Takes a scaled batch of data from this spec and unscales it based on the spec's scaler.
        """
        if self.scaler is not None:
            return self.scaler.unscale_batch(batch)

        return batch

    def get_filter_mask(self, batch: torch.Tensor) -> torch.Tensor:
        """
        Returns the mask generated by a batch of data based on the filter value of this spec.
        If filter is None, will return a positive mask for all samples in the batch.
        """
        if self.filter is not None:
            return self.filter.get_batch_mask(batch)

        return torch.ones(size=(batch.shape[0],), device=batch.device) == 1


class ModelDataSpec(BaseModel):
    """
    The set of DataSpec that is used to train or analyze models.
    This of this as a package of all of the important data specifications needed
    to train a specific kind of model.
    """

    features: Mapping[str, DataSpec]
    targets: Mapping[str, DataSpec]
    extras: Mapping[str, DataSpec] | None = None

    def transform_batch(
        self, raw_batch
    ) -> tuple[
        dict[str, torch.Tensor], dict[str, torch.Tensor], dict[str, torch.Tensor] | None
    ]:
        """
        Takes in a raw batch as a tuple of (features, targets, extras) and, based on
        the DataSpec's, will apply the correct scaling and filtering as needed.

        NOTE: The the filtering is applied *before* scaling!
        """
        features_batch, targets_batch, extras_batch = raw_batch

        # compute filter mask
        masks = [
            self.features[key].get_filter_mask(feature_batch)
            for key, feature_batch in features_batch.items()
        ]

        masks += [
            self.targets[key].get_filter_mask(target_batch)
            for key, target_batch in targets_batch.items()
        ]

        if self.extras is not None:
            masks += [
                self.extras[key].get_filter_mask(extra_batch)
                for key, extra_batch in extras_batch.items()
            ]

        final_mask = None

        for mask in masks:
            final_mask = (final_mask & mask) if (final_mask is not None) else mask

        # apply transformations and filter mask
        transformed_features = {
            k: self.features[k].transform_batch(features_batch[k][final_mask])
            for k in self.features.keys()
        }

        transformed_targets = {
            k: self.targets[k].transform_batch(targets_batch[k][final_mask])
            for k in self.targets.keys()
        }

        transformed_extras = None

        if self.extras is not None:
            transformed_extras = {
                k: self.extras[k].transform_batch(extras_batch[k][final_mask])
                for k in self.extras.keys()
            }

        return transformed_features, transformed_targets, transformed_extras

    def unscale_batch(self, scaled_batch):
        scaled_features, scaled_targets, scaled_extras = scaled_batch

        unscaled_features = {
            k: self.features[k].unscale_batch(scaled_features[k])
            for k in self.features.keys()
        }

        unscaled_targets = {
            k: self.targets[k].unscale_batch(scaled_targets[k])
            for k in self.targets.keys()
        }

        unscaled_extras = None
        if self.extras is not None:
            unscaled_extras = {
                k: self.extras[k].unscale_batch(scaled_extras[k])
                for k in self.extras.keys()
            }

        return unscaled_features, unscaled_targets, unscaled_extras

    def unscale_targets(self, scaled_targets):
        return {
            k: self.targets[k].unscale_batch(scaled_targets[k])
            for k in self.targets.keys()
        }

    def _raw_slice_to_tensor(self, raw_slice: Sequence) -> torch.Tensor:
        raw_tensor = torch.from_numpy(np.array(raw_slice, copy=True, dtype=np.float32))

        if len(raw_tensor.shape) == 1:
            raw_tensor = raw_tensor.reshape(-1, 1)

        return raw_tensor

    def load_raw_slice(
        self, source: DataSource, start: int, end: int
    ) -> tuple[
        dict[str, torch.Tensor], dict[str, torch.Tensor], dict[str, torch.Tensor] | None
    ]:
        """
        Load a slice of raw data from a DataSource with the provided 'start' and 'end' indices.
        """
        raw_features = {
            k: self._raw_slice_to_tensor(feature.load_raw_slice(source, start, end))
            for k, feature in self.features.items()
        }

        raw_targets = {
            k: self._raw_slice_to_tensor(target.load_raw_slice(source, start, end))
            for k, target in self.targets.items()
        }

        if self.extras is not None:
            raw_extras = {
                k: self._raw_slice_to_tensor(extra.load_raw_slice(source, start, end))
                for k, extra in self.extras.items()
            }
        else:
            raw_extras = None

        return raw_features, raw_targets, raw_extras
