{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008ce633-8ecc-4d52-a254-a0784d743198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import isfile\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5\"\n",
    "#os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"]=\"true\"\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"]=\"cuda_malloc_async\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import L1, L2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import mlflow\n",
    "import mlflow.tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3ea1be-bfd5-4112-989a-8d9bd16bcb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.tensorflow.autolog()\n",
    "mlflow.set_experiment(\"HSEL ae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c6bafc-be5f-4bcb-9bd9-16ea3147f262",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"/data/nature_run/fulldays_reduced_evenmore/*.npz\")\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10dada0-c81e-47a0-a73a-29eda171cadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AE\n",
    "\n",
    "a = [\"/data/nature_run/fulldays_reduced_evenmore/20060615/hsel.npy\",\n",
    "\"/data/nature_run/fulldays_reduced_evenmore/20061215/hsel.npy\",\n",
    "\"/data/nature_run/fulldays_reduced_evenmore/20060515/hsel.npy\",\n",
    "\"/data/nature_run/fulldays_reduced_evenmore/20060815/hsel.npy\",\n",
    "\"/data/nature_run/fulldays_reduced_evenmore/20060915/hsel.npy\",\n",
    "\"/data/nature_run/fulldays_reduced_evenmore/20060715/hsel.npy\",\n",
    "\"/data/nature_run/fulldays_reduced_evenmore/20061015/hsel.npy\",\n",
    "\"/data/nature_run/fulldays_reduced_evenmore/20060315/hsel.npy\",\n",
    "\"/data/nature_run/fulldays_reduced_evenmore/20061115/hsel.npy\"]\n",
    "\n",
    "hsel_val = []\n",
    "\n",
    "for i in a:\n",
    "    # Keys: 'mh', 'hsel', 'scalar', 'table']\n",
    "    tmp = np.load(i)\n",
    "    hsel_val.append(tmp)\n",
    "hsel = np.vstack(hsel_val)\n",
    "print(hsel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be920c2f-3b4e-4634-b93d-31df70c9070a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AE\n",
    "\n",
    "mins = np.min(hsel, axis=0)\n",
    "maxs = np.max(hsel, axis=0)\n",
    "hsel = (hsel - mins)/(maxs - mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8b7556-bc62-4b99-9357-665d794e73d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    x_train = tf.convert_to_tensor(hsel, np.float32)\n",
    "    y_train = tf.convert_to_tensor(hsel, np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f53e02-ccbb-4e62-aa15-767d1a0283e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "del hsel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c437fcd1-6b26-42d3-ab0a-91c17476ddde",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_autoencoder(input_dim, latent_dim):\n",
    "    # Encoder\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    act = 'relu'\n",
    "    #act = 'gelu'\n",
    "    #act = \"sigmoid\"\n",
    "    \n",
    "    encoder = Dense(72, activation=act)(input_layer)\n",
    "    encoder = Dense(60, activation=act)(encoder)\n",
    "    encoder = Dense(40, activation=act)(encoder)\n",
    "    \n",
    "    latent_space = Dense(latent_dim, activation=\"linear\")(encoder)\n",
    "\n",
    "    decoder = Dense(40, activation=act)(latent_space)\n",
    "    decoder = Dense(60, activation=act)(decoder)\n",
    "    decoder = Dense(72, activation=act)(decoder)\n",
    "    output_layer = Dense(input_dim, activation='linear')(decoder)\n",
    "\n",
    "    # Autoencoder model\n",
    "    autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
    "    encoder_model = Model(inputs=input_layer, outputs=latent_space)\n",
    "\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    \n",
    "    return autoencoder, encoder_model\n",
    "model, enc = build_autoencoder(1957, 32)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f1a860-df2b-4a2f-b155-744866a2dcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run() as run:\n",
    "    history = model.fit(x_train, y_train, epochs=1000, batch_size=2000, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7248f311-6548-40ff-be07-07dde2647383",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3ea1a6-3bcb-47bd-92ea-1e00f31589e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"shitty_ae.keras\")\n",
    "enc.save(\"shitty_enc.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2011ba2-a13f-47c1-8387-018d05bce551",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4400956-8bbf-4641-baf1-1f1f43927b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.predict(x_train, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44a414f-54fe-4063-a1fc-2d7e3b6146f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 0\n",
    "\n",
    "plt.plot(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b48a92-7531-44b6-8461-5c367878d930",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(filelist):\n",
    "    hsel_val = []\n",
    "    scalar_val = []\n",
    "    table_val = []\n",
    "\n",
    "    for i in filelist:\n",
    "        # Keys: 'mh', 'hsel', 'scalar', 'table']\n",
    "        tmp = np.load(i)\n",
    "        hsel_val.append(tmp[\"hsel\"])\n",
    "        scalar_val.append(tmp[\"scalar\"])\n",
    "        table_val.append(tmp[\"table\"])\n",
    "\n",
    "    return np.vstack(hsel_val), np.vstack(scalar_val), np.vstack(table_val)\n",
    "\n",
    "\n",
    "train = ['/data/nature_run/fulldays_reduced_evenmore/all_20060815.npz',\n",
    "         '/data/nature_run/fulldays_reduced_evenmore/all_20060915.npz',\n",
    "         '/data/nature_run/fulldays_reduced_evenmore/all_20061015.npz',\n",
    "         '/data/nature_run/fulldays_reduced_evenmore/all_20060515.npz',\n",
    "         '/data/nature_run/fulldays_reduced_evenmore/all_20060715.npz',\n",
    "         '/data/nature_run/fulldays_reduced_evenmore/all_20061115.npz',\n",
    "         '/data/nature_run/fulldays_reduced_evenmore/all_20060315.npz', \n",
    "         '/data/nature_run/fulldays_reduced_evenmore/all_20061215.npz',\n",
    "         '/data/nature_run/fulldays_reduced_evenmore/all_20060615.npz']\n",
    "\n",
    "test = ['/data/nature_run/fulldays_reduced_evenmore/all_20060803.npz']\n",
    "\n",
    "validation = ['/data/nature_run/fulldays_reduced_evenmore/all_20060803.npz']\n",
    "\n",
    "hsel_train, scalar_train, table_train = get_data(train)\n",
    "hsel_test, scalar_test, table_test = get_data(test)\n",
    "hsel_val, scalar_val, table_val = get_data(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60acad29-2adf-4f8a-a5c3-cd98a9b63d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(filelist):\n",
    "    hsel_val = []\n",
    "    scalar_val = []\n",
    "    table_val = []\n",
    "\n",
    "    for i in filelist:\n",
    "        # Keys: 'mh', 'hsel', 'scalar', 'table']\n",
    "        tmp = np.load(i)\n",
    "        hsel_val.append(tmp[\"hsel\"])\n",
    "        scalar_val.append(tmp[\"scalar\"])\n",
    "        table_val.append(tmp[\"table\"])\n",
    "\n",
    "    return np.vstack(hsel_val), np.vstack(scalar_val), np.vstack(table_val)\n",
    "\n",
    "\n",
    "train = ['/data/nature_run/fulldays_reduced_evenmore/all_20060815.npz',\n",
    "         '/data/nature_run/fulldays_reduced_evenmore/all_20060915.npz',\n",
    "         '/data/nature_run/fulldays_reduced_evenmore/all_20061015.npz',\n",
    "         '/data/nature_run/fulldays_reduced_evenmore/all_20060515.npz',\n",
    "         '/data/nature_run/fulldays_reduced_evenmore/all_20060715.npz',\n",
    "         '/data/nature_run/fulldays_reduced_evenmore/all_20061115.npz',\n",
    "         '/data/nature_run/fulldays_reduced_evenmore/all_20060315.npz', \n",
    "         '/data/nature_run/fulldays_reduced_evenmore/all_20061215.npz',\n",
    "         '/data/nature_run/fulldays_reduced_evenmore/all_20060615.npz']\n",
    "\n",
    "test = ['/data/nature_run/fulldays_reduced_evenmore/all_20060803.npz']\n",
    "\n",
    "validation = ['/data/nature_run/fulldays_reduced_evenmore/all_20060803.npz']\n",
    "\n",
    "hsel_train, scalar_train, table_train = get_data(train)\n",
    "hsel_test, scalar_test, table_test = get_data(test)\n",
    "hsel_val, scalar_val, table_val = get_data(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2751b636-5210-4f12-8989-d3f9b0a29eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Presssure\n",
    "spress_test = scalar_test[:, 3].reshape(-1, 1)\n",
    "spress_train = scalar_train[:, 3].reshape(-1, 1)\n",
    "spress_val = scalar_val[:, 3].reshape(-1, 1)\n",
    "\n",
    "mins = np.min(spress_train, axis=0)\n",
    "maxs = np.max(spress_train, axis=0)\n",
    "\n",
    "np.savez(\"spress_scalar.npz\", mins=mins, maxs=maxs)\n",
    "spress_test = (spress_test - mins)/(maxs - mins)\n",
    "spress_train = (spress_train - mins)/(maxs - mins)\n",
    "spress_val = (spress_val - mins)/(maxs - mins)\n",
    "\n",
    "\n",
    "# Labels\n",
    "q_train = table_train[:, :, 1]\n",
    "q_test = table_test[:, :, 1]\n",
    "q_val = table_val[:, :, 1]\n",
    "\n",
    "# Spectra\n",
    "\n",
    "mins = np.min(hsel_train, axis=0)\n",
    "maxs = np.max(hsel_train, axis=0)\n",
    "np.savez(\"minimac_scaling_factors_hsel_v2.npz\", mins=mins, maxs=maxs)\n",
    "\n",
    "#s_factors = np.load(\"minimac_scaling_factors_hsel.npz\")\n",
    "#mins = s_factors['mins']\n",
    "#maxs = s_factors['maxs']\n",
    "\n",
    "hsel_train = np.nan_to_num(hsel_train)\n",
    "hsel_test = np.nan_to_num(hsel_test)\n",
    "hsel_val = np.nan_to_num(hsel_val)\n",
    "\n",
    "hsel_train = (hsel_train - mins)/(maxs - mins)\n",
    "hsel_test = (hsel_test - mins)/(maxs - mins)\n",
    "hsel_val = (hsel_val - mins)/(maxs - mins)\n",
    "\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    # train\n",
    "    x_train = {'rad': tf.convert_to_tensor(hsel_train, np.float32),\n",
    "               'spress': tf.convert_to_tensor(spress_train, np.float32)}\n",
    "    del hsel_train\n",
    "    del spress_train\n",
    "    \n",
    "    y_train =  tf.convert_to_tensor(q_train, np.float32)\n",
    "    del q_train\n",
    "\n",
    "    \n",
    "    # Val\n",
    "    x_val = {'rad': tf.convert_to_tensor(hsel_val, np.float32),\n",
    "             'spress': tf.convert_to_tensor(spress_val, np.float32)}\n",
    "    del hsel_val\n",
    "    del spress_val\n",
    "    \n",
    "    y_val =  tf.convert_to_tensor(q_val, np.float32)\n",
    "    del q_val\n",
    "\n",
    "    \n",
    "    # Test\n",
    "    x_test = {'rad': tf.convert_to_tensor(hsel_test, np.float32),\n",
    "              'spress': tf.convert_to_tensor(spress_test, np.float32)}\n",
    "    del hsel_test\n",
    "    del spress_test\n",
    "    \n",
    "    y_test =  tf.convert_to_tensor(q_test, np.float32)\n",
    "    del q_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fdbe91-dd90-46b1-b519-60d0fd1da662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ae_model(config):\n",
    "    # ATMS 22\n",
    "    mh = Input(shape=(config[\"shape\"],), name=\"rad\")\n",
    "    spress = Input(shape=(1,), name=\"spress\")\n",
    "    # [ha, hb, hc, hd, hw, mh]\n",
    "\n",
    "    encoder = load_model(\"encoder_3_mae.keras\")\n",
    "    encoder.trainable = False\n",
    "    #for layer in encoder.layers:\n",
    "    #    layer.trainable = False\n",
    "\n",
    "    \n",
    "    enc = encoder(mh)\n",
    "    x = Concatenate()([enc, spress])\n",
    "    for i in range(config[\"num_layers\"]):\n",
    "        x =  Dropout(config[\"dropout\"])(Dense(config[\"num_neurons\"], \n",
    "                                             activation=config[\"activation\"])(x))\n",
    "    outputs = Dense(config['output'], name=\"Temp\")(x)\n",
    "\n",
    "    model = Model(inputs=[mh, spress], outputs=outputs, name=\"Temp\")\n",
    "    model.compile(optimizer=\"adam\", loss='mae')\n",
    "\n",
    "    return model\n",
    "\n",
    "config = {'shape': 1957,\n",
    "          'output': 72,\n",
    "          'dropout': np.random.choice([0.01, 0.1, 0.2, 0.5]),\n",
    "          'num_layers': np.random.choice([3, 4, 5, 10]),\n",
    "          'num_neurons': np.random.choice([16, 32, 64, 128]),\n",
    "          'activation': np.random.choice(['gelu', 'gelu', 'relu'])}\n",
    "\n",
    "model = build_ae_model(config)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137680e3-1dc6-4550-8561-a37c87676066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(config):\n",
    "    # ATMS 22\n",
    "    mh = Input(shape=(config[\"shape\"],), name=\"rad\")\n",
    "    spress = Input(shape=(1,), name=\"spress\")\n",
    "    # [ha, hb, hc, hd, hw, mh]\n",
    "    \n",
    "    x = Concatenate()([mh, spress])\n",
    "    for i in range(config[\"num_layers\"]):\n",
    "        x =  Dropout(config[\"dropout\"])(Dense(config[\"num_neurons\"], \n",
    "                                             activation=config[\"activation\"])(x))\n",
    "    outputs = Dense(config['output'], name=\"Temp\")(x)\n",
    "\n",
    "    model = Model(inputs=[mh, spress], outputs=outputs, name=\"Temp\")\n",
    "    model.compile(optimizer=\"adam\", loss='mae')\n",
    "\n",
    "    return model\n",
    "\n",
    "config = {'shape': 1957,\n",
    "          'output': 72,\n",
    "          'dropout': np.random.choice([0.01, 0.1, 0.2, 0.5]),\n",
    "          'num_layers': np.random.choice([3, 4, 5, 10]),\n",
    "          'num_neurons': np.random.choice([16, 32, 64, 128]),\n",
    "          'activation': np.random.choice(['gelu', 'gelu', 'relu'])}\n",
    "\n",
    "model = build_model(config)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3081d9a-e65b-44d5-9c98-9558667c04ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b849f517-93eb-4370-bff5-0d7e79fc93cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AE\n",
    "num_runs = 100\n",
    "\n",
    "for _ in range(num_runs):\n",
    "    config = {'shape': 1957,\n",
    "              'output': 72,\n",
    "              'dropout': np.random.choice([0.01, 0.1, 0.2, 0.5]),\n",
    "              'num_layers': np.random.choice([3, 4, 5, 10]),\n",
    "              'num_neurons': np.random.choice([16, 32, 64, 128]),\n",
    "              'activation': np.random.choice(['gelu', 'gelu', 'relu'])}\n",
    "    \n",
    "    ae = np.random.choice([False, True, True])\n",
    "    if ae:\n",
    "        model = build_ae_model(config)\n",
    "    else:\n",
    "        model = build_model(config)\n",
    "    \n",
    "    with mlflow.start_run() as run:\n",
    "        model_checkpoint_callback = ModelCheckpoint(\n",
    "            filepath=f\"models/model_{run.info.run_id}.keras\",\n",
    "            save_weights_only=False,\n",
    "            monitor='val_loss',\n",
    "            mode='min',\n",
    "            save_best_only=True)\n",
    "        callback = EarlyStopping(monitor='val_loss', patience=10, verbose=0)\n",
    "        mlflow.log_param(\"Autoencoder\", ae)\n",
    "\n",
    "        history = model.fit(x_train, y_train, epochs=1000, batch_size=2000,\n",
    "                            validation_data=(x_val, y_val),\n",
    "                            callbacks=[callback, model_checkpoint_callback])\n",
    "        \n",
    "        evaled_test = model.evaluate(x_train, y_train, batch_size=100)\n",
    "        evaled_train = model.evaluate(x_test, y_test, batch_size=100)\n",
    "\n",
    "        mlflow.log_metric(\"test_loss\", evaled_test)\n",
    "        mlflow.log_metric(\"train_loss\", evaled_train)\n",
    "\n",
    "        plt.plot(history.history[\"loss\"])\n",
    "        plt.plot(history.history[\"val_loss\"])\n",
    "        plt.title('Model Loss')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plotname = f\"plots/loss_plot_{run.info.run_id}.png\"\n",
    "        plt.savefig(plotname)\n",
    "        plt.close()\n",
    "\n",
    "        # Log the plot as an artifact\n",
    "        mlflow.log_artifact(plotname)\n",
    "        #model_path = \"modles\"\n",
    "        #mlflow.tensorflow.log_model(tf_saved_model_dir=model_path, artifact_path=\"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62d5b96-20c7-4802-939d-2135ffabe8bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
