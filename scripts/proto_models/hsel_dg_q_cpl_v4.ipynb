{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "008ce633-8ecc-4d52-a254-a0784d743198",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-29 19:48:41.401198: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-29 19:48:41.533444: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import isfile\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\"\n",
    "#os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"]=\"true\"\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"]=\"cuda_malloc_async\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import L1, L2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import mlflow\n",
    "import mlflow.tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea3ea1be-bfd5-4112-989a-8d9bd16bcb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/29 19:48:45 INFO mlflow.tracking.fluent: Experiment with name 'HSEL+CPL q' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///data/nature_run/work/src/mlruns/424939423499244567', creation_time=1727653725883, experiment_id='424939423499244567', last_update_time=1727653725883, lifecycle_stage='active', name='HSEL+CPL q', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.tensorflow.autolog()\n",
    "mlflow.set_experiment(\"HSEL+CPL q\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92b48a92-7531-44b6-8461-5c367878d930",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(filelist):\n",
    "    hsel_val = []\n",
    "    scalar_val = []\n",
    "    table_val = []\n",
    "    cpl_val = []\n",
    "\n",
    "    for i in filelist:\n",
    "        # Keys: 'mh', 'hsel', 'scalar', 'table']\n",
    "        tmp = np.load(i)\n",
    "        hsel_val.append(tmp[\"hsel\"])\n",
    "        scalar_val.append(tmp[\"scalar\"])\n",
    "        table_val.append(tmp[\"table\"])\n",
    "        cpl_val.append(tmp[\"cpl\"])\n",
    "\n",
    "    return np.vstack(hsel_val), np.vstack(cpl_val), np.vstack(scalar_val), np.vstack(table_val)\n",
    "\n",
    "\n",
    "train = ['/data/nature_run/fulldays_reduced/all_cpl_20060815.npz',\n",
    "         '/data/nature_run/fulldays_reduced/all_cpl_20060915.npz',\n",
    "         '/data/nature_run/fulldays_reduced/all_cpl_20061015.npz',\n",
    "         '/data/nature_run/fulldays_reduced/all_cpl_20060515.npz',\n",
    "         '/data/nature_run/fulldays_reduced/all_cpl_20060715.npz',\n",
    "         '/data/nature_run/fulldays_reduced/all_cpl_20061115.npz',\n",
    "         '/data/nature_run/fulldays_reduced/all_cpl_20060315.npz', \n",
    "         '/data/nature_run/fulldays_reduced/all_cpl_20061215.npz',\n",
    "         '/data/nature_run/fulldays_reduced/all_cpl_20060615.npz']\n",
    "\n",
    "test = ['/data/nature_run/fulldays_reduced/all_cpl_20060803.npz']\n",
    "\n",
    "validation = ['/data/nature_run/fulldays_reduced/all_cpl_20060803.npz']\n",
    "\n",
    "hsel_train, cpl_train, scalar_train, table_train = get_data(train)\n",
    "hsel_test, cpl_test, scalar_test, table_test = get_data(test)\n",
    "hsel_val, cpl_val, scalar_val, table_val = get_data(validation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c5ebff-6c25-4ae4-a936-6e372a7a3147",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hsel_train, table_train, scalar_train, hsel_test, table_test, scalar_test = dataload(\"mh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e5dbb2-4a9a-419a-baf7-be1ced137464",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hsel_train, table_train, scalar_train, hsel_test, table_test, scalar_test = dataload(\"mh\")\n",
    "#hsel_val = hsel_test.copy()\n",
    "#table_val = table_test.copy()\n",
    "#scalar_val = scalar_test.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e622c75-32d0-47dd-8af7-7d25a1d78f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hsel_train.shape)\n",
    "print(cpl_train.shape)\n",
    "print(table_train.shape)\n",
    "print(scalar_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2751b636-5210-4f12-8989-d3f9b0a29eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-29 21:00:30.146843: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-29 21:00:30.722372: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-09-29 21:00:30.723385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31017 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:88:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "# What should we do\n",
    "# 1) Only use train scalars\n",
    "# 2) Scale seperateley\n",
    "\n",
    "\n",
    "# Presssure ####\n",
    "spress_test = scalar_test[:, 3].reshape(-1, 1)\n",
    "spress_train = scalar_train[:, 3].reshape(-1, 1)\n",
    "spress_val = scalar_val[:, 3].reshape(-1, 1)\n",
    "\n",
    "mins = np.min(spress_train, axis=0)\n",
    "maxs = np.max(spress_train, axis=0)\n",
    "np.savez(\"spress_scalar_cpl.npz\", mins=mins, maxs=maxs)\n",
    "\n",
    "spress_test = (spress_test - mins)/(maxs - mins)\n",
    "spress_train = (spress_train - mins)/(maxs - mins)\n",
    "spress_val = (spress_val - mins)/(maxs - mins)\n",
    "\n",
    "\n",
    "# Labels ####\n",
    "q_train = table_train[:, :, 2]\n",
    "q_test = table_test[:, :, 2]\n",
    "q_val = table_val[:, :, 2]\n",
    "\n",
    "# Spectra ####\n",
    "mins = np.min(hsel_train, axis=0)\n",
    "maxs = np.max(hsel_train, axis=0)\n",
    "\n",
    "np.savez(\"minimac_scaling_factors_cpl_mh.npz\", maxs=maxs, mins=mins)\n",
    "\n",
    "hsel_train = np.nan_to_num(hsel_train)\n",
    "hsel_test = np.nan_to_num(hsel_test)\n",
    "hsel_val = np.nan_to_num(hsel_val)\n",
    "\n",
    "hsel_train = (hsel_train - mins)/(maxs - mins)\n",
    "hsel_test = (hsel_test - mins)/(maxs - mins)\n",
    "hsel_val = (hsel_val - mins)/(maxs - mins)\n",
    "\n",
    "# CPL #####\n",
    "mins = np.min(cpl_train, axis=0)\n",
    "maxs = np.max(cpl_train, axis=0)\n",
    "np.savez(\"minimac_scaling_factors_cpl_cpl.npz\", maxs=maxs, mins=mins)\n",
    "\n",
    "cpl_train = (cpl_train - mins)/(maxs - mins)\n",
    "cpl_test = (cpl_test - mins)/(maxs - mins)\n",
    "cpl_val = (cpl_val - mins)/(maxs - mins)\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    # train\n",
    "    x_train = {'rad': tf.convert_to_tensor(hsel_train, np.float32),\n",
    "               'spress': tf.convert_to_tensor(spress_train, np.float32),\n",
    "               'cpl': tf.convert_to_tensor(cpl_train, np.float32)}\n",
    "    del hsel_train\n",
    "    del spress_train\n",
    "    \n",
    "    y_train =  tf.convert_to_tensor(q_train, np.float32)\n",
    "    del q_train\n",
    "\n",
    "    \n",
    "    # Val\n",
    "    x_val = {'rad': tf.convert_to_tensor(hsel_val, np.float32),\n",
    "             'spress': tf.convert_to_tensor(spress_val, np.float32),\n",
    "             'cpl': tf.convert_to_tensor(cpl_val, np.float32)}\n",
    "    del hsel_val\n",
    "    del spress_val\n",
    "    \n",
    "    y_val =  tf.convert_to_tensor(q_val, np.float32)\n",
    "    del q_val\n",
    "\n",
    "    \n",
    "    # Test\n",
    "    x_test = {'rad': tf.convert_to_tensor(hsel_test, np.float32),\n",
    "              'spress': tf.convert_to_tensor(spress_test, np.float32),\n",
    "              'cpl': tf.convert_to_tensor(cpl_test, np.float32)}\n",
    "    del hsel_test\n",
    "    del spress_test\n",
    "    \n",
    "    y_test =  tf.convert_to_tensor(q_test, np.float32)\n",
    "    del q_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66848f44-450d-4748-b044-1d8a1da680a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(x_test)\n",
    "# print(x_val)\n",
    "# print(y_train.shape)\n",
    "#a = np.argwhere(np.isnan(x_train['rad']))\n",
    "#print(np.sum(np.isnan(x_train['rad'])))\n",
    "#np.nan_to_num(x_train['rad'], copy=False)\n",
    "#print(np.sum(np.isnan(x_train['rad'])))\n",
    "#print(a)\n",
    "#print(len(a))\n",
    "\n",
    "np.sum(np.isnan(x_train['rad']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea81c3db-993b-4c0d-8af7-4b3f35665f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"q\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " rad (InputLayer)               [(None, 1957)]       0           []                               \n",
      "                                                                                                  \n",
      " model_1 (Functional)           (None, 64)           275468      ['rad[0][0]']                    \n",
      "                                                                                                  \n",
      " spress (InputLayer)            [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 65)           0           ['model_1[0][0]',                \n",
      "                                                                  'spress[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 16)           1056        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 16)           0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 16)           272         ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 16)           0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 16)           272         ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 16)           0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 16)           272         ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 16)           0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " Temp (Dense)                   (None, 72)           1224        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 278,564\n",
      "Trainable params: 3,096\n",
      "Non-trainable params: 275,468\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_ae_model(config):\n",
    "    # HSEL 22\n",
    "    mh = Input(shape=(config[\"shape\"],), name=\"rad\")\n",
    "    spress = Input(shape=(1,), name=\"spress\")\n",
    "    #cpl = Input(shape=(733,), name=\"cpl\")\n",
    "    # [ha, hb, hc, hd, hw, mh]\n",
    "\n",
    "    encoder = load_model(\"encoder_3_mae.keras\")\n",
    "    encoder.trainable = False\n",
    "\n",
    "    #cpl_reduced = Dense(128, activation=config[\"activation\"])(cpl)\n",
    "    #cpl_reduced = Dense(32, activation=config[\"activation\"])(cpl_reduced)\n",
    "    \n",
    "    enc = encoder(mh)\n",
    "    x = Concatenate()([enc, spress])\n",
    "    for i in range(config[\"num_layers\"]):\n",
    "        x =  Dropout(config[\"dropout\"])(Dense(config[\"num_neurons\"], \n",
    "                                             activation=config[\"activation\"])(x))\n",
    "    outputs = Dense(config['output'], name=\"Temp\")(x)\n",
    "\n",
    "    model = Model(inputs=[mh, spress], outputs=outputs, name=\"q\")\n",
    "    model.compile(optimizer=\"adam\", loss='mae')\n",
    "\n",
    "    return model\n",
    "\n",
    "config = {'shape': 1957,\n",
    "          'output': 72,\n",
    "          'dropout': np.random.choice([0.01, 0.1, 0.2, 0.5]),\n",
    "          'num_layers': np.random.choice([3, 4, 5, 10]),\n",
    "          'num_neurons': np.random.choice([16, 32, 64, 128]),\n",
    "          'activation': np.random.choice(['gelu', 'gelu', 'relu'])}\n",
    "\n",
    "model = build_ae_model(config)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "137680e3-1dc6-4550-8561-a37c87676066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"q\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " rad (InputLayer)               [(None, 1957)]       0           []                               \n",
      "                                                                                                  \n",
      " model_1 (Functional)           (None, 64)           275468      ['rad[0][0]']                    \n",
      "                                                                                                  \n",
      " spress (InputLayer)            [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 65)           0           ['model_1[0][0]',                \n",
      "                                                                  'spress[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 64)           4224        ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 64)           0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 64)           4160        ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 64)           0           ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 64)           4160        ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 64)           0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 64)           4160        ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 64)           0           ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 64)           4160        ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 64)           0           ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " Temp (Dense)                   (None, 72)           4680        ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 301,012\n",
      "Trainable params: 25,544\n",
      "Non-trainable params: 275,468\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_ae_cpl_model(config):\n",
    "    # ATMS 22\n",
    "    mh = Input(shape=(config[\"shape\"],), name=\"rad\")\n",
    "    spress = Input(shape=(1,), name=\"spress\")\n",
    "    cpl = Input(shape=(733,), name=\"cpl\")\n",
    "    # [ha, hb, hc, hd, hw, mh]\n",
    "\n",
    "    encoder = load_model(\"encoder_3_mae.keras\")\n",
    "    encoder.trainable = False\n",
    "\n",
    "    cpl_reduced = Dense(128, activation=config[\"activation\"])(cpl)\n",
    "    cpl_reduced = Dense(32, activation=config[\"activation\"])(cpl_reduced)\n",
    "    \n",
    "    enc = encoder(mh)\n",
    "    x = Concatenate()([enc, spress, cpl_reduced])\n",
    "    for i in range(config[\"num_layers\"]):\n",
    "        x =  Dropout(config[\"dropout\"])(Dense(config[\"num_neurons\"], \n",
    "                                             activation=config[\"activation\"])(x))\n",
    "    outputs = Dense(config['output'], name=\"Temp\")(x)\n",
    "\n",
    "    model = Model(inputs=[mh, spress, cpl], outputs=outputs, name=\"q\")\n",
    "    model.compile(optimizer=\"adam\", loss='mae')\n",
    "\n",
    "    return model\n",
    "\n",
    "config = {'shape': 1957,\n",
    "          'output': 72,\n",
    "          'dropout': np.random.choice([0.01, 0.1, 0.2, 0.5]),\n",
    "          'num_layers': np.random.choice([3, 4, 5, 10]),\n",
    "          'num_neurons': np.random.choice([16, 32, 64, 128]),\n",
    "          'activation': np.random.choice(['gelu', 'gelu', 'relu'])}\n",
    "\n",
    "model = build_ae_model(config)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3081d9a-e65b-44d5-9c98-9558667c04ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DING\n"
     ]
    }
   ],
   "source": [
    "print(\"DING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b849f517-93eb-4370-bff5-0d7e79fc93cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/29 21:20:17 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/29 21:20:17 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 71s - loss: 0.0014 - val_loss: 5.5836e-04 - 71s/epoch - 17ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 69s - loss: 5.8657e-04 - val_loss: 5.4408e-04 - 69s/epoch - 16ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 67s - loss: 5.6945e-04 - val_loss: 5.1746e-04 - 67s/epoch - 16ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 67s - loss: 5.1922e-04 - val_loss: 4.5836e-04 - 67s/epoch - 16ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 66s - loss: 5.0480e-04 - val_loss: 4.4960e-04 - 66s/epoch - 16ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 65s - loss: 5.0404e-04 - val_loss: 4.4677e-04 - 65s/epoch - 16ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 66s - loss: 5.0209e-04 - val_loss: 4.3893e-04 - 66s/epoch - 16ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 65s - loss: 5.0082e-04 - val_loss: 4.5013e-04 - 65s/epoch - 16ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 64s - loss: 5.0015e-04 - val_loss: 4.4245e-04 - 64s/epoch - 15ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 65s - loss: 5.0024e-04 - val_loss: 4.5449e-04 - 65s/epoch - 15ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 65s - loss: 4.9890e-04 - val_loss: 4.4825e-04 - 65s/epoch - 15ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 65s - loss: 4.9783e-04 - val_loss: 4.3901e-04 - 65s/epoch - 16ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 65s - loss: 4.9823e-04 - val_loss: 4.5414e-04 - 65s/epoch - 15ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 65s - loss: 4.9603e-04 - val_loss: 4.5148e-04 - 65s/epoch - 15ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 64s - loss: 4.9638e-04 - val_loss: 4.6500e-04 - 64s/epoch - 15ms/step\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpo_8m9dkh/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/29 21:37:55 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/data/jmackin1/miniconda/envs/tf-gpu/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/29 21:42:54 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/29 21:42:54 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 64s - loss: 0.0019 - val_loss: 6.2061e-04 - 64s/epoch - 15ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 65s - loss: 6.3472e-04 - val_loss: 5.5750e-04 - 65s/epoch - 15ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 64s - loss: 6.0864e-04 - val_loss: 5.2478e-04 - 64s/epoch - 15ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 62s - loss: 5.7556e-04 - val_loss: 4.8087e-04 - 62s/epoch - 15ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 61s - loss: 5.5980e-04 - val_loss: 4.8991e-04 - 61s/epoch - 15ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 62s - loss: 5.5705e-04 - val_loss: 4.8246e-04 - 62s/epoch - 15ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 62s - loss: 5.5264e-04 - val_loss: 4.7132e-04 - 62s/epoch - 15ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 62s - loss: 5.5323e-04 - val_loss: 4.7163e-04 - 62s/epoch - 15ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 61s - loss: 5.5331e-04 - val_loss: 4.8736e-04 - 61s/epoch - 15ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 61s - loss: 5.5225e-04 - val_loss: 4.8254e-04 - 61s/epoch - 15ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 62s - loss: 5.5198e-04 - val_loss: 4.7049e-04 - 62s/epoch - 15ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 63s - loss: 5.5131e-04 - val_loss: 4.7108e-04 - 63s/epoch - 15ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 62s - loss: 5.5158e-04 - val_loss: 4.8893e-04 - 62s/epoch - 15ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 62s - loss: 5.5018e-04 - val_loss: 4.7535e-04 - 62s/epoch - 15ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 63s - loss: 5.5028e-04 - val_loss: 4.7177e-04 - 63s/epoch - 15ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 63s - loss: 5.5047e-04 - val_loss: 4.6590e-04 - 63s/epoch - 15ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 62s - loss: 5.5068e-04 - val_loss: 4.7104e-04 - 62s/epoch - 15ms/step\n",
      "Epoch 18/1000\n",
      "4208/4208 - 63s - loss: 5.5275e-04 - val_loss: 4.7626e-04 - 63s/epoch - 15ms/step\n",
      "Epoch 19/1000\n",
      "4208/4208 - 65s - loss: 5.5143e-04 - val_loss: 4.6754e-04 - 65s/epoch - 15ms/step\n",
      "Epoch 20/1000\n",
      "4208/4208 - 65s - loss: 5.5086e-04 - val_loss: 4.7563e-04 - 65s/epoch - 15ms/step\n",
      "Epoch 21/1000\n",
      "4208/4208 - 62s - loss: 5.4923e-04 - val_loss: 4.8525e-04 - 62s/epoch - 15ms/step\n",
      "Epoch 22/1000\n",
      "4208/4208 - 63s - loss: 5.5221e-04 - val_loss: 4.7787e-04 - 63s/epoch - 15ms/step\n",
      "Epoch 23/1000\n",
      "4208/4208 - 63s - loss: 5.5144e-04 - val_loss: 4.6336e-04 - 63s/epoch - 15ms/step\n",
      "Epoch 24/1000\n",
      "4208/4208 - 62s - loss: 5.5073e-04 - val_loss: 4.7463e-04 - 62s/epoch - 15ms/step\n",
      "Epoch 25/1000\n",
      "4208/4208 - 63s - loss: 5.4807e-04 - val_loss: 4.7205e-04 - 63s/epoch - 15ms/step\n",
      "Epoch 26/1000\n",
      "4208/4208 - 62s - loss: 5.5001e-04 - val_loss: 4.9386e-04 - 62s/epoch - 15ms/step\n",
      "Epoch 27/1000\n",
      "4208/4208 - 61s - loss: 5.5123e-04 - val_loss: 4.8533e-04 - 61s/epoch - 15ms/step\n",
      "Epoch 28/1000\n",
      "4208/4208 - 61s - loss: 5.5201e-04 - val_loss: 4.6197e-04 - 61s/epoch - 15ms/step\n",
      "Epoch 29/1000\n",
      "4208/4208 - 62s - loss: 5.5069e-04 - val_loss: 4.8231e-04 - 62s/epoch - 15ms/step\n",
      "Epoch 30/1000\n",
      "4208/4208 - 61s - loss: 5.5078e-04 - val_loss: 4.7136e-04 - 61s/epoch - 15ms/step\n",
      "Epoch 31/1000\n",
      "4208/4208 - 63s - loss: 5.5129e-04 - val_loss: 4.8498e-04 - 63s/epoch - 15ms/step\n",
      "Epoch 32/1000\n",
      "4208/4208 - 62s - loss: 5.5011e-04 - val_loss: 4.6908e-04 - 62s/epoch - 15ms/step\n",
      "Epoch 33/1000\n",
      "4208/4208 - 63s - loss: 5.4805e-04 - val_loss: 4.6667e-04 - 63s/epoch - 15ms/step\n",
      "Epoch 34/1000\n",
      "4208/4208 - 62s - loss: 5.5058e-04 - val_loss: 4.7778e-04 - 62s/epoch - 15ms/step\n",
      "Epoch 35/1000\n",
      "4208/4208 - 62s - loss: 5.5154e-04 - val_loss: 4.7601e-04 - 62s/epoch - 15ms/step\n",
      "Epoch 36/1000\n",
      "4208/4208 - 62s - loss: 5.5084e-04 - val_loss: 4.6629e-04 - 62s/epoch - 15ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpohmi2x2x/model/data/model/assets\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/29 22:26:17 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/29 22:26:17 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 65s - loss: 7.7305e-04 - val_loss: 4.2233e-04 - 65s/epoch - 15ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 62s - loss: 3.8362e-04 - val_loss: 3.5786e-04 - 62s/epoch - 15ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 63s - loss: 3.4325e-04 - val_loss: 3.4280e-04 - 63s/epoch - 15ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 62s - loss: 3.3268e-04 - val_loss: 3.2647e-04 - 62s/epoch - 15ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 62s - loss: 3.2610e-04 - val_loss: 3.2588e-04 - 62s/epoch - 15ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 64s - loss: 3.1832e-04 - val_loss: 3.2336e-04 - 64s/epoch - 15ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 63s - loss: 3.1476e-04 - val_loss: 3.1666e-04 - 63s/epoch - 15ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 63s - loss: 3.1340e-04 - val_loss: 3.1454e-04 - 63s/epoch - 15ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 64s - loss: 3.1133e-04 - val_loss: 3.0794e-04 - 64s/epoch - 15ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 63s - loss: 3.0872e-04 - val_loss: 3.1679e-04 - 63s/epoch - 15ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 63s - loss: 3.0747e-04 - val_loss: 3.0626e-04 - 63s/epoch - 15ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 62s - loss: 3.0624e-04 - val_loss: 3.0557e-04 - 62s/epoch - 15ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 63s - loss: 3.0406e-04 - val_loss: 3.0308e-04 - 63s/epoch - 15ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 63s - loss: 3.0389e-04 - val_loss: 3.0984e-04 - 63s/epoch - 15ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 65s - loss: 3.0137e-04 - val_loss: 3.1137e-04 - 65s/epoch - 15ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 64s - loss: 2.9966e-04 - val_loss: 3.1372e-04 - 64s/epoch - 15ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 65s - loss: 2.9906e-04 - val_loss: 3.0194e-04 - 65s/epoch - 15ms/step\n",
      "Epoch 18/1000\n",
      "4208/4208 - 64s - loss: 2.9944e-04 - val_loss: 2.9573e-04 - 64s/epoch - 15ms/step\n",
      "Epoch 19/1000\n",
      "4208/4208 - 64s - loss: 2.9835e-04 - val_loss: 3.0629e-04 - 64s/epoch - 15ms/step\n",
      "Epoch 20/1000\n",
      "4208/4208 - 63s - loss: 2.9611e-04 - val_loss: 2.9764e-04 - 63s/epoch - 15ms/step\n",
      "Epoch 21/1000\n",
      "4208/4208 - 63s - loss: 2.9614e-04 - val_loss: 2.9435e-04 - 63s/epoch - 15ms/step\n",
      "Epoch 22/1000\n",
      "4208/4208 - 62s - loss: 2.9609e-04 - val_loss: 3.0337e-04 - 62s/epoch - 15ms/step\n",
      "Epoch 23/1000\n",
      "4208/4208 - 64s - loss: 2.9441e-04 - val_loss: 3.0991e-04 - 64s/epoch - 15ms/step\n",
      "Epoch 24/1000\n",
      "4208/4208 - 63s - loss: 2.9378e-04 - val_loss: 3.0513e-04 - 63s/epoch - 15ms/step\n",
      "Epoch 25/1000\n",
      "4208/4208 - 63s - loss: 2.9302e-04 - val_loss: 3.0634e-04 - 63s/epoch - 15ms/step\n",
      "Epoch 26/1000\n",
      "4208/4208 - 63s - loss: 2.9259e-04 - val_loss: 2.9923e-04 - 63s/epoch - 15ms/step\n",
      "Epoch 27/1000\n",
      "4208/4208 - 63s - loss: 2.8991e-04 - val_loss: 3.0332e-04 - 63s/epoch - 15ms/step\n",
      "Epoch 28/1000\n",
      "4208/4208 - 63s - loss: 2.9053e-04 - val_loss: 2.9562e-04 - 63s/epoch - 15ms/step\n",
      "Epoch 29/1000\n",
      "4208/4208 - 63s - loss: 2.8786e-04 - val_loss: 2.9477e-04 - 63s/epoch - 15ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpt6lco8n_/model/data/model/assets\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/29 23:02:58 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/29 23:02:58 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 68s - loss: 7.2366e-04 - val_loss: 4.6264e-04 - 68s/epoch - 16ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 66s - loss: 5.0556e-04 - val_loss: 4.4708e-04 - 66s/epoch - 16ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 66s - loss: 4.8216e-04 - val_loss: 4.4394e-04 - 66s/epoch - 16ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 65s - loss: 4.6551e-04 - val_loss: 4.3290e-04 - 65s/epoch - 16ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 65s - loss: 4.6265e-04 - val_loss: 4.2411e-04 - 65s/epoch - 15ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 65s - loss: 4.5940e-04 - val_loss: 4.1896e-04 - 65s/epoch - 16ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 66s - loss: 4.5798e-04 - val_loss: 4.2301e-04 - 66s/epoch - 16ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 66s - loss: 4.5760e-04 - val_loss: 4.2601e-04 - 66s/epoch - 16ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 67s - loss: 4.5654e-04 - val_loss: 4.1571e-04 - 67s/epoch - 16ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 66s - loss: 4.5377e-04 - val_loss: 4.0917e-04 - 66s/epoch - 16ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 65s - loss: 4.5231e-04 - val_loss: 4.1104e-04 - 65s/epoch - 15ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 64s - loss: 4.5141e-04 - val_loss: 4.2226e-04 - 64s/epoch - 15ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 64s - loss: 4.4776e-04 - val_loss: 4.0470e-04 - 64s/epoch - 15ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 65s - loss: 4.4924e-04 - val_loss: 4.1418e-04 - 65s/epoch - 15ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 65s - loss: 4.4821e-04 - val_loss: 4.1817e-04 - 65s/epoch - 15ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 64s - loss: 4.4870e-04 - val_loss: 4.0108e-04 - 64s/epoch - 15ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 67s - loss: 4.4602e-04 - val_loss: 4.0252e-04 - 67s/epoch - 16ms/step\n",
      "Epoch 18/1000\n",
      "4208/4208 - 65s - loss: 4.4465e-04 - val_loss: 3.8876e-04 - 65s/epoch - 16ms/step\n",
      "Epoch 19/1000\n",
      "4208/4208 - 65s - loss: 4.4488e-04 - val_loss: 4.0190e-04 - 65s/epoch - 16ms/step\n",
      "Epoch 20/1000\n",
      "4208/4208 - 65s - loss: 4.4452e-04 - val_loss: 3.8820e-04 - 65s/epoch - 15ms/step\n",
      "Epoch 21/1000\n",
      "4208/4208 - 65s - loss: 4.4583e-04 - val_loss: 4.6163e-04 - 65s/epoch - 15ms/step\n",
      "Epoch 22/1000\n",
      "4208/4208 - 65s - loss: 4.4709e-04 - val_loss: 3.9882e-04 - 65s/epoch - 15ms/step\n",
      "Epoch 23/1000\n",
      "4208/4208 - 64s - loss: 4.4566e-04 - val_loss: 3.9266e-04 - 64s/epoch - 15ms/step\n",
      "Epoch 24/1000\n",
      "4208/4208 - 66s - loss: 4.4347e-04 - val_loss: 3.9607e-04 - 66s/epoch - 16ms/step\n",
      "Epoch 25/1000\n",
      "4208/4208 - 66s - loss: 4.4400e-04 - val_loss: 3.9299e-04 - 66s/epoch - 16ms/step\n",
      "Epoch 26/1000\n",
      "4208/4208 - 67s - loss: 4.4564e-04 - val_loss: 3.9768e-04 - 67s/epoch - 16ms/step\n",
      "Epoch 27/1000\n",
      "4208/4208 - 67s - loss: 4.4275e-04 - val_loss: 3.9507e-04 - 67s/epoch - 16ms/step\n",
      "Epoch 28/1000\n",
      "4208/4208 - 66s - loss: 4.4100e-04 - val_loss: 3.8062e-04 - 66s/epoch - 16ms/step\n",
      "Epoch 29/1000\n",
      "4208/4208 - 65s - loss: 4.4244e-04 - val_loss: 4.0221e-04 - 65s/epoch - 16ms/step\n",
      "Epoch 30/1000\n",
      "4208/4208 - 67s - loss: 4.4589e-04 - val_loss: 3.8811e-04 - 67s/epoch - 16ms/step\n",
      "Epoch 31/1000\n",
      "4208/4208 - 66s - loss: 4.4310e-04 - val_loss: 3.8932e-04 - 66s/epoch - 16ms/step\n",
      "Epoch 32/1000\n",
      "4208/4208 - 66s - loss: 4.4793e-04 - val_loss: 3.9801e-04 - 66s/epoch - 16ms/step\n",
      "Epoch 33/1000\n",
      "4208/4208 - 65s - loss: 4.4358e-04 - val_loss: 3.9754e-04 - 65s/epoch - 15ms/step\n",
      "Epoch 34/1000\n",
      "4208/4208 - 64s - loss: 4.5526e-04 - val_loss: 3.9965e-04 - 64s/epoch - 15ms/step\n",
      "Epoch 35/1000\n",
      "4208/4208 - 65s - loss: 4.5015e-04 - val_loss: 3.9506e-04 - 65s/epoch - 15ms/step\n",
      "Epoch 36/1000\n",
      "4208/4208 - 66s - loss: 4.5195e-04 - val_loss: 3.9423e-04 - 66s/epoch - 16ms/step\n",
      "1/1 [==============================] - 0s 158ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpkn6lg6ch/model/data/model/assets\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/29 23:48:25 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/29 23:48:25 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 62s - loss: 0.0012 - val_loss: 9.1868e-04 - 62s/epoch - 15ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 60s - loss: 8.7670e-04 - val_loss: 9.0743e-04 - 60s/epoch - 14ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 58s - loss: 8.7648e-04 - val_loss: 9.1668e-04 - 58s/epoch - 14ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 60s - loss: 8.7632e-04 - val_loss: 9.1524e-04 - 60s/epoch - 14ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 59s - loss: 8.7627e-04 - val_loss: 9.1728e-04 - 59s/epoch - 14ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 60s - loss: 8.7626e-04 - val_loss: 9.0623e-04 - 60s/epoch - 14ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 59s - loss: 8.7627e-04 - val_loss: 9.1452e-04 - 59s/epoch - 14ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 57s - loss: 8.7616e-04 - val_loss: 9.1269e-04 - 57s/epoch - 13ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 55s - loss: 8.7615e-04 - val_loss: 9.0919e-04 - 55s/epoch - 13ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 59s - loss: 8.7620e-04 - val_loss: 9.2480e-04 - 59s/epoch - 14ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 59s - loss: 8.7626e-04 - val_loss: 9.0001e-04 - 59s/epoch - 14ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 59s - loss: 8.7623e-04 - val_loss: 9.0301e-04 - 59s/epoch - 14ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 59s - loss: 8.7620e-04 - val_loss: 9.1345e-04 - 59s/epoch - 14ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 59s - loss: 8.7627e-04 - val_loss: 8.9838e-04 - 59s/epoch - 14ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 59s - loss: 8.7626e-04 - val_loss: 9.1250e-04 - 59s/epoch - 14ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 60s - loss: 8.7627e-04 - val_loss: 9.1902e-04 - 60s/epoch - 14ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 58s - loss: 8.7654e-04 - val_loss: 9.0013e-04 - 58s/epoch - 14ms/step\n",
      "Epoch 18/1000\n",
      "4208/4208 - 60s - loss: 8.7630e-04 - val_loss: 9.0659e-04 - 60s/epoch - 14ms/step\n",
      "Epoch 19/1000\n",
      "4208/4208 - 59s - loss: 8.7648e-04 - val_loss: 9.1594e-04 - 59s/epoch - 14ms/step\n",
      "Epoch 20/1000\n",
      "4208/4208 - 59s - loss: 8.7624e-04 - val_loss: 9.1206e-04 - 59s/epoch - 14ms/step\n",
      "Epoch 21/1000\n",
      "4208/4208 - 58s - loss: 8.7623e-04 - val_loss: 9.1143e-04 - 58s/epoch - 14ms/step\n",
      "Epoch 22/1000\n",
      "4208/4208 - 58s - loss: 8.7619e-04 - val_loss: 9.1259e-04 - 58s/epoch - 14ms/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f51af98f490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmplq8to0ga/model/data/model/assets\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/30 00:15:26 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/30 00:15:26 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 66s - loss: 6.7683e-04 - val_loss: 3.7634e-04 - 66s/epoch - 16ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 65s - loss: 3.7210e-04 - val_loss: 3.4842e-04 - 65s/epoch - 15ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 64s - loss: 3.5264e-04 - val_loss: 3.3956e-04 - 64s/epoch - 15ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 64s - loss: 3.4473e-04 - val_loss: 3.2872e-04 - 64s/epoch - 15ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 63s - loss: 3.3824e-04 - val_loss: 3.2529e-04 - 63s/epoch - 15ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 64s - loss: 3.3241e-04 - val_loss: 3.1534e-04 - 64s/epoch - 15ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 64s - loss: 3.2706e-04 - val_loss: 3.1790e-04 - 64s/epoch - 15ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 64s - loss: 3.2347e-04 - val_loss: 3.1375e-04 - 64s/epoch - 15ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 63s - loss: 3.1962e-04 - val_loss: 3.0638e-04 - 63s/epoch - 15ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 65s - loss: 3.1553e-04 - val_loss: 3.0981e-04 - 65s/epoch - 15ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 65s - loss: 3.1346e-04 - val_loss: 3.0370e-04 - 65s/epoch - 16ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 64s - loss: 3.1175e-04 - val_loss: 2.9564e-04 - 64s/epoch - 15ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 62s - loss: 3.0943e-04 - val_loss: 2.8757e-04 - 62s/epoch - 15ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 62s - loss: 3.0758e-04 - val_loss: 2.9647e-04 - 62s/epoch - 15ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 63s - loss: 3.0678e-04 - val_loss: 2.9063e-04 - 63s/epoch - 15ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 63s - loss: 3.0603e-04 - val_loss: 2.9761e-04 - 63s/epoch - 15ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 63s - loss: 3.0467e-04 - val_loss: 2.9861e-04 - 63s/epoch - 15ms/step\n",
      "Epoch 18/1000\n",
      "4208/4208 - 64s - loss: 3.0424e-04 - val_loss: 2.9412e-04 - 64s/epoch - 15ms/step\n",
      "Epoch 19/1000\n",
      "4208/4208 - 63s - loss: 3.0349e-04 - val_loss: 2.9225e-04 - 63s/epoch - 15ms/step\n",
      "Epoch 20/1000\n",
      "4208/4208 - 62s - loss: 3.0275e-04 - val_loss: 2.9541e-04 - 62s/epoch - 15ms/step\n",
      "Epoch 21/1000\n",
      "4208/4208 - 64s - loss: 3.0278e-04 - val_loss: 2.9738e-04 - 64s/epoch - 15ms/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f51afc49090> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 188ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmptnpwi1wr/model/data/model/assets\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/30 00:43:43 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/30 00:43:43 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 74s - loss: 0.0012 - val_loss: 4.1657e-04 - 74s/epoch - 18ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 67s - loss: 4.4586e-04 - val_loss: 4.0322e-04 - 67s/epoch - 16ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 67s - loss: 4.2912e-04 - val_loss: 3.8224e-04 - 67s/epoch - 16ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 67s - loss: 4.1607e-04 - val_loss: 3.6698e-04 - 67s/epoch - 16ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 65s - loss: 4.0554e-04 - val_loss: 3.6835e-04 - 65s/epoch - 15ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 65s - loss: 4.0188e-04 - val_loss: 3.6086e-04 - 65s/epoch - 16ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 66s - loss: 4.0043e-04 - val_loss: 3.5644e-04 - 66s/epoch - 16ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 65s - loss: 3.9804e-04 - val_loss: 3.4606e-04 - 65s/epoch - 16ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 66s - loss: 3.9760e-04 - val_loss: 3.4297e-04 - 66s/epoch - 16ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 66s - loss: 3.9655e-04 - val_loss: 3.5264e-04 - 66s/epoch - 16ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 66s - loss: 3.9630e-04 - val_loss: 3.4290e-04 - 66s/epoch - 16ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 66s - loss: 3.9584e-04 - val_loss: 3.6223e-04 - 66s/epoch - 16ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 65s - loss: 3.9488e-04 - val_loss: 3.4594e-04 - 65s/epoch - 16ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 65s - loss: 3.9496e-04 - val_loss: 3.5162e-04 - 65s/epoch - 15ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 65s - loss: 3.9508e-04 - val_loss: 3.5288e-04 - 65s/epoch - 15ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 65s - loss: 3.9400e-04 - val_loss: 3.5151e-04 - 65s/epoch - 15ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 66s - loss: 3.9423e-04 - val_loss: 3.4138e-04 - 66s/epoch - 16ms/step\n",
      "Epoch 18/1000\n",
      "4208/4208 - 66s - loss: 3.9385e-04 - val_loss: 3.4505e-04 - 66s/epoch - 16ms/step\n",
      "Epoch 19/1000\n",
      "4208/4208 - 65s - loss: 3.9331e-04 - val_loss: 3.4888e-04 - 65s/epoch - 16ms/step\n",
      "Epoch 20/1000\n",
      "4208/4208 - 66s - loss: 3.9326e-04 - val_loss: 3.4451e-04 - 66s/epoch - 16ms/step\n",
      "Epoch 21/1000\n",
      "4208/4208 - 65s - loss: 3.9284e-04 - val_loss: 3.4735e-04 - 65s/epoch - 15ms/step\n",
      "Epoch 22/1000\n",
      "4208/4208 - 64s - loss: 3.9259e-04 - val_loss: 3.4229e-04 - 64s/epoch - 15ms/step\n",
      "Epoch 23/1000\n",
      "4208/4208 - 64s - loss: 3.9186e-04 - val_loss: 3.4292e-04 - 64s/epoch - 15ms/step\n",
      "Epoch 24/1000\n",
      "4208/4208 - 66s - loss: 3.9214e-04 - val_loss: 3.4841e-04 - 66s/epoch - 16ms/step\n",
      "Epoch 25/1000\n",
      "4208/4208 - 66s - loss: 3.9167e-04 - val_loss: 3.4407e-04 - 66s/epoch - 16ms/step\n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpnlc9qwmd/model/data/model/assets\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/30 01:17:25 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/30 01:17:25 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 62s - loss: 0.0011 - val_loss: 6.4508e-04 - 62s/epoch - 15ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 58s - loss: 5.3818e-04 - val_loss: 4.2536e-04 - 58s/epoch - 14ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 59s - loss: 4.3304e-04 - val_loss: 3.7441e-04 - 59s/epoch - 14ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 59s - loss: 4.0515e-04 - val_loss: 3.6991e-04 - 59s/epoch - 14ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 60s - loss: 3.9759e-04 - val_loss: 3.5941e-04 - 60s/epoch - 14ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 60s - loss: 3.9253e-04 - val_loss: 3.5576e-04 - 60s/epoch - 14ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 58s - loss: 3.8894e-04 - val_loss: 3.5254e-04 - 58s/epoch - 14ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 59s - loss: 3.8411e-04 - val_loss: 3.4249e-04 - 59s/epoch - 14ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 61s - loss: 3.8183e-04 - val_loss: 3.5455e-04 - 61s/epoch - 14ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 60s - loss: 3.7999e-04 - val_loss: 3.3725e-04 - 60s/epoch - 14ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 60s - loss: 3.7543e-04 - val_loss: 3.4619e-04 - 60s/epoch - 14ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 58s - loss: 3.7760e-04 - val_loss: 3.4253e-04 - 58s/epoch - 14ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 61s - loss: 3.7659e-04 - val_loss: 3.3717e-04 - 61s/epoch - 14ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 61s - loss: 3.7689e-04 - val_loss: 3.3513e-04 - 61s/epoch - 15ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 59s - loss: 3.7377e-04 - val_loss: 3.3075e-04 - 59s/epoch - 14ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 61s - loss: 3.7328e-04 - val_loss: 3.3852e-04 - 61s/epoch - 14ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 58s - loss: 3.7193e-04 - val_loss: 3.3493e-04 - 58s/epoch - 14ms/step\n",
      "Epoch 18/1000\n",
      "4208/4208 - 59s - loss: 3.7183e-04 - val_loss: 3.3496e-04 - 59s/epoch - 14ms/step\n",
      "Epoch 19/1000\n",
      "4208/4208 - 60s - loss: 3.7198e-04 - val_loss: 3.3586e-04 - 60s/epoch - 14ms/step\n",
      "Epoch 20/1000\n",
      "4208/4208 - 60s - loss: 3.7036e-04 - val_loss: 3.3790e-04 - 60s/epoch - 14ms/step\n",
      "Epoch 21/1000\n",
      "4208/4208 - 61s - loss: 3.7177e-04 - val_loss: 3.3529e-04 - 61s/epoch - 14ms/step\n",
      "Epoch 22/1000\n",
      "4208/4208 - 62s - loss: 3.6905e-04 - val_loss: 3.3723e-04 - 62s/epoch - 15ms/step\n",
      "Epoch 23/1000\n",
      "4208/4208 - 61s - loss: 3.6792e-04 - val_loss: 3.3244e-04 - 61s/epoch - 15ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpoxwk_ct2/model/data/model/assets\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/30 01:46:19 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/30 01:46:19 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 67s - loss: 9.3156e-04 - val_loss: 9.3329e-04 - 67s/epoch - 16ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 66s - loss: 8.8107e-04 - val_loss: 9.2755e-04 - 66s/epoch - 16ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 65s - loss: 8.8169e-04 - val_loss: 9.1286e-04 - 65s/epoch - 15ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 64s - loss: 8.8163e-04 - val_loss: 9.0432e-04 - 64s/epoch - 15ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 65s - loss: 8.8188e-04 - val_loss: 9.1504e-04 - 65s/epoch - 15ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 67s - loss: 8.8207e-04 - val_loss: 9.1594e-04 - 67s/epoch - 16ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 66s - loss: 8.8175e-04 - val_loss: 9.1764e-04 - 66s/epoch - 16ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 66s - loss: 8.8227e-04 - val_loss: 9.1454e-04 - 66s/epoch - 16ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 67s - loss: 8.8176e-04 - val_loss: 9.2348e-04 - 67s/epoch - 16ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 67s - loss: 8.8171e-04 - val_loss: 9.1660e-04 - 67s/epoch - 16ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 66s - loss: 8.8170e-04 - val_loss: 9.1247e-04 - 66s/epoch - 16ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 68s - loss: 8.8201e-04 - val_loss: 9.1132e-04 - 68s/epoch - 16ms/step\n",
      "1/1 [==============================] - 0s 182ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpe5dkifxx/model/data/model/assets\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/30 02:06:36 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/30 02:06:36 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 68s - loss: 7.7101e-04 - val_loss: 5.0040e-04 - 68s/epoch - 16ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 65s - loss: 5.1366e-04 - val_loss: 4.4679e-04 - 65s/epoch - 15ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 65s - loss: 4.9892e-04 - val_loss: 4.4801e-04 - 65s/epoch - 15ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 64s - loss: 4.7903e-04 - val_loss: 4.3897e-04 - 64s/epoch - 15ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 65s - loss: 4.6691e-04 - val_loss: 4.4138e-04 - 65s/epoch - 15ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 65s - loss: 4.6353e-04 - val_loss: 4.3156e-04 - 65s/epoch - 15ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 65s - loss: 4.6210e-04 - val_loss: 4.2171e-04 - 65s/epoch - 15ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 66s - loss: 4.5766e-04 - val_loss: 4.0864e-04 - 66s/epoch - 16ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 66s - loss: 4.5676e-04 - val_loss: 4.0311e-04 - 66s/epoch - 16ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 67s - loss: 4.5956e-04 - val_loss: 4.3025e-04 - 67s/epoch - 16ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 66s - loss: 4.5871e-04 - val_loss: 4.1070e-04 - 66s/epoch - 16ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 65s - loss: 4.6114e-04 - val_loss: 4.1108e-04 - 65s/epoch - 15ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 66s - loss: 4.6023e-04 - val_loss: 4.0513e-04 - 66s/epoch - 16ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 65s - loss: 4.6642e-04 - val_loss: 4.2267e-04 - 65s/epoch - 16ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 66s - loss: 4.6589e-04 - val_loss: 4.3845e-04 - 66s/epoch - 16ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 65s - loss: 4.6116e-04 - val_loss: 4.1658e-04 - 65s/epoch - 16ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 66s - loss: 4.6248e-04 - val_loss: 4.4476e-04 - 66s/epoch - 16ms/step\n",
      "1/1 [==============================] - 0s 192ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp4hhsaq2m/model/data/model/assets\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/30 02:31:44 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/30 02:31:44 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 79s - loss: 5.2872e-04 - val_loss: 4.3763e-04 - 79s/epoch - 19ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 72s - loss: 4.5937e-04 - val_loss: 4.1784e-04 - 72s/epoch - 17ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 71s - loss: 4.4616e-04 - val_loss: 4.2558e-04 - 71s/epoch - 17ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 71s - loss: 4.3796e-04 - val_loss: 4.1082e-04 - 71s/epoch - 17ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 71s - loss: 4.3169e-04 - val_loss: 4.1574e-04 - 71s/epoch - 17ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 72s - loss: 4.2517e-04 - val_loss: 4.1444e-04 - 72s/epoch - 17ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 71s - loss: 4.2429e-04 - val_loss: 4.0527e-04 - 71s/epoch - 17ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 71s - loss: 4.2259e-04 - val_loss: 4.0124e-04 - 71s/epoch - 17ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 71s - loss: 4.2353e-04 - val_loss: 4.1365e-04 - 71s/epoch - 17ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 71s - loss: 4.1693e-04 - val_loss: 3.8874e-04 - 71s/epoch - 17ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 73s - loss: 4.1080e-04 - val_loss: 3.8805e-04 - 73s/epoch - 17ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 70s - loss: 4.0883e-04 - val_loss: 3.8042e-04 - 70s/epoch - 17ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 69s - loss: 4.0904e-04 - val_loss: 3.8298e-04 - 69s/epoch - 16ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 69s - loss: 4.0530e-04 - val_loss: 3.8313e-04 - 69s/epoch - 16ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 71s - loss: 4.0656e-04 - val_loss: 3.7715e-04 - 71s/epoch - 17ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 70s - loss: 4.0562e-04 - val_loss: 3.7525e-04 - 70s/epoch - 17ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 71s - loss: 4.0498e-04 - val_loss: 3.7317e-04 - 71s/epoch - 17ms/step\n",
      "Epoch 18/1000\n",
      "4208/4208 - 70s - loss: 4.0524e-04 - val_loss: 3.6527e-04 - 70s/epoch - 17ms/step\n",
      "Epoch 19/1000\n",
      "4208/4208 - 71s - loss: 4.0329e-04 - val_loss: 3.7938e-04 - 71s/epoch - 17ms/step\n",
      "Epoch 20/1000\n",
      "4208/4208 - 71s - loss: 4.0372e-04 - val_loss: 3.7591e-04 - 71s/epoch - 17ms/step\n",
      "Epoch 21/1000\n",
      "4208/4208 - 71s - loss: 4.0349e-04 - val_loss: 3.7272e-04 - 71s/epoch - 17ms/step\n",
      "Epoch 22/1000\n",
      "4208/4208 - 71s - loss: 4.0282e-04 - val_loss: 3.8341e-04 - 71s/epoch - 17ms/step\n",
      "Epoch 23/1000\n",
      "4208/4208 - 73s - loss: 4.0237e-04 - val_loss: 3.8939e-04 - 73s/epoch - 17ms/step\n",
      "Epoch 24/1000\n",
      "4208/4208 - 72s - loss: 4.0277e-04 - val_loss: 3.7352e-04 - 72s/epoch - 17ms/step\n",
      "Epoch 25/1000\n",
      "4208/4208 - 69s - loss: 4.0231e-04 - val_loss: 3.7641e-04 - 69s/epoch - 16ms/step\n",
      "Epoch 26/1000\n",
      "4208/4208 - 71s - loss: 4.0284e-04 - val_loss: 3.6717e-04 - 71s/epoch - 17ms/step\n",
      "1/1 [==============================] - 0s 287ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp5t_wshxh/model/data/model/assets\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/30 03:09:50 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/30 03:09:50 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 76s - loss: 4.1037e-04 - val_loss: 3.3566e-04 - 76s/epoch - 18ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 76s - loss: 3.5980e-04 - val_loss: 3.2496e-04 - 76s/epoch - 18ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 73s - loss: 3.4569e-04 - val_loss: 3.1206e-04 - 73s/epoch - 17ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 75s - loss: 3.3438e-04 - val_loss: 3.0592e-04 - 75s/epoch - 18ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 77s - loss: 3.2844e-04 - val_loss: 2.9610e-04 - 77s/epoch - 18ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 75s - loss: 3.2350e-04 - val_loss: 3.0471e-04 - 75s/epoch - 18ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 77s - loss: 3.2023e-04 - val_loss: 3.0465e-04 - 77s/epoch - 18ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 78s - loss: 3.1850e-04 - val_loss: 2.9024e-04 - 78s/epoch - 19ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 76s - loss: 3.1539e-04 - val_loss: 2.9672e-04 - 76s/epoch - 18ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 75s - loss: 3.1460e-04 - val_loss: 3.0857e-04 - 75s/epoch - 18ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 77s - loss: 3.1310e-04 - val_loss: 2.9169e-04 - 77s/epoch - 18ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 77s - loss: 3.1119e-04 - val_loss: 2.9559e-04 - 77s/epoch - 18ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 75s - loss: 3.0991e-04 - val_loss: 2.9240e-04 - 75s/epoch - 18ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 78s - loss: 3.0923e-04 - val_loss: 2.9696e-04 - 78s/epoch - 19ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 76s - loss: 3.0758e-04 - val_loss: 2.9209e-04 - 76s/epoch - 18ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 76s - loss: 3.0614e-04 - val_loss: 2.8926e-04 - 76s/epoch - 18ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 77s - loss: 3.0552e-04 - val_loss: 2.9430e-04 - 77s/epoch - 18ms/step\n",
      "Epoch 18/1000\n",
      "4208/4208 - 75s - loss: 3.0350e-04 - val_loss: 3.0567e-04 - 75s/epoch - 18ms/step\n",
      "Epoch 19/1000\n",
      "4208/4208 - 76s - loss: 3.0286e-04 - val_loss: 3.0298e-04 - 76s/epoch - 18ms/step\n",
      "Epoch 20/1000\n",
      "4208/4208 - 75s - loss: 3.0147e-04 - val_loss: 3.1184e-04 - 75s/epoch - 18ms/step\n",
      "Epoch 21/1000\n",
      "4208/4208 - 77s - loss: 3.0078e-04 - val_loss: 3.0189e-04 - 77s/epoch - 18ms/step\n",
      "Epoch 22/1000\n",
      "4208/4208 - 75s - loss: 3.0074e-04 - val_loss: 2.9113e-04 - 75s/epoch - 18ms/step\n",
      "Epoch 23/1000\n",
      "4208/4208 - 75s - loss: 3.0021e-04 - val_loss: 3.0955e-04 - 75s/epoch - 18ms/step\n",
      "Epoch 24/1000\n",
      "4208/4208 - 76s - loss: 2.9910e-04 - val_loss: 3.0067e-04 - 76s/epoch - 18ms/step\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpfay4_8d3/model/data/model/assets\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/30 03:47:24 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/30 03:47:24 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 63s - loss: 5.8785e-04 - val_loss: 3.8522e-04 - 63s/epoch - 15ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 61s - loss: 4.0535e-04 - val_loss: 3.6812e-04 - 61s/epoch - 14ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 60s - loss: 3.8534e-04 - val_loss: 3.4758e-04 - 60s/epoch - 14ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 63s - loss: 3.7562e-04 - val_loss: 3.4292e-04 - 63s/epoch - 15ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 63s - loss: 3.6986e-04 - val_loss: 3.4145e-04 - 63s/epoch - 15ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 65s - loss: 3.6278e-04 - val_loss: 3.3526e-04 - 65s/epoch - 16ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 67s - loss: 3.5776e-04 - val_loss: 3.3733e-04 - 67s/epoch - 16ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 67s - loss: 3.5196e-04 - val_loss: 3.2881e-04 - 67s/epoch - 16ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 62s - loss: 3.4882e-04 - val_loss: 3.1773e-04 - 62s/epoch - 15ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 63s - loss: 3.4547e-04 - val_loss: 3.2422e-04 - 63s/epoch - 15ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 62s - loss: 3.4441e-04 - val_loss: 3.1502e-04 - 62s/epoch - 15ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 62s - loss: 3.4191e-04 - val_loss: 3.1149e-04 - 62s/epoch - 15ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 63s - loss: 3.3980e-04 - val_loss: 3.1031e-04 - 63s/epoch - 15ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 63s - loss: 3.4008e-04 - val_loss: 3.0709e-04 - 63s/epoch - 15ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 61s - loss: 3.3988e-04 - val_loss: 3.1183e-04 - 61s/epoch - 15ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 63s - loss: 3.3874e-04 - val_loss: 3.1709e-04 - 63s/epoch - 15ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 63s - loss: 3.3867e-04 - val_loss: 3.1439e-04 - 63s/epoch - 15ms/step\n",
      "Epoch 18/1000\n",
      "4208/4208 - 63s - loss: 3.3747e-04 - val_loss: 3.1190e-04 - 63s/epoch - 15ms/step\n",
      "Epoch 19/1000\n",
      "4208/4208 - 62s - loss: 3.3656e-04 - val_loss: 3.1444e-04 - 62s/epoch - 15ms/step\n",
      "Epoch 20/1000\n",
      "4208/4208 - 62s - loss: 3.3719e-04 - val_loss: 3.1189e-04 - 62s/epoch - 15ms/step\n",
      "Epoch 21/1000\n",
      "4208/4208 - 62s - loss: 3.3604e-04 - val_loss: 3.1147e-04 - 62s/epoch - 15ms/step\n",
      "Epoch 22/1000\n",
      "4208/4208 - 64s - loss: 3.3484e-04 - val_loss: 3.0475e-04 - 64s/epoch - 15ms/step\n",
      "Epoch 23/1000\n",
      "4208/4208 - 62s - loss: 3.3339e-04 - val_loss: 3.0073e-04 - 62s/epoch - 15ms/step\n",
      "Epoch 24/1000\n",
      "4208/4208 - 60s - loss: 3.3447e-04 - val_loss: 3.0931e-04 - 60s/epoch - 14ms/step\n",
      "Epoch 25/1000\n",
      "4208/4208 - 61s - loss: 3.3432e-04 - val_loss: 3.1142e-04 - 61s/epoch - 15ms/step\n",
      "Epoch 26/1000\n",
      "4208/4208 - 61s - loss: 3.3442e-04 - val_loss: 3.0871e-04 - 61s/epoch - 15ms/step\n",
      "Epoch 27/1000\n",
      "4208/4208 - 64s - loss: 3.3392e-04 - val_loss: 3.0756e-04 - 64s/epoch - 15ms/step\n",
      "Epoch 28/1000\n",
      "4208/4208 - 62s - loss: 3.3287e-04 - val_loss: 3.1134e-04 - 62s/epoch - 15ms/step\n",
      "Epoch 29/1000\n",
      "4208/4208 - 64s - loss: 3.3296e-04 - val_loss: 3.0426e-04 - 64s/epoch - 15ms/step\n",
      "Epoch 30/1000\n",
      "4208/4208 - 65s - loss: 3.3292e-04 - val_loss: 3.1159e-04 - 65s/epoch - 15ms/step\n",
      "Epoch 31/1000\n",
      "4208/4208 - 61s - loss: 3.3347e-04 - val_loss: 3.1210e-04 - 61s/epoch - 15ms/step\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmptjwxsg71/model/data/model/assets\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/30 04:26:11 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/30 04:26:11 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 58s - loss: 0.0011 - val_loss: 9.2850e-04 - 58s/epoch - 14ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 60s - loss: 8.7806e-04 - val_loss: 9.1534e-04 - 60s/epoch - 14ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 58s - loss: 8.7881e-04 - val_loss: 9.1082e-04 - 58s/epoch - 14ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 55s - loss: 8.7853e-04 - val_loss: 9.2258e-04 - 55s/epoch - 13ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 55s - loss: 8.7858e-04 - val_loss: 9.0472e-04 - 55s/epoch - 13ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 55s - loss: 8.7855e-04 - val_loss: 9.2216e-04 - 55s/epoch - 13ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 56s - loss: 8.7851e-04 - val_loss: 9.1287e-04 - 56s/epoch - 13ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 55s - loss: 8.7851e-04 - val_loss: 9.1426e-04 - 55s/epoch - 13ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 55s - loss: 8.7854e-04 - val_loss: 9.1385e-04 - 55s/epoch - 13ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 55s - loss: 8.7863e-04 - val_loss: 9.0974e-04 - 55s/epoch - 13ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 58s - loss: 8.7862e-04 - val_loss: 9.2522e-04 - 58s/epoch - 14ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 54s - loss: 8.7860e-04 - val_loss: 9.0974e-04 - 54s/epoch - 13ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 55s - loss: 8.7853e-04 - val_loss: 9.1478e-04 - 55s/epoch - 13ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmphhmkwwog/model/data/model/assets\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/30 04:43:37 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/30 04:43:37 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 57s - loss: 0.0020 - val_loss: 9.2722e-04 - 57s/epoch - 14ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 54s - loss: 8.8663e-04 - val_loss: 9.2821e-04 - 54s/epoch - 13ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 54s - loss: 8.8667e-04 - val_loss: 9.1243e-04 - 54s/epoch - 13ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 57s - loss: 8.8645e-04 - val_loss: 9.1929e-04 - 57s/epoch - 14ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 58s - loss: 8.8638e-04 - val_loss: 9.1748e-04 - 58s/epoch - 14ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 54s - loss: 8.8636e-04 - val_loss: 9.1698e-04 - 54s/epoch - 13ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 54s - loss: 8.8592e-04 - val_loss: 9.2500e-04 - 54s/epoch - 13ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 53s - loss: 8.8591e-04 - val_loss: 9.2830e-04 - 53s/epoch - 13ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 55s - loss: 8.8586e-04 - val_loss: 9.2823e-04 - 55s/epoch - 13ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 55s - loss: 8.8594e-04 - val_loss: 9.2741e-04 - 55s/epoch - 13ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 55s - loss: 8.8597e-04 - val_loss: 9.3128e-04 - 55s/epoch - 13ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpwa1uhkdt/model/data/model/assets\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/30 04:59:19 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/30 04:59:19 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 57s - loss: 0.0016 - val_loss: 9.1506e-04 - 57s/epoch - 14ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 54s - loss: 8.8055e-04 - val_loss: 9.0788e-04 - 54s/epoch - 13ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 55s - loss: 8.8040e-04 - val_loss: 9.0515e-04 - 55s/epoch - 13ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 55s - loss: 8.8011e-04 - val_loss: 9.3148e-04 - 55s/epoch - 13ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 56s - loss: 8.8012e-04 - val_loss: 9.0219e-04 - 56s/epoch - 13ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 55s - loss: 8.8019e-04 - val_loss: 9.0241e-04 - 55s/epoch - 13ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 57s - loss: 8.7999e-04 - val_loss: 9.1647e-04 - 57s/epoch - 14ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 57s - loss: 8.7981e-04 - val_loss: 9.2248e-04 - 57s/epoch - 13ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 57s - loss: 8.7980e-04 - val_loss: 9.0328e-04 - 57s/epoch - 13ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 56s - loss: 8.8012e-04 - val_loss: 9.0360e-04 - 56s/epoch - 13ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 59s - loss: 8.8019e-04 - val_loss: 9.1454e-04 - 59s/epoch - 14ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 57s - loss: 8.7970e-04 - val_loss: 8.9679e-04 - 57s/epoch - 14ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 54s - loss: 8.8005e-04 - val_loss: 9.0017e-04 - 54s/epoch - 13ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 53s - loss: 8.7983e-04 - val_loss: 9.1091e-04 - 53s/epoch - 13ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 55s - loss: 8.8006e-04 - val_loss: 9.1347e-04 - 55s/epoch - 13ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 54s - loss: 8.7973e-04 - val_loss: 9.0239e-04 - 54s/epoch - 13ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 55s - loss: 8.7984e-04 - val_loss: 9.0967e-04 - 55s/epoch - 13ms/step\n",
      "Epoch 18/1000\n",
      "4208/4208 - 55s - loss: 8.7978e-04 - val_loss: 9.0598e-04 - 55s/epoch - 13ms/step\n",
      "Epoch 19/1000\n",
      "4208/4208 - 54s - loss: 8.8016e-04 - val_loss: 9.1087e-04 - 54s/epoch - 13ms/step\n",
      "Epoch 20/1000\n",
      "4208/4208 - 54s - loss: 8.7980e-04 - val_loss: 9.1605e-04 - 54s/epoch - 13ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpsmc_0bn8/model/data/model/assets\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/30 05:23:13 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/30 05:23:13 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 66s - loss: 9.1181e-04 - val_loss: 9.3356e-04 - 66s/epoch - 16ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 61s - loss: 8.9234e-04 - val_loss: 9.3567e-04 - 61s/epoch - 14ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 61s - loss: 8.9242e-04 - val_loss: 9.2222e-04 - 61s/epoch - 14ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 61s - loss: 8.9265e-04 - val_loss: 9.3455e-04 - 61s/epoch - 15ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 61s - loss: 8.9234e-04 - val_loss: 9.2788e-04 - 61s/epoch - 14ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 61s - loss: 8.9247e-04 - val_loss: 9.3113e-04 - 61s/epoch - 15ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 61s - loss: 8.9268e-04 - val_loss: 9.3425e-04 - 61s/epoch - 14ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 59s - loss: 8.9238e-04 - val_loss: 9.3167e-04 - 59s/epoch - 14ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 61s - loss: 8.9239e-04 - val_loss: 9.1533e-04 - 61s/epoch - 15ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 61s - loss: 8.9244e-04 - val_loss: 9.1979e-04 - 61s/epoch - 14ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 61s - loss: 8.9276e-04 - val_loss: 9.2806e-04 - 61s/epoch - 14ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 60s - loss: 8.9240e-04 - val_loss: 9.3387e-04 - 60s/epoch - 14ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 63s - loss: 8.9237e-04 - val_loss: 9.1552e-04 - 63s/epoch - 15ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 60s - loss: 8.9270e-04 - val_loss: 9.1867e-04 - 60s/epoch - 14ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 60s - loss: 8.9263e-04 - val_loss: 9.2361e-04 - 60s/epoch - 14ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 60s - loss: 8.9243e-04 - val_loss: 9.4723e-04 - 60s/epoch - 14ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 64s - loss: 8.9232e-04 - val_loss: 9.2976e-04 - 64s/epoch - 15ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp8k1o1_bj/model/data/model/assets\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/30 05:46:34 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/30 05:46:34 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 63s - loss: 0.0015 - val_loss: 4.6636e-04 - 63s/epoch - 15ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 62s - loss: 4.9999e-04 - val_loss: 4.4467e-04 - 62s/epoch - 15ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 61s - loss: 4.8272e-04 - val_loss: 4.4052e-04 - 61s/epoch - 14ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 62s - loss: 4.6855e-04 - val_loss: 4.2876e-04 - 62s/epoch - 15ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 61s - loss: 4.6278e-04 - val_loss: 4.2939e-04 - 61s/epoch - 15ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 62s - loss: 4.6107e-04 - val_loss: 4.2478e-04 - 62s/epoch - 15ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 64s - loss: 4.6006e-04 - val_loss: 4.1804e-04 - 64s/epoch - 15ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 62s - loss: 4.5876e-04 - val_loss: 4.1937e-04 - 62s/epoch - 15ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 60s - loss: 4.5787e-04 - val_loss: 4.2690e-04 - 60s/epoch - 14ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 65s - loss: 4.5146e-04 - val_loss: 3.9778e-04 - 65s/epoch - 15ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 64s - loss: 4.4892e-04 - val_loss: 4.0137e-04 - 64s/epoch - 15ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 63s - loss: 4.4796e-04 - val_loss: 3.8287e-04 - 63s/epoch - 15ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 61s - loss: 4.4739e-04 - val_loss: 3.8882e-04 - 61s/epoch - 15ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 63s - loss: 4.4691e-04 - val_loss: 3.8602e-04 - 63s/epoch - 15ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 62s - loss: 4.4596e-04 - val_loss: 3.8449e-04 - 62s/epoch - 15ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 63s - loss: 4.4562e-04 - val_loss: 3.8674e-04 - 63s/epoch - 15ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 63s - loss: 4.4531e-04 - val_loss: 3.8615e-04 - 63s/epoch - 15ms/step\n",
      "Epoch 18/1000\n",
      "4208/4208 - 62s - loss: 4.4511e-04 - val_loss: 3.8263e-04 - 62s/epoch - 15ms/step\n",
      "Epoch 19/1000\n",
      "4208/4208 - 63s - loss: 4.4490e-04 - val_loss: 3.9704e-04 - 63s/epoch - 15ms/step\n",
      "Epoch 20/1000\n",
      "4208/4208 - 63s - loss: 4.4520e-04 - val_loss: 3.8510e-04 - 63s/epoch - 15ms/step\n",
      "Epoch 21/1000\n",
      "4208/4208 - 63s - loss: 4.4621e-04 - val_loss: 4.0057e-04 - 63s/epoch - 15ms/step\n",
      "Epoch 22/1000\n",
      "4208/4208 - 60s - loss: 4.4621e-04 - val_loss: 3.9451e-04 - 60s/epoch - 14ms/step\n",
      "Epoch 23/1000\n",
      "4208/4208 - 64s - loss: 4.4584e-04 - val_loss: 3.9166e-04 - 64s/epoch - 15ms/step\n",
      "Epoch 24/1000\n",
      "4208/4208 - 63s - loss: 4.4439e-04 - val_loss: 3.8763e-04 - 63s/epoch - 15ms/step\n",
      "Epoch 25/1000\n",
      "4208/4208 - 63s - loss: 4.4540e-04 - val_loss: 4.0141e-04 - 63s/epoch - 15ms/step\n",
      "Epoch 26/1000\n",
      "4208/4208 - 61s - loss: 4.4626e-04 - val_loss: 3.9092e-04 - 61s/epoch - 15ms/step\n",
      "1/1 [==============================] - 0s 226ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpbuc2lgp2/model/data/model/assets\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/30 06:19:46 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/30 06:19:46 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 59s - loss: 7.6192e-04 - val_loss: 3.3932e-04 - 59s/epoch - 14ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 58s - loss: 3.0935e-04 - val_loss: 3.0657e-04 - 58s/epoch - 14ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 60s - loss: 2.8418e-04 - val_loss: 2.8129e-04 - 60s/epoch - 14ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 61s - loss: 2.7100e-04 - val_loss: 2.8160e-04 - 61s/epoch - 15ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 56s - loss: 2.6291e-04 - val_loss: 2.8469e-04 - 56s/epoch - 13ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 57s - loss: 2.5670e-04 - val_loss: 2.8424e-04 - 57s/epoch - 13ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 57s - loss: 2.5283e-04 - val_loss: 2.8308e-04 - 57s/epoch - 14ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 57s - loss: 2.4948e-04 - val_loss: 2.7214e-04 - 57s/epoch - 13ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 57s - loss: 2.4604e-04 - val_loss: 2.6624e-04 - 57s/epoch - 14ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 60s - loss: 2.4427e-04 - val_loss: 2.7876e-04 - 60s/epoch - 14ms/step\n",
      "Epoch 11/1000\n",
      "4208/4208 - 58s - loss: 2.4182e-04 - val_loss: 2.6911e-04 - 58s/epoch - 14ms/step\n",
      "Epoch 12/1000\n",
      "4208/4208 - 58s - loss: 2.4001e-04 - val_loss: 2.7050e-04 - 58s/epoch - 14ms/step\n",
      "Epoch 13/1000\n",
      "4208/4208 - 57s - loss: 2.3807e-04 - val_loss: 2.7433e-04 - 57s/epoch - 14ms/step\n",
      "Epoch 14/1000\n",
      "4208/4208 - 58s - loss: 2.3717e-04 - val_loss: 2.8287e-04 - 58s/epoch - 14ms/step\n",
      "Epoch 15/1000\n",
      "4208/4208 - 57s - loss: 2.3570e-04 - val_loss: 2.7818e-04 - 57s/epoch - 14ms/step\n",
      "Epoch 16/1000\n",
      "4208/4208 - 58s - loss: 2.3453e-04 - val_loss: 2.7507e-04 - 58s/epoch - 14ms/step\n",
      "Epoch 17/1000\n",
      "4208/4208 - 58s - loss: 2.3341e-04 - val_loss: 2.6955e-04 - 58s/epoch - 14ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp27eprb5d/model/data/model/assets\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/30 06:41:55 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'dict'>. Dataset logging skipped.\n",
      "2024/09/30 06:41:55 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4208/4208 - 55s - loss: 0.0016 - val_loss: 8.9645e-04 - 55s/epoch - 13ms/step\n",
      "Epoch 2/1000\n",
      "4208/4208 - 55s - loss: 8.6464e-04 - val_loss: 8.9357e-04 - 55s/epoch - 13ms/step\n",
      "Epoch 3/1000\n",
      "4208/4208 - 58s - loss: 8.6482e-04 - val_loss: 9.0264e-04 - 58s/epoch - 14ms/step\n",
      "Epoch 4/1000\n",
      "4208/4208 - 55s - loss: 8.6472e-04 - val_loss: 8.9551e-04 - 55s/epoch - 13ms/step\n",
      "Epoch 5/1000\n",
      "4208/4208 - 55s - loss: 8.6487e-04 - val_loss: 9.0427e-04 - 55s/epoch - 13ms/step\n",
      "Epoch 6/1000\n",
      "4208/4208 - 57s - loss: 8.6463e-04 - val_loss: 9.0580e-04 - 57s/epoch - 13ms/step\n",
      "Epoch 7/1000\n",
      "4208/4208 - 55s - loss: 8.6458e-04 - val_loss: 8.9706e-04 - 55s/epoch - 13ms/step\n",
      "Epoch 8/1000\n",
      "4208/4208 - 57s - loss: 8.6457e-04 - val_loss: 9.0270e-04 - 57s/epoch - 13ms/step\n",
      "Epoch 9/1000\n",
      "4208/4208 - 54s - loss: 8.6474e-04 - val_loss: 9.0267e-04 - 54s/epoch - 13ms/step\n",
      "Epoch 10/1000\n",
      "4208/4208 - 55s - loss: 8.6490e-04 - val_loss: 8.9597e-04 - 55s/epoch - 13ms/step\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpm0tigfl0/model/data/model/assets\n"
     ]
    }
   ],
   "source": [
    "# AE\n",
    "\n",
    "for _ in range(100):\n",
    "    config = {'shape': 1957,\n",
    "              'output': 72,\n",
    "              'dropout': np.random.choice([0.01, 0.1, 0.2, 0.5]),\n",
    "              'num_layers': np.random.choice([3, 4, 5, 10]),\n",
    "              'num_neurons': np.random.choice([16, 32, 64, 128]),\n",
    "              'activation': np.random.choice(['gelu', 'gelu', 'relu'])}\n",
    "\n",
    "    model = build_ae_cpl_model(config)\n",
    "    \n",
    "    with mlflow.start_run() as run:\n",
    "        model_checkpoint_callback = ModelCheckpoint(\n",
    "            filepath=f\"models/model_{run.info.run_id}.keras\",\n",
    "            save_weights_only=False,\n",
    "            monitor='val_loss',\n",
    "            mode='min',\n",
    "            save_best_only=True)\n",
    "        callback = EarlyStopping(monitor='val_loss', patience=8, verbose=0)\n",
    "        mlflow.log_param(\"Autoencoder\", True)\n",
    "        mlflow.log_param(\"CPL\", True)\n",
    "\n",
    "        history = model.fit(x_train, y_train, epochs=1000, batch_size=2000,\n",
    "                            validation_data=(x_val, y_val),\n",
    "                            verbose=2,\n",
    "                            callbacks=[callback, model_checkpoint_callback])\n",
    "        \n",
    "        evaled_test = model.evaluate(x_train, y_train, batch_size=100, verbose=0)\n",
    "        evaled_train = model.evaluate(x_test, y_test, batch_size=100, verbose=0)\n",
    "\n",
    "        mlflow.log_metric(\"test_loss\", evaled_test)\n",
    "        mlflow.log_metric(\"train_loss\", evaled_train)\n",
    "\n",
    "        plt.plot(history.history[\"loss\"])\n",
    "        plt.plot(history.history[\"val_loss\"])\n",
    "        plt.title('Model Loss')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plotname = f\"plots/loss_plot_{run.info.run_id}.png\"\n",
    "        plt.savefig(plotname)\n",
    "        plt.close()\n",
    "\n",
    "        # Log the plot as an artifact\n",
    "        mlflow.log_artifact(plotname)\n",
    "        #model_path = \"modles\"\n",
    "        #mlflow.tensorflow.log_model(tf_saved_model_dir=model_path, artifact_path=\"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62d5b96-20c7-4802-939d-2135ffabe8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regs\n",
    "\n",
    "for _ in range(100):\n",
    "    config = {'shape': 1957,\n",
    "              'output': 72,\n",
    "              'dropout': np.random.choice([0.01, 0.1, 0.2, 0.5]),\n",
    "              'num_layers': np.random.choice([3, 4, 5, 10]),\n",
    "              'num_neurons': np.random.choice([16, 32, 64, 128]),\n",
    "              'activation': np.random.choice(['gelu', 'gelu', 'relu'])}\n",
    "    \n",
    "    model = build_ae_model(config)\n",
    "    \n",
    "    with mlflow.start_run() as run:\n",
    "        model_checkpoint_callback = ModelCheckpoint(\n",
    "            filepath=f\"models/model_{run.info.run_id}.keras\",\n",
    "            save_weights_only=False,\n",
    "            monitor='val_loss',\n",
    "            mode='min',\n",
    "            save_best_only=True)\n",
    "        callback = EarlyStopping(monitor='val_loss', patience=8, verbose=0)\n",
    "        mlflow.log_param(\"Autoencoder\", True)\n",
    "        mlflow.log_param(\"CPL\", False)\n",
    "\n",
    "        history = model.fit(x_train, y_train, epochs=1000, batch_size=2000,\n",
    "                            validation_data=(x_val, y_val),\n",
    "                            verbose=2,\n",
    "                            callbacks=[callback, model_checkpoint_callback])\n",
    "        \n",
    "        evaled_test = model.evaluate(x_train, y_train, batch_size=100, verbose=0)\n",
    "        evaled_train = model.evaluate(x_test, y_test, batch_size=100, verbose=0)\n",
    "\n",
    "        mlflow.log_metric(\"test_loss\", evaled_test)\n",
    "        mlflow.log_metric(\"train_loss\", evaled_train)\n",
    "\n",
    "        plt.plot(history.history[\"loss\"])\n",
    "        plt.plot(history.history[\"val_loss\"])\n",
    "        plt.title('Model Loss')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plotname = f\"plots/loss_plot_{run.info.run_id}.png\"\n",
    "        plt.savefig(plotname)\n",
    "        plt.close()\n",
    "\n",
    "        # Log the plot as an artifact\n",
    "        mlflow.log_artifact(plotname)\n",
    "        #model_path = \"modles\"\n",
    "        #mlflow.tensorflow.log_model(tf_saved_model_dir=model_path, artifact_path=\"model\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
